<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JMS(4)-AMQ Destination特性]]></title>
    <url>%2F2018%2F12%2F07%2FJMS-4-AMQ-Destination%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[wildcardswildcards用来支持名字分层体系,它不属于JMS规范,是AMQ的一个扩展。 AMQ支持三种wildcards: ‘.’, 路径上名字的分隔符 ‘*’, 常见的通配符,匹配路径上的所有 ‘&gt;’,递归匹配以这个名字开头的dest 例如下面两个dest: PRICE.STOCK.CN.WANDAPRICE.STOCK.AM.ALIBABA PRICE.&gt; 匹配所有的价格变动 PRICE.STOCK.&gt;匹配所有的股价变动 PRICE.STOCK.CN.* 匹配所有A股变动 PRICE.STOCK.*.ALIBABA 匹配与阿里相关的股价变动 组合队列 composite destination组合队列允许用一个虚拟的dest代表多个dest,这样就可以通过组合队列在一个操作中同时向多个queue发送消息。 不同队列名用’,’隔开。如果有topic有ptp,则需要写明 12345678910public Queue queue()&#123; return new ActiveMQQueue(&quot;queue.a,queue.b&quot;);&#125;public Queue queue2()&#123; return new ActiveMQQueue(&quot;queue://queue.a,topic://topic.a&quot;);&#125; delete inactive destination上面的组合队列可以很大程度上方便使用,但是可能会造成创建过多的队列,那么就需要一种功能能够自动删除无用的队列。当然也可以通过控制台或者jms远程删除。 这种方式需要在配置文件进行配置: 12345678910111213&lt;broker xmlns=&quot;http://activemq.apache.org/schema/core&quot; schedulePeriodForDestinationPurge=&quot;10000&quot;&gt;&lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry topic=&quot;&gt;&quot; gcInactiveDestinations=&quot;true&quot; inactiveTimeoutBeforeGC=&quot;30000&quot;&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt;&lt;/destinationPolicy&gt;&lt;/destinationPolicy&gt;&lt;/broker&gt; schedulePeriodForDestinationPurge 设置检查间隔,单位ms inactiveTimeoutBeforeGC 表示空闲多久会被删除,单位ms gcInactiveDestinations=true 删除不活动的队列 Destination options这个特性是AMQ在JMS规范之外提供的特性,以一种url的方式可以对队列进行一些配置。 consumer.prefechSize: consumer一次可以拉取的最大消息数量 consumer.maximumPendingMessageLimit: 当存在慢消费的情况时,非持久化的topic允许丢弃消息的最大值 consumer.retroactive: 是否为回溯消费者 consumer.dispatchAsync: 是否异步分发,默认为true consumer.exclusive: 是否为独占消费者,默认false consumer.priority: 消费者优先级,默认为0 123public Queue queue3()&#123; return new ActiveMQQueue(&quot;queue.c?consumer.priority=false&amp;consumer.prefechSize=10&quot;)&#125; Visual Destitation虚拟dest创建的是逻辑dest,客户端和消费端通过它来生产和消费消息,并把它映射到物理dest。AMQ支持两种方式: visual topic 虚拟主题 composite destination 组合 虚拟dest的作用体现在哪里呢? 在AMQ,topic只有在持久订阅下才是持久化的,它的每个订阅者都会收到所有的消息。但它存在两个问题: 同一个应用只能用一个listener去监听topic,而不能使用多个,通过负载均衡来处理消息(当消费端部署了多个节点,那么每个节点都会消费一遍这个消息,而我们理想的情况是a节点处理n条,b节点处理m条)。虽然PTP模式可以解决这个问题,但明显会创建过多的Queue。所以,又要订阅发布,又要消息分组,JMS本身是不支持的。 同一个应用内,消费者failover问题。由于只能有单个持久订阅者,如果这个订阅者离线,那么消息就无法处理,系统健壮性不足。 为了解决这个问题,AMQ提出了visual topic 如何使用1234@Beanpublic Topic topic()&#123; return new ActiveMQTopic(&quot;VirtualTopic.Orders&quot;);&#125; 对于消费者来说,只需要创建正常的topic,然后以’VirtualTopic’开头。 对于消费端来说,需要将自己视为一个队列,不同的应用使用不同的队列名,即可表示自己是一个消费端的负载均衡。队列名必须以‘Consume’开头 123456789@Beanpublic Queue queue4()&#123; return new ActiveMQQueue(&quot;Consumer.A.VirtualTopic.Orders&quot;);&#125;@Beanpublic Queue queue5()&#123; return new ActiveMQQueue(&quot;Consumer.B.VirtualTopic.Orders&quot;);&#125; Mirrored QueuesAMQ中每个Queue中的消息只能被一个consumer消费。但有时候你可能希望监视消息流。因此AMQ提供了mirrored queue机制,broker会把发送到某个queue的消息转发到一个名称类似的topic,监视程序只需要监听这个mirrored queue topic。 首先要对broker进行配置: 1&lt;broker xmlns=&quot;http://activemq.apache.org/schema/core&quot; brokerName=&quot;localhost&quot; dataDirectory=&quot;$&#123;activemq.data&#125; useMirroredQueues=&quot;true&quot;&gt; 如果不进行其他配置,默认的mirror topic前缀是 ‘VirtualTopic.Mirror.’,当然也支持自定义格式: 123&lt;destinationInterceptors&gt; &lt;mirroredQueue copyMessage=&quot;true&quot; postPrefix=&quot;.mirror&quot; prefix=&quot;mirror.&quot;&gt;&lt;/destinationInterceptors&gt;]]></content>
      <categories>
        <category>JMS</category>
      </categories>
      <tags>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JMS(3)-JMS API结构]]></title>
    <url>%2F2018%2F12%2F06%2FJMS-3-JMS%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[JMS API的结构还是比较简单的。 创建一个JMS的基本步骤是: 创建JMS ConnectionFactory 通过ConnectionFactory创建一个Connection 通过Connection创建jms session 创建destination、producer、consumer 发送消息 关闭资源 JmsTempate在Springboot中一般使用JmsTempate进行操作,所以对照上面的过程,看一下template是如何进行封装的。 引入Pom 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt;&lt;/dependency&gt; code 首先在启动类上添加注解@EnableJms,会启动一些JMS的自动配置,包括JmsTempate。 12345public JmsTemplate(ConnectionFactory connectionFactory) &#123; this(); setConnectionFactory(connectionFactory); afterPropertiesSet(); &#125; JmsTemplate的构造函数中需要一个ConnectionFactory,因此会先实例化一个ConnectionFactory。也就对应了上面过程中的第一步。 当注入JmsTemplate我们就可以调用send方法进行消息发送,非常简单。但正是因为它封装的太好了,我们反而不容易了解它的具体实现细节,所以进入send方法的源码 123456public void send(final Destination destination, final MessageCreator messageCreator) throws JmsException &#123; execute(session -&gt; &#123; doSend(session, destination, messageCreator); return null; &#125;, false); &#125; send方法调用了内部方法execute,而且我们看到一个关键参数名session,这里是一个lambda表达式,在session内封装了消息和destination,然后丢进execute方法。 12345678910111213141516171819202122232425262728public &lt;T&gt; T execute(SessionCallback&lt;T&gt; action, boolean startConnection) throws JmsException &#123; Assert.notNull(action, &quot;Callback object must not be null&quot;); Connection conToClose = null; Session sessionToClose = null; try &#123; Session sessionToUse = ConnectionFactoryUtils.doGetTransactionalSession( obtainConnectionFactory(), this.transactionalResourceFactory, startConnection); if (sessionToUse == null) &#123; conToClose = createConnection(); sessionToClose = createSession(conToClose); if (startConnection) &#123; conToClose.start(); &#125; sessionToUse = sessionToClose; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Executing callback on JMS Session: &quot; + sessionToUse); &#125; return action.doInJms(sessionToUse); &#125; catch (JMSException ex) &#123; throw convertJmsAccessException(ex); &#125; finally &#123; JmsUtils.closeSession(sessionToClose); ConnectionFactoryUtils.releaseConnection(conToClose, getConnectionFactory(), startConnection); &#125; &#125; execute方法创建connection,绑定session。调用doInJms方法将message发送到broker,然后释放资源。 这样粗略的看了一下消息的发送原理。]]></content>
      <categories>
        <category>JMS</category>
      </categories>
      <tags>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JMS(2)-可靠性保证与消息模型]]></title>
    <url>%2F2018%2F12%2F06%2FJMS-2-%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81%2F</url>
    <content type="text"><![CDATA[消息确认对于一个消息中间件来说,可靠性保证一直是一个重要主题。Jms消息的可靠性保证,通常包含三个阶段: 客户端接收消息/客户端处理消息/客户端ACK 在事务性会话中(jms session),当事务被提交,即发生自动确认。在非事务会话中,消息的确认取决于应答模式:包含三种应答模式: client 客户端手动确认 auto 自动确认 dups_ok 一种延迟确认的模式,个人理解是一种批量签收。可以减少开销,但是可能会造成重复的ack。如果没有仔细研究过原理,不建议使用 消息持久化JMS消息持久化有两种方式: PERSISTENT: 持久化模式,消息不会因为broker宕机而丢失,默认模式 NO_PERSISTENT: broker宕机,消息丢失 ActiveMQ内部消息存储默认使用了KahaDB,同时开支持的方式有AMQ,JDBC,Memory。可以在activemq.xml中对KahaDB进行配置 123&lt;persistenceAdapter&gt; &lt;kahaDB directory=&quot;$&#123;activemq.data&#125;/kahadb&quot;/&gt;&lt;/persistenceAdapter&gt; 可用属性: indexWriteBatchSize: 批量写入磁盘索引的数量,默认1000 indexCacheSize: 内存中缓存索引的page数量,默认1000 enableIndexWriteAsync: 是否异步写出索引,默认false journalMaxFileLength: 设置每个消息datalog大小,默认32MB enableJournalDiskSyncs: 如果没有加事务,是否需要写入磁盘。JMS持久化时需要设置为false cleanUpInterval: 清理过期消息,默认30000 archiveDataLogs: 对于需要删除的文件,不做删除,而是进行压缩。默认为false directoryArchive: 压缩文件的存放位置 消息过期可以设置消息的过期时间,默认是永不过期。 临时目的地jms session可以创建临时的queue或者topic,当创建临时目的地的连接断开,临时目的地也就删除。只有创建临时目的地连接的消费者才可以消费这里的信息。 本地事务在JMS客户端中,可以使用本地事务来组合消息的接收和发送,最后使用commit提交或者使用rollback进行回滚。事务提交表示发送者的消息都已经发送,消费者消息都已确认。事务回滚意味着生产的所有消息被销毁，消费的所有消息被恢复并重新提交。 需要注意的是,如果业务是一个请求/回复模式,发送一个消息,同时希望在事务中等待消息的回复,那么程序会被挂起,因为直到事务提交,发送操作才会真正执行。 消息的生产和消费不能再同一个事务中。 消息模型-PTPPTP就是一种点对点的模型,一个消费者一个生产者,是一种单播模式。 当session关闭时,如果有一些消息已经收到,但还没有签收,那么当客户端再次连接上时,这些消息还会被再次接收。 如果消费端设置了选择器,那么不符合条件的消息会留在队列中,不会被接收。 队列可以持久保存消息知道消费端收到消息,充分体现异步传输的优势 消息模型-pub/sub发布订阅模式,生产者制定一个主题,多个消费端可以订阅这个主题来收到消息,是一种广播模式。 消息订阅分为持久订阅和非持久订阅:非持久订阅当客户端处于非激活状态时,消息将会消失,永远不能接收到。持久模式则是消费端向JMS注册自身,当消费端宕机,broker会保存这个主题的消息,当消费端上线时,可以得到离线时漏掉的消息。 非持久模式下不能重新派送一个未签收的消息,所以需要设置为持久化模式。]]></content>
      <categories>
        <category>JMS</category>
      </categories>
      <tags>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JMS(1)-消息结构]]></title>
    <url>%2F2018%2F12%2F06%2Fjms-%E6%B6%88%E6%81%AF%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[JMS消息结构JMS消息由以下部分组成: 消息头 消息体 属性 消息头包含识别信息和路由信息: JMSDestatination: 路由地址,由sender设置 JMSDeliveryMode: 传送模式。两种: 持久模式和非持久化模式,持久模式消息会被传送”仅仅一次”。也就是说当broker宕机,消息不会丢失,当broker恢复后会再次发送消息。非持久消息保证传输最多一次,当机器宕机,数据将永远消失。 JMSExpiration: 消息过期时间,消息在过期时间内没有被消费,则会删除。 JMSPriority: 消息优先级,从0-9,0-4是普通消息,5-9是加急消息。JMS提供的保障的是加急消息先于普通消息送达,其他尽量保证,默认为4 JMSMessageID: 每个消息的唯一识别,可以手动设置为业务id,否则会自动生成。 JMSCorrelationID: 用来连接到另外一个消息,典型的应用是将回复消息链接到原消息,也就是有应答的场景。 JMSReplyTo: 提供本消息回复消息的目的地址 JMSType: 消息类型识别符 JMSRedelivered: 如果客户端收到一个设置了JMSRedelivered属性的消息,表示客户端之前接受过这个消息,但是没有ack。如果触发了消息重新发送,JMSRedelivered=true,否则false。 JMS消息体提供了5种消息体: TextMessage MapMessage BytesMessage StreamMessage ObjectMessage JMS提供三种消息属性: 应用程序添加的属性: Message.setStringProperty(k,v) JMS定义的属性: connection.getMetaData().getJMSXPropertyNames() 获取jms定义的属性 三方插件提供的特殊属性]]></content>
      <categories>
        <category>JMS</category>
      </categories>
      <tags>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习总结5-调度]]></title>
    <url>%2F2018%2F12%2F05%2Fk8s%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%935-%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[K8S调度器的主要任务就是为Pod寻找一个合适的Node。 默认调度器K8S提供了默认调度器,它的主要流程是:根据Predicate算法检查每个Node。然后再调用Priority算法给Node打分。最终调度结果就是选择分数最高的那个Node。 K8S调度算法的流程如下: 主要是两个循环过程: 第一个循环informer负责监听etcd中Pod、Node、Service等需要调度的组件。一旦发现informer就将它放入一个优先级队列。 第二个循环是Scheduling Path,不断从优先队列中取出一个Pod,使用Predicate算法过滤出一组Node,Node的信息从Cache中获取。选出一个合适的Node之后,调度器就会进行绑定操作,将Pod的nodeName填写为筛选出的Node名称。 PredicatesK8S中Predicates算法默认提供四种调度策略: GeneralPredicates这是第一组过滤策略,也是最基础的调度规则。目的就是根据yaml配置文件检查硬件资源是否充足,端口是否冲突。由于调度策略采用了无锁化设计,所以当一个Pod被调度到Node上时,Node会再次执行一遍这个策略。 Volume相关过滤这组规则主要对Volume进行过滤。 首先是NoDiskconflict,检查Pod声明挂载的volume是否存在冲突。 接着是MaxPDVolumeCountPredicate,判断节点某种volume类型是否超过上限。 接着是VolumeBindingPredicate,主要作用是判断节点亲和性。 宿主机相关过滤规则这组规则是判断Pod是否满足Node的某些条件。 例如配置了PodToleratesNodeTaints字段,只有当Pod的Toleration和Node的taint字段相匹配,才能调度到该节点。 Pod相关过滤规则这组检查和GeneralPredicates有很多重合,比较特殊的一点是PodAffinityPredicate。用来检查Node上Pod之间的亲密和反亲密关系。 上面这四种类型的 Predicates，就构成了调度器确定一个Node可以运行待调度Pod的基本策略。 PrioritesProorites根据算法对选出的Node打分,最常用的是LeastRequestedPriority 1score = (cpu((capacity-sum(requested))10/capacity) + memory((capacity-sum(requested))10/capacity))/2 其实就是选择内存和CPU最多的主机,除此之外还有NodeAffinityPriority,TaintTolerationPriority以及InterPodAffinityPriority。 优先级与抢占机制优先级首先要明确的是,优先级与抢占解决的是Pod调度失败的问题。 通常情况下,调度失败的Pod会被搁置,直到出现满足条件的Node才能再次调度。但是如果这个Pod是一个优先级非常高的系统,我们希望能通过减少一部分优先度低的Pod,给优先级高的Pod空出位置。 在K8S 1.10版本提供了优先级与抢占机制,首先要定义一个PriorityClass类型的yaml 1234567apiVersion: scheduling.k8s.io/v1beta1kind: PriorityClassmetadata: name: high-priorityvalue: 1000000globalDefault: falsedescription: &quot;This priority class should be used for high priority service pods only.&quot; 这里定义了优先级为1000000的配置文件,globalDefault如果设置为true,就会将Pod的默认优先级定义为1000000,而实际默认是0。优先级最大为10亿,超过10亿为K8S内部的Pod。 定义过后就可以在Pod中使用: 123456789101112apiVersion: v1kind: Podmetadata: name: nginx labels: env: testspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent priorityClassName: high-priority 经过配置之后,调度队列就会将这个Pod就会比优先级低的Pod提前出队。 抢占抢占机制相比优先级要复杂的多。当一个高优先级的Pod调度失败之后,就会触发抢占机制。抢占的大概过程如下: k8s选出优先级较低的Pod所在的Node节点,将抢占者的spec.nominatedNodeName填写为该Node,然后将该pod重新入队。如果在下个周期,这个Pod没有抢到node(出现了优先级更高的pod),将spec.nominatedNodeName去掉重新入队,如果抢占成功,则让被抢占节点优雅退出(delete api),将新pod部署。 接下来讲述一下详细原理,我们将这个Pod称为抢占者,旧的节点称为牺牲者: 抢占的重要设计就是在调度队列的实现里,实现了两个不同的队列。 activeQ: 存放下个周期需要调度的Pod unschedulableQ: 用于存放调度失败的Pod,当这个队列中的Pod被更新时,k8s将它重新放入activeq。 在这里发生调度失败,也就是节点入队时会去触发寻找牺牲者的流程。 首先调度器检查这次调度失败的原因,用来确认抢占机制可以实现重新调度。 如果抢占可以发生,调度器将缓存的所有节点信息复制一份,然后利用副本去模拟一遍抢占过程。 模拟成功之后会选出一个最佳Node,接着调度器就会开始真正的抢占操作: 首先检查牺牲者列表,清理Pod的spec.nominatedNodeName字段 为抢占者设置spec.nominatedNodeName属性 开启协程,删除旧Pod,完成抢占]]></content>
      <categories>
        <category>K8S</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>K8S</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql之日志模块]]></title>
    <url>%2F2018%2F12%2F04%2Fmysql%E4%B9%8Bredo-log%E5%92%8Cundo-log%2F</url>
    <content type="text"><![CDATA[平时在看一些mysql的文章时,不可避免看到过undolog,redolog,binlog等xxlog概念,这些概念都属于mysql的日志模块,这里对这些概念做一次总结。 redologredolog也叫重做日志,是innodb特有的一种log,用于保证事务的持久性。在事务提交时,必须将该事务所有事务日志写到磁盘的redologfile 和 undologfile上。 我们知道mysql的数据会持久化到磁盘上,但是如果每次进行更新都写磁盘。磁盘要进行io操作找到这条记录并更改,成本很高。因此mysql就是用了redolog来提升效率。 具体来说,当有一条记录更新时,Innodb将数据循环写到redolog中,更新内存。当数据库空闲时或者redolog满,就会异步刷写到磁盘上。这种基于WAL(预写日志)的存储,都是crash-safe的,因为mysql可以通过redolog在crash之后恢复数据。redo log是在事务开始之后就开始逐步写入磁盘。 关于redolog比较重要的一个参数是innodb_flush_log_at_trx_commit innodb_flush_log_at_trx_commit=1,每次commit都会将日志从redo log buffer(用户空间)写到system buffer(内核空间),并fsync刷新到磁盘文件中。 innodb_flush_log_at_trx_commit=2,每次commit都会将日志从redo log buffer(用户空间)写到system buffer(内核空间),由系统决定什么时候fsync到磁盘。如果这时服务器宕机,则会丢失这部分数据。 innodb_flush_log_at_trx_commit=0,mysql每秒从redo log buffer,把数据写入到系统中去。数据库宕机则丢失一秒内的数据。 binlogbinlog是mysql服务器级别的日志,也叫做归档日志,二进制日志。这是因为innodb并不是mysql原生的引擎,binlog只能用于归档,并没有提供crash-safe能力。 binlog在事务提交的时候产生,将事务中的语句按照一定的格式记录到binlog中。这里binlog的功能与redolog有些类似,但是精度也就是可靠性明显不同,redolog作用于事务层面,而binlog则主要用来做数据库备份,同步。另一个区别在于redolog是循环写的,不提供持久保存,而binlog提供归档的功能。 binlog有两种模式:row和statement:statement记录的是sql语句,row模式记录变更前后的内容,会记录两条。因此row模式更安全,但是会是log变大。 两阶段提交由于redo log和binlog都会记录事务,那么这就对binlog和redolog的提交有要求。如果binlog和redolog的记录不一致,那么就会出现事务不一致的状况,这常常发生在主从复制的环境下。 MySQL通过两阶段提交过程来完成事务的一致性的,也即redo log和binlog的一致性的,先写redo log,处于prepare状态,再写binlog,写成功后进入commit状态。两个日志都提交成功（刷入磁盘），事务才算真正的完成。 undologundolog也叫回滚日志,保存了事务发生之前数据的版本,可以用来回滚,并提供MVCC。 当我们对数据进行更新操作就会产生undolog,可以把undolog可以理解为一个链表,保存了一个字段连续变化的过程。当我们进行修改时,会将数据备份到undolog,并在undlog中进行修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。undolog正式凭借此保证事务的原子性。 undolog另一个重要作用就是并发读写时支持mvcc(多版本并发控制)机制。当一行数据被写操作锁定时,读操作可以根据事务号到undolog中找到合适版本的数据,而不会写锁阻塞读操作,这就是一致性视图。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm学习笔记-重载与重写]]></title>
    <url>%2F2018%2F11%2F29%2Fjvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%87%8D%E8%BD%BD%E4%B8%8E%E9%87%8D%E5%86%99%2F</url>
    <content type="text"><![CDATA[重载与重写重载与重写是java中相当重要的一组概念,java利用重载和重写实现了多态,看下面一个例子 123456void invoke(Object obj, Object... args) &#123; ... &#125;void invoke(String s, Object obj, Object... args) &#123; ... &#125;invoke(null, 1); // 调用第二个 invoke 方法invoke(null, 1, 2); // 调用第二个 invoke 方法 在java中,如果一个类中存在相同名字的函数,并且参数也相同,那么它是无法通过编译的。那么就需要修改参数类型让他们不同,这种方法之间的关系,就是重载。 重载的方法在编译阶段就可以识别,有以下几个原则: 首先在不进行自动装箱/拆箱的情况下调用方法 1234567891011121314public void test(int i )&#123; System.out.println(&quot;test int&quot;);&#125;public void test(Integer i)&#123; System.out.println(&quot;test integer&quot;);&#125;public static void main(String[] args) &#123; Rich r = new Rich(); r.test(1); // 执行第一个&#125; 在1不匹配的情况下,允许自动拆箱装箱,不优先选择带有可变长参数方法: 1234567891011121314public void test(int i,String hello)&#123; System.out.println(&quot;test int&quot;);&#125;public void test(Integer i,String ... hellos)&#123; System.out.println(&quot;test integer&quot;);&#125;public static void main(String[] args) &#123; Rich r = new Rich(); r.test(1,&quot;1&quot;); //执行第一个&#125; 在2不匹配的情况下,允许自动装箱拆箱/允许可变长参数 除了同一个类中的方法,重载也可以作用于父类与子类之间,如果子类定义了与父类方法名称相同而参数类型不同,那么这两个方法也构成了重载。 那么如果子类定义了与父类非私有方法同名的方法,并且参数类型也相同,那么这时子类重写了父类的方法。方法的重写,正是多态的一种重要体现方式,它允许子类继承父类部分功能的同时,拥有自己独特的行为。 jvm静态绑定与动态绑定jvm标识一个方法的依据是类名+方法名+方法描述符,方法描述符就是参数类型和返回类型构成。对于方法冲突的情况,jvm会在验证阶段报错。 对于重载方法的区分,在java编译时期就可以区分,因此重载也叫做静态绑定,或者编译时多态。而重写方法是在运行时确定的,所以也叫做动态绑定或者运行时多态。 当然上面的说法在某些情况下就不太严谨,例如某个类中的重载方法被它的子类重写,那么jvm就会将这个方法编译为动态绑定的类型。 更准确的说,jvm的静态绑定指的是在解析时能够直接识别目标的情况,而动态绑定则是依据运行时调用者的动态类型来识别目标的情况。 重写方法-桥接对于方法重写,jvm与java的判断条件是不同的。对于java来说,只要方法的名称和参数名称相同,则构成重写。而对于jvm来说,不同的返回值所构成的方法描述符是不同的,所以对于jvm来说并没有构成重写。举个栗子: 1234567891011121314151617181920public class Merchant &#123; public Number actionPrice(double price) &#123; return price * 0.8; &#125;&#125;public class NaiveMerchant extends Merchant &#123; @Override public Double actionPrice(double price) &#123; return 0.9 * price; &#125; public static void main(String[] args) &#123; Merchant merchant = new NaiveMerchant(); // price 必须定义成 Number 类型 Number price = merchant.actionPrice(40); System.out.println(price); &#125;&#125; 在上面的代码中,父类与子类的返回类型是不同的,java对其判断为重写方法,那么这时jvm如何处理呢,因为jvm只有当方法的方法描述也相同才判断为重写方法 123javac Merchant.java NaiveMerchant.javajavap -v NaiveMerchant 我们通过反编译查看字节码 12345678910111213141516171819202122232425 public java.lang.Double actionPrice(double); descriptor: (D)Ljava/lang/Double; flags: ACC_PUBLIC Code: stack=4, locals=3, args_size=2 0: dload_1 1: ldc2_w #2 // double 0.9d 4: dmul 5: invokestatic #4 // Method java/lang/Double.valueOf:(D)Ljava/lang/Double; 8: areturn LineNumberTable: line 13: 0// 桥接方法 public java.lang.Number actionPrice(double); descriptor: (D)Ljava/lang/Number; flags: ACC_PUBLIC, ACC_BRIDGE, ACC_SYNTHETIC Code: stack=3, locals=3, args_size=2 0: aload_0 1: dload_1 2: invokevirtual #12 // Method actionPrice:(D)Ljava/lang/Double; 5: areturn LineNumberTable: line 9: 0 可以看到这里生成了两个方法,第二个方法的flags描述为ACC_BRIDGE,为了保持重写的语义，Java 编译器会在 NaiveMerchant 的字节码文件中自动生成一个桥接方法来保证重写语义。当子类在继承父类的一个泛型方法、或子类实现一个接口的泛型方法,编译器也会在子类的 class 文件中自动生成桥接方法。 调用相关指令java字节码中与调用相关的指令共有5种: invokestatic 调用静态方法(static) invokedynamic 调用动态方法 invokevirtual 调用非私有实例方法 invokespecial 调用私有实例方法,构造器,super,实现接口的默认方法 invokeinterface 调用接口 常量池在编译的过程中,并不知道方法的具体内存地址。因此编译器会暂时使用一个符号引用来表示该方法。符号引用存储在class文件的常量池中,上面字节码中#12 #4就表示符号引用,常量池会显示在class文件的头部 12345678Constant pool: #1 = Methodref #12.#28 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #29.#30 // java/lang/System.out:Ljava/io/PrintStream; #3 = String #31 // action 1 #4 = Methodref #32.#33 // java/io/PrintStream.println:(Ljava/lang/String;)V #5 = InvokeDynamic #0:#37 // #0:makeConcatWithConstants:(Ljava/lang/String;)Ljava/lang/String; #6 = String #38 // test int...]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm学习笔记-类加载]]></title>
    <url>%2F2018%2F11%2F27%2F%E8%A1%A8%E9%9D%A2%E7%90%86%E8%A7%A3jvm-%E7%B1%BB%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[宏观 当我们写好.java程序点击运行的时候发生了什么 当我们写好.java的源程序，使用javac命令把源程序编译成.class文件，编译后的.class文件(类字节码文件)包括以下内容: 以魔数Magic Number:0xCafeBabe开头 ConstantPool:符号表 FieldInfo:类成员变量表 方法描述 附加节点 … 有了.class文件我们就可以执行java命令运行java程序 首先JVM装载.class，也就是类加载器加载字节码。但是类加载器本身也是一个java类，所以它也需要被加载，幸运的是有一个类加载器是用c++编写的，叫做Bootstrap类加载器，属于虚拟机内核，用特定于操作系统的本地代码实现。Bootstrap类加载器负责加载javajava核心包中的类(rt.jar)，这些类的Class.getClassLoader()方法返回值会null，表示需要Bootstrap加载器来加载。JAVA核心包中还有两个类加载器:ExtClassLoader和ApplicationClassLoader。他们都用java语言编写，其中ExtClassLoader负责加载/jre/lib/ext目录下的jar，ApplicationClassLoader负责加载应用程序的启动执行类，即当使用java命令去启动执行一个类时，JAVA虚拟机使用AppClassLoader加载这个类。所以这里有个小track就是把一些自己常用但是非java自带的jar放到ext目录下，这样就可以少写几个maven dependency。 为什么要类加载器 java类加载都是在程序的运行期完成的 增加java程序的灵活性，例如： 面向接口的编程，在程序运行时才指定其具体的实现类。 用户自定义类加载器,支持程序从网络或者其他地方加载一个类。 类的生命周期 ①的可控性最强，因为可以自定义类加载器 ①②③⑤的顺序一定。但注意是开始顺序一定，并不保证按顺序完成。 ④过程可能在⑤之后进行，为了支持java的运行时绑定 加载我们知道java类型分为基本类型和引用类型,基本类型是jvm预先定义好的,引用类型包括类,接口,数组类,泛型参数。由于泛型参数在编译过程中会被擦除,数组类由jvm生成,所以只剩下类和接口才会有对应的字节流。 通过一个类的全限定名获取定义此类的二进制字节流 将字节流转化元数据区的数据结构 在堆中生成这个类的对象，作为访问此类的入口 在jvm中有个规矩,任何一个类加载器拿到一个接收到加载请求,都要转交给父类加载器,如果父类加载器没有找到路径的情况下,子类加载器才会去加载。 在JAVA9之前,类加载器的层级结构为: Bootstrap ClasssLoader(c) -&gt; extension ClassLoader -&gt; application ClassLoader 由于JAVA9引入了模块系统,将extension ClassLoader改为Platform ClassLoader。除了java.base由启动类加载器加载,其他都交给平台类加载器加载 如果两个类相等，那么不光要class是相同的，而且需要类加载器相同。 连接 验证: 确保符合jvm规范，没有安全问题 准备: 为类的静态字段分配内存。在这里static变量会被赋予一个默认初始值,而final修饰的则会直接赋予原值 解析: 将常量池内的引用符号替换为直接引用（可以理解为将原来的多级指针指向的最终地址替换指针） 初始化将一个类中所有被static关键字标识的代码统一执行一遍，如果执行的是静态变量，那么就会使用用户指定的值覆盖之前在准备阶段设置的初始值.如果执行的是static代码块，那么在初始化阶段，JVM就会执行static代码块中定义的所有操作。 jvm并没有强制规定什么时候要进行加载，但是规定了五种有且只有的情况立即初始化类，当然在初始化之前要完成前面的几个步骤。 new一个类的对象 调用类的静态成员（除了final常量）和静态方法 使用java.lang.reflect包的方法对类进行反射调用 当虚拟机启动,加载main方法所在的类 当初始化一个类，如果其父类没有被初始化，则先初始化它父类 类加载器 关于双亲委派模型的疑问？？？ 这个图相信大家都见到过，也就是双亲委派模型(Parents-Delegation-Model)的示意图。详细内容就不作介绍。一点疑问就是当我第一次学这个内容的时候我在考虑双亲的双体现在哪里呢？它只是向上面一级也就是父加载器传递，这个Parents体现的应该是垂直方向，也就是父亲，爷爷这种关系，而不是水平方向上的双亲关系。所以我认为这个模型不应该叫双亲委派模型，英文也应该是(Parent-Delegation-Model),我认为双亲这种说法很容易误导初学者。在《Thinking in jvm》英文原本中印证了我的想法,如图。个人认为这种说法更准确。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红黑树]]></title>
    <url>%2F2018%2F11%2F25%2F%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[《算法导论》中的红黑树红黑树与AVL相似,都是对BST进行了一系列优化,防止退化成链表的现象。算法导论中对红黑树的定义如下 每个节点要么是红色,要么是黑色 根节点必须黑色 每个叶子节点(空节点)也是黑色 红节点的孩子节点必须为黑色 任意节点到叶子节点,经过的黑色节点数量是相同的 相信大多数人都看过这段关于RBT的描述,然后通过这段描述推导出更多的性质,然后就是一些列的旋转、染色代码,非常不友好。问题就在于我们通过上面的性质根本无法得知红黑树是怎么得来的,作者怎么发明这种算法的。 2-3树事实上红黑树与2-3树是一种等价结构,但是2-3树更便于理解,因此我们从2-3树开始 首先2-3树满足BST的基本性质,每个节点可能是一个元素或两个元素,对于两个元素的节点,左边的元素小于右边的元素,如图所示: 在这个2-3树种,42叫做2节点,17/33叫做3节点,由于2-3树插入数据的方式,保证了2-3树是一个绝对平衡的树,也就是从根节点到任意叶子节点,所经过的长度一定是相同的。 2-3树如何保持平衡当树中插入第一个节点42,这个节点就作为根节点,此时2-3树平衡 这时插入第二个节点37,如果是BST则会判断大小然后放到42的左子树上去。但是2-3树不会将节点添加到一个空的位置,而是和42融合为一个新的节点,放在42的左边,也就是找到最后一个叶子节点并融合,此时树依然平衡 继续添加一个节点12,同理12融合到27的左边,暂时形成一个四节点。由于2-3树不允许存在4节点,那么此时就必须将这个4节点拆分,很容易就可以拆分成一个子树 这时我们继续添加一个节点18,它将融合到12的右边,形成一个3节点,此时树依然绝对平衡 继续添加节点6,暂时会融合到12的左边,形成一个4节点,但这时如果再像第一次那样拆分,树的形式就不是绝对平衡了 那么这时候该怎么做呢,答案就是将12与37进行融合,形成一个三节点,这时树就保持绝对平衡了 我们继续插入11,5。变化过程同理,首先形成一个二叉树,然后将6融合到父亲节点,形成一个暂时的四节点,继续将根节点进行拆分,则又得到了一个完全平衡的树 继续插入节点则可以根据上述的过程同理变换。 2-3树与红黑树的等价性在上面看到了2-3树的变换过程,其实红黑树的变换和2-3树是等价的。对于2-3树来说,包含两种节点,2节点和3节点。对于2节点,我们可以用一个普通的Node节点来表示。而对于3节点这种形式,由于一个Node只能放置一个元素,我们必须使用两个节点来表示3节点。而实际上这两个节点是一个同级的关系,并且本身应该属于同一个节点,所以这时我们可以对其中一个节点进行着色,一般是将左边较小的元素表示为红色。这时我们就可以通过一个红色节点和一个黑色节点将他们表示成2-3树种的3节点。这时我们就可以将一个2-3树映射成红黑树了。 这时我们将上面的2-3树描述成红黑树,相信这样一看,就可以理解为什么红黑树这样进行着色了。对照算法导论中的定义,可以发现每一条都符合 观察红黑树,可以发现,其实红黑树是一个保持”黑平衡”的二叉树,但是严格意义上来说,它并不是一个平衡二叉树,因为它的最大高度为2logn,也就是一红一黑相连续,由于常数不记,所以它的时间复杂度是logn。相比于avl来说,查找可能会更慢,虽然都是O(logn)级别的。但是红黑树的应用却更加广泛,因为对于删除元素和新增元素,红黑树要更快]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习总结4-网络]]></title>
    <url>%2F2018%2F11%2F12%2Fk8s%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%934-%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[K8S的网络部分确实是一个难点,我在这里卡了很久也看了很多相关的文档。K8S的网络依赖于Docker,Docker的网络离不开linux内核的支持,所以要理解K8S的网络必须要了解linux网络知识。 linux网络基础Docker使用到的linux技术主要包括下面几种: linux通过命名空间(ns)可以将网络栈进行隔离,不同的ns完全隔离无法进行通信。Docker也正是利用了这种特性实现不同容器网络环境的隔离。那么如果我有需求需要让不同ns的进程进行通信,该怎么做呢?答案就是veth设备对。 Veth的重要作用就是打通网络栈之间的壁垒,就像一个通道,两端连着不同的网络栈,所以Veth必须成对出现。 Docker 服务启动后默认会创建一个 docker0 网桥（其上有一个 docker0 内部接口），它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。linux网桥的作用就是绑定多个以太网设备,将他们桥接起来。网桥上层只需要将数据交给网桥,网桥负责决定是将数据转发到哪些以太网口。以太网口接收到的网络报文,同样只需要交给网桥,网桥负责判断是丢弃还是继续向上层提交。 假如用户需要对某些关心的数据进行一些操作,Iptable/Netfilter就提供了这种功能,通过在挂载点挂载钩子函数,可以对一些数据包进行过滤、修改、丢弃操作等。Netfilter提供了五个位置来作控制 123451.PREROUTING (路由前)2.INPUT (数据包流入口)3.FORWARD (转发管卡)4.OUTPUT(数据包出口)5.POSTROUTING（路由后） 任何一个数据包，只要经过本机，必将经过这五个链中的其中一个链。接着又定义了表的概念用来管理这些链 123filter:定义允许与不允许manage: 修改数据报文nat: 网络地址转换 对于filter来讲一般只能做在3个链上：INPUT ，FORWARD ，OUTPUT 对于nat来讲一般也只能做在3个链上：PREROUTING ，OUTPUT ，POSTROUTING 而mangle则是5个链都可以做：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING iptables是工作在用户控件提供管理这些规则的接口的工具,它的背后就是工作在内和空间的Netfilter。 Docker网络模型docker支持四种网络模式: host container none bridge docker默认启用的是bridge类型,安装docker后会在宿主机上创建一个docker0网桥,当运行一个容器,veth就被会创建,一端连在docker0网桥上,另一端在宿主机内的eth0网桥上。这样就做到了同一主机上不同容器可以相互访问,但如果要通过其他ip访问这台机器的docker容器,就需要将宿主机上分配端口,将docker0的一个端口映射到宿主机端口上。 Kubernates网络模型K8S作为一种容器编排工具,主要解决一下场景中的问题: 容器与容器之间的通信 Pod与Pod之间的通信 Pod与service之间的通信 集群内外的通信 容器与容器由于Pod中的容器共享网络栈,所以容器之间可以使用localhost进行通信。 Pod之间通信Pod之间的通信可能存在于同一个Node上,也有可能存在于不同Node上。 同一个Node上的Pod都是通过veth连接到宿主机的docker0网桥,他们的Ip都是从docker0上动态获取并且和docker0 ip属于同一个网段。 Pod的地址与docker0在同一个网段,docker0与宿主机eth0属于两个不同的网段,Node之间的通信依赖于宿主机的网卡。所以不同Node的Pod想要通信,首先要找到Node对应的宿主机Ip,将数据包发送到宿主机网卡上,然后在转发给docker0,最后再到达目标Pod。 这部分的实现通常都是依赖一些网络配置工具来完成,例如flannel,后面再详细介绍。 Pod与Servicekubernetes创建服务时，会为服务分配一个虚拟的IP地址，即为ClusterIP，客户端通过访问这 个虚拟IP地址来访问内部组件。实质上具体访问内部的工作都是kube-proxy来完成的。kube- proxy担负着透明代理和负载均衡的角色，其实就是将某个访问service的请求，通过一套算法 和规则转发给后端的pod，这里说的算法就是Round Robin负载均衡算法和session粘连规则。 我们还可以通过修改service里面的service.spec.sessionAffinity参数的值来实现会话保持特 的定向转发。 总之，不管是clusterIP+targetPort，还是节点IP+NodePort，都会被Iptables规则重新定向到 kube-proxy监听服务的代理端口。 集群内外通信 NodeIP+NodePort 这种方式就是在宿主机上开放一个端口,供外部访问 Ingress Ingress 可以给 service 提供集群外部访问的 URL、负载均衡、SSL 终止、HTTP 路由等。为了配置这些 Ingress 规则，集群管理员需要部署一个 Ingress controller，它监听 Ingress 和 service 的变化，并根据规则配置负载均衡并提供访问入口。典型的就是Nginx Ingress。 loadbalance]]></content>
      <categories>
        <category>K8S</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>K8S</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习总结3-存储]]></title>
    <url>%2F2018%2F11%2F12%2Fk8s%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%933-%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[PV PVC StorageClass容器化一个应用最麻烦的地方,莫过于对其状态的管理,而最常见的状态就是存储状态。K8s提出了PV和PVC这样的概念,来方便开发人员对存储状态进行管理 PVPV文件描述的是一个持久化存储卷,例如一个Ceph文件系统,一个云盘等等,主要信息就是声明了访问方式以及存储容量的大小,主要由运维人员来维护,开发人员无需关心存储的具体细节。 12345678910111213apiVersion: v1kind: PersistentVolumemetadata: name: nfsspec: storageClassName: manual capacity: storage: 1Gi accessModes: - ReadWriteMany nfs: server: 10.244.1.4 path: &quot;/&quot; PVCPVC描述的是Pod所希望持久化存储的属性,例如所需磁盘的大小,可读写的权限等 1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: nfsspec: accessModes: - ReadWriteMany storageClassName: manual resources: requests: storage: 1Gi 这里PVC真正能够使用起来,必须要同一个PV进行绑定,这里包括两部分检查: PV的存储空间大于等于PVC所声明的 PV与PVC的storageClassName必须相同 当PV与PVC进行绑定之后,我们就可以在yaml里使用这个存储了。 12345678910111213141516171819apiVersion: v1kind: Podmetadata: labels: role: web-frontendspec: containers: - name: web image: nginx ports: - name: web containerPort: 80 volumeMounts: - name: nfs mountPath: &quot;/usr/share/nginx/html&quot; volumes: - name: nfs persistentVolumeClaim: claimName: nfs PV与PVCPV与PVC是如何做到持久化呢?我们知道Docker的volume机制就是将宿主机上的一个目录与容器里的目录绑定挂在到一起。而对于K8s这种分布式的系统来说,数据的持久化一定不能落在本地盘上,因为这样不具备分布式的特性,会引起单点的故障,所以hostPath和enptyDir是不行的。所以大多数情况下,持久化volume的实现依赖于一个远程存储服务，如NFS。 K8S所需要做的就是将这个远程存储服务与容器的本地目录进行绑定,这个过程分为两步: Attach:连接到远程的存储服务 Mount: 将磁盘设备格式化并挂载到宿主机目录 经过这两个阶段的处理,我们就得到了一个持久化的volume宿主机目录,然后通过-v 就可以为Pod里的容器挂在这个持久化volume了,这就是K8s处理PV的过程。 可以看到PV与PVC的关系就像JAVA中的接口与实现类,这样做的好出就是实现了解耦，与面向对象的思想一致。但是这样的方式也引入了一些困难:因为PV一般都是运维人员进行编写的,如果开发声明了一个PVC但是无法绑定PV,那么Pod就会创建失败,当K8s集群大到一定规模时,这种方式一定会成为一种灾难。 StorageClass由于PV与PVC带来的这种问题,我们很自然的就希望能够提供一个自动创建PV的机制,这就是dynamic provisioning,相比于人工管理PV的方式就叫做static provisioning。 dynamic provisioning机制的核心就是StorageClass对象,即创建一个PV的模板。一般来说一个StorageClass会定义两部分内容: PV的属性,如存储类型,大小 创建这种PV所需要的插件,如ceph,nfs 有了这个模板,K8S就能根据用户提交的PVC,找到一个对应的storageClass,然后调用storageClass所声明的插件,创建出PV。 1234567apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: block-serviceprovisioner: kubernetes.io/gce-pdparameters: type: pd-ssd 而作为开发者,我们就只需要在yaml中指定需要使用的storageClass就可以了 1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: claim1spec: accessModes: - ReadWriteOnce storageClassName: block-service resources: requests: storage: 30Gi 本地持久化虽然K8S内置了20中持久化实现方式,但是并没有提供本地的持久化存储方式。但是依然有很多用户希望能够直接使用宿主机上的本地磁盘目录,而不依赖远程的存储服务。这样做好出也很明显,Volume直接使用本地磁盘,IO性能会好很多。所以在1.10版本之后,K8S依靠PV/PVC实现了这个特性,即Local Persistent Volume。 首先本地持久卷并不适用于所有应用,并且相对于其他PV,一旦这些节点宕机,那么数据就会丢失,这就要求使用Local Persistent Volume的节点必须具有备份和回复能力。 难点1Local Persistent Volume并不等于hostPath+nodeAffinity。实际上并不应该把宿主机上的一个目录当做PV来使用,因为本地目录的存储完全不可控,随时都有可能被写满,其次缺少最基础IO隔离机制。所以一个Local Persistent Volume应该等于一块额外挂载到宿主机的磁盘,也就是一个PV一块盘。 难点2调度器如何保证Pod始终能被正确的调度到他所请求的Local Persistent Volume所在的节点。对于local PV来说,每个节点挂载情况可能完全不同,有的节点甚至没有挂载,那么K8s就需要维护这种关系,才能调度Pod,也就是在调度的时候考虑volume分布。 使用首先需要手动在node上挂载磁盘,例如/mnt/disks 接着定义PV 12345678910111213141516171819202122apiVersion: v1kind: PersistentVolumemetadata: name: example-pvspec: capacity: storage: 5Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /mnt/disks/vol1 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - node-1 可以看到这个PV定义了lcoal字段并且指定了路径.如果Pod要使用这个PV那么就必须运行在这个node-1节点上,所以指定了nodeAffinity。 接着定义一个StorageClass 123456kind: StorageClassapiVersion: storage.k8s.io/v1metadata: name: local-storageprovisioner: kubernetes.io/no-provisionervolumeBindingMode: WaitForFirstConsumer 这里需要注意local pv目前不支持动态创建,所以需要指定为no-provisioner。所以创建PV的过程是不可以省略的。 volumeBindingMode=WaitForFirstConsumer属性也非常重要,这是一种延迟绑定的机制,这种绑定会在调度的时候才去绑定,否则就会引起Pod调度的失败。 接着我们就可以编写一个普通的PVC来使用这个local pv了,这就类似于面向对象的设计,我们只需要修改接口的实现类,就可以动态修改类的表现。]]></content>
      <categories>
        <category>K8S</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>K8S</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习总结-2]]></title>
    <url>%2F2018%2F11%2F10%2Fk8s%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%932-Pod%2F</url>
    <content type="text"><![CDATA[为什么我们需要Pod关于docker容器,我们都知道它的技术原理就是Namespace做隔离,cgroups做限制,rootfs做文件系统,那么k8s为什么又提出了Pod这个概念呢。 我们可以这样理解,容器就是一个特殊的进程,而k8s就类似于操作系统,去调度管理这些特殊的进程,那么k8s就可以比做操作系统。我们知道,在真正的操作系统中,进程并不是孤单的运行,它存在于一个进程组之中,被操作系统有规则的组织在一起。 那么我们可以理解Pod其实就是将操作系统中进程组的概念抽象到了K8s中,因为k8s的设计脱身于borg系统,谷歌的开发者们发现,他们部署的应用,往往都存在进程与进程组的关系,这些应用密切协作,必须部署在一台机器上。而如果没有组这个概念,这种组织关系就难以维护,而Pod就是将操作系统中的进程组的概念映射到了容器中。 关于Pod的一个事实是,Pod只是一个逻辑概念,Pod里的容器共享网络栈并且可以声明共享同一个Volume。 Pod的设计降低了调度的复杂度,考虑这样一种场景:A/B/C三个容器必须要部署在一起,各需要1G内存。现在node1有3G内存,node2有2.5G内存。若A首先初始化,部署到了node2上,那么轮到C就不满足硬件条件而部署失败。那么就必须要将AB两个容器回滚,重新部署到node1上。 这就是一个典型的成组调度没有被妥善处理的例子,虽然有很多可供选择的方案,但谈不上完美,要么造成资源的严重浪费,要么技术难度不是常规团队可以驾驭。而加入了Pod这种概念,Pod是K8s调度的原子单位,调度器是按照Pod的需求而不是容器的需求来进行计算的。根据这种调度方式,上述的例子就会选择node1而不会选择node2进行调度。 Pod除了简化调度模型,还有个更重要的意义就是容器设计模式。 首先要弄清楚Pod的实现原理,Pod的实现需要一个中间容器,叫做infra容器(k8s.gcr.io/pause)。在Pod中,infra会首先被创建,其他容器都是通过join network namespace的方式与infra容器关联在一起。因此对于一个pod中的A B两个容器来说: 可以使用localhost进行通信 Pod的生命周期与infra容器一致,与A B无关 而对于volume的共享,K8s只需要将所有volume的定义都设计在Pod层就好 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: two-containersspec: restartPolicy: Never volumes: - name: shared-data hostPath: path: /data containers: - name: nginx-container image: nginx volumeMounts: - name: shared-data mountPath: /usr/share/nginx/html - name: debian-container image: debian volumeMounts: - name: shared-data mountPath: /pod-data command: [&quot;/bin/sh&quot;] args: [&quot;-c&quot;, &quot;echo Hello from the debian container &gt; /pod-data/index.html&quot;] 所以Pod这种”超亲密关系”容器的设计思想,实际上就是希望当用户想在容器里完成多个应用的时候,应该考虑是不是可以描述为一个pod里的多个容器。 例如应用war包和tomcat容器,可以描述为一个Pod内的多个容器,以组合的方式解决war和tomcat的耦合关系。但是应用与mysql等数据库的关系,不应该描述为一个Pod,我们不能因为应用宕机而造成数据库无法使用,所以应用与数据库要分为两个Pod来部署。]]></content>
      <categories>
        <category>K8S</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>K8S</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习总结-1]]></title>
    <url>%2F2018%2F11%2F10%2Fk8s%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%931-%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[什么是容器容器其实是一种沙盒技术,能够像集装箱一样,把你的应用装起来。应用与应用之间因为有了边界而不至于互相干扰,被装进集装箱的应用,也可以被方便的搬来搬去,这就是paas最理想的状态。 docker是如何修改应用的边界容器的核心技术,就是通过约束和修改进程的动态表现,从而创造出一种边界。对于Docker等大多数容器来说,Cgroups技术是用来制造约束的主要手段,Namespace技术则是用来修改进程视图的主要方式。 Namespace可以视为一个障眼法,一个namespace里的应用都只能看到当前namespace下被cgroups等技术所限制的资源,文件,设备,而对于宿主机或其他不相关的应用,就完全看不到。这就是linux容器最基本的实现原理。所以容器技术其实就是一个特殊即进程而已。 容器与文件系统容器里的应用进程,理应看到一份完全独立的文件系统,这样,他就可以在自己的容器目录下完成操作,完全不受宿主机和其他容器的影响。Docker在处理这个问题的时候使用了mount namespace技术,改变了容器文件系统的挂载点,简单来说可以理解为执行一下操作: 12345cd /var/lib/docker/以容器ID为名称创建一个文件夹,如123cd 123创建一系列文件夹如:etc var lib等待以及所需要的文件内容mount(&quot;/&quot;,&quot;var/lib/docker/123&quot;)即修改文件系统挂载点 这个挂载到容器根目录上,用来为容器进程提供隔离后执行环境的文件系统,就是所谓的容器镜像。他还有个更专业的名字,rootfs(根文件系统) 一个常见的rootfs,通常会包含一些文件目录,如/bin /etc /proc等。rootfs只是一个操作系统所包含的文件、配置、目录,并不包含操作系统内核,所以容器镜像要比一个虚拟机iso小的多,因为虚拟机iso文件包含了操作系统的内核。 除此之外,docker公司做出了一个巨大的创新,就是引入了layer概念,用户每修改一次镜像,都会增量追加一个rootfs,这种做法利用了Union File System技术,即将不同的目录联合挂载到一个目录下,最后我们所看到的文件系统实际上是由多个layer视图叠加显示出来的,一个容器的rootfs实际由三部分组成: 用户所进行的一切操作都是在最上部的rw层进行的,init层是用来存放/etc/hosts、/etc/resolv.conf等信息。因为这些信息属于底层文件系统的一部分,有些场景需要修改这些文件,但是我们对镜像进行提交时又不希望将这些信息一起提交,所以设计了init层。下面的就全部都是只读的镜像层。 当我们创建一个文件时,我们实际上只是在最上层的镜像添加了一个文件,当我们删除一个文件时,实际上创建了一个.wh.foo的文件,这样这个文件就被遮罩了起来。当修改一个文件时,首先会从上到下查找有没有这个文件，找到，就复制到容器层中修改，修改的结果就会作用到下层的文件，这种方式也被称为copy-on-write。]]></content>
      <categories>
        <category>K8S</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>K8S</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rabbitmq常用模式]]></title>
    <url>%2F2018%2F09%2F27%2FRabbitmq%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[RabbitMQ常用模式 迅速消息发送 迅速消息指消息不进行落库,不做可靠性保障 用于非核心消息,例如日志、统计分析 特点是性能高,吞吐量大 代码层面来看就是直接调用rabbitTemplate.convertAndSend方法,不需要消息落库,也不需要监听return or confirm 确认消息发送 消息确认模式是一种非常常见的模式,消息需要落库,生产端需要监听broker的confirm响应。对于异常消息需要定时任务进行补偿。 批量消息发送批量消息是指我们把多条消息放到一个集合里,在一个session中进行提交。一种做法是将数据放在threadLocal中,提交时带上size属性,最重要的是对这一批数据进行合并。这种方式的缺点是消费端不保证可靠性,返回结果无法预期。同时幂等性也是一个大问题。需要进行消息补偿。 延迟消息发送消息延迟推送、定时任务,用于业务削峰限流,降级的异步延迟消息机制 Rabbitmq对延迟队列的支持需要下载插件来完成 安装插件 http://www.rabbitmq.com/community-plugins.html 下载对应版本的rabbitmq_delayed_message_exchange插件,解压缩得到.ez文件,放到plugins文件夹 rabbitmq-plugins enable rabbitmq_delayed_message_exchange 启用插件之后重启rabbitmq-server就可以了 延迟队列的使用非常广泛:例如收货后自动评价功能,优惠券过期等 顺序消息发送 保证顺序消费,必须保证消息投递到一个队列中,并且消费者只能有一个(exclusive模式) 统一提交,保证在同一个会话中 添加消息属性:顺序标记的序号、消息Size属性，进行落库操作 并行进行发送给自身的延迟消息进行后续消费处理 消费者延迟消息,根据会话ID、size进行处理 定时任务进行补偿 消息幂等性消息的幂等性是一个非常重要的特性,是指对于同一个消息,消费者不论消费者接收到多少次这条消息,处理结果都是相同的。 导致非幂等性的原因 可靠性消息投递的机制 Broker与消费者之间网络波动 消费端异常 这里利用的是一个ID路由组件,如果单个数据库当然就不需要了。生产端生成消息并落库,统一批次的消息一定有一个全局唯一的id去标识。那么消费端利用这个ID去插入数据库,根据是否产生主键冲突来判断幂等性。]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rabbitmq与Springboot]]></title>
    <url>%2F2018%2F09%2F22%2FRabbitmq%E4%B8%8ESpringboot%2F</url>
    <content type="text"><![CDATA[SimpleMessageListenerContainerSimpleMessageListenerContainer是一个简单消息监听容器,提供了事务特性的设置,包括事务并发量,回滚以及消息确认,重回队列等绝大部分消费者的设置。 SimpleMessageListenerContainer支持动态修改消费者的配置,可以根据这一特性去自定义rabbitmq管控台。 12345678910111213141516171819202122232425262728293031323334 @Bean public SimpleMessageListenerContainer container(ConnectionFactory factory)&#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(factory); container.setQueues(queue1()); container.setConcurrentConsumers(1); container.setMaxConcurrentConsumers(10); container.setDefaultRequeueRejected(false); container.setAcknowledgeMode(AcknowledgeMode.AUTO); container.setConsumerTagStrategy(new ConsumerTagStrategy() &#123; @Override public String createConsumerTag(String queue) &#123; return queue+&quot;_&quot;+UUID.randomUUID().toString(); &#125; &#125;); //1.接收消息 不灵活&lt;!-- container.setMessageListener(new ChannelAwareMessageListener() &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; String s = new String(message.getBody()); System.out.println(s+&quot;收到消息&quot;); &#125; &#125;);--&gt; // 自定义消费函数 MessageListenerAdapter adapter = new MessageListenerAdapter(new MessageDelegate()); container.setMessageListener(adapter); return container; &#125; public class MessageDelegate &#123; public void handleMessage(byte[] body)&#123; System.out.println(new String(body)+&quot;收到消息&quot;); &#125;&#125; 上面的代码自定义消费者函数,可以看到MessageDelegate就是一个普通类,并没有继承或者实现任何类。那么消息是如何接受的呢?其实这里amqp使用了适配器模式,默认会去你的代理类中调用handleMessage方法,可以通过设置一个方法名来进行自定义。 1adapter.setDefaultListenerMethod(&quot;你的方法名&quot;); 如果不进行配置,默认需要用byte[]作为参数来接收消息,否则会抛出错误。 MessageConvert当我们实现自定义的MessageListenerAdapter后,还有可以配置MessageConvert将byte[]编码为需要的格式,而不仅仅是byte[]。展示几种比较常用的转换类型。 自定义string类型1234567MessageListenerAdapter adapter = new MessageListenerAdapter(new MessageDelegate());adapter.setMessageConverter(new TextMessageConvert());//指定的队列路由到指定的方法 对列名-方法名Map&lt;String,String&gt; map = new HashMap&lt;&gt;();map.put(&quot;queue-1&quot;,&quot;method1&quot;);map.put(&quot;queue-2&quot;,&quot;method2&quot;);adapter.setQueueOrTagToMethodName(map); 这里配置了QueueOrTagToMethodName,通过这样一个map。可以实现这样的效果:queue-1返回的消息会被MessageDelegate.method1方法接收,queue-2的消息会被MessageDelegate.method2方法接收 1234567891011public class TextMessageConvert implements MessageConverter &#123; @Override public Message toMessage(Object object, MessageProperties messageProperties) throws MessageConversionException &#123; return new Message(object.toString().getBytes(),messageProperties); &#125; @Override public Object fromMessage(Message message) throws MessageConversionException &#123; return new String(message.getBody()); &#125;&#125; 代理类 123public void handleMessage(String body)&#123; System.out.println(body+&quot;收到消息&quot;);&#125; 这里我们就可以直接使用String类型接收消息了 json类型123MessageListenerAdapter adapter = new MessageListenerAdapter(new MessageDelegate());Jackson2JsonMessageConverter converter = new Jackson2JsonMessageConverter();adapter.setMessageConverter(converter); 测试 这里需要注意 接收函数的入参需要定义为Map类型 1234567891011public void testJson()&#123; Order o = new Order(); o.setDesc(&quot;test&quot;); o.setId(&quot;1&quot;); o.setName(&quot;apple&quot;); MessageProperties p = new MessageProperties(); p.setContentType(&quot;application/json&quot;); String s = JSON.toJSONString(o); Message message = new Message(s.getBytes(),p); rabbitTemplate.send(&quot;001&quot;,message);&#125; 代理类 123public void handleMessage(Map body)&#123; System.out.println(body+&quot;收到消息-json&quot;);&#125; java 对象12345Jackson2JsonMessageConverter converter = new Jackson2JsonMessageConverter();DefaultJackson2JavaTypeMapper mapper = new DefaultJackson2JavaTypeMapper();mapper.setTrustedPackages(&quot;*&quot;);converter.setJavaTypeMapper(mapper);adapter.setMessageConverter(converter); 可以看到消息体转JAVA对象,就是在json的基础上再进行一次封装。 Test 12345678910111213@Testpublic void testJson()&#123; Order o = new Order(); o.setDesc(&quot;123123&quot;); o.setId(&quot;1&quot;); o.setName(&quot;apple&quot;); MessageProperties p = new MessageProperties(); p.setContentType(&quot;application/json&quot;); p.getHeaders().put(&quot;__TypeId__&quot;,&quot;com.demo.rabbitmq.amqp.entity.Order&quot;); String s = JSON.toJSONString(o); Message message = new Message(s.getBytes(),p); rabbitTemplate.send(&quot;001&quot;,message);&#125; 代理类 123public void handleMessage(Order order)&#123; System.out.println(order+&quot;收到消息 java-type&quot;);&#125; java多对象123456789Jackson2JsonMessageConverter converter = new Jackson2JsonMessageConverter();DefaultJackson2JavaTypeMapper mapper = new DefaultJackson2JavaTypeMapper();Map&lt;String,Class&lt;?&gt;&gt; classMap = new HashMap&lt;&gt;();classMap.put(&quot;order&quot;, Order.class);classMap.put(&quot;package&quot;, Package.class);mapper.setIdClassMapping(classMap);mapper.setTrustedPackages(&quot;*&quot;);converter.setJavaTypeMapper(mapper);adapter.setMessageConverter(converter); Test 1234567891011121314151617181920212223@Testpublic void testMutilPojo()&#123; Order o = new Order(); o.setDesc(&quot;123123&quot;); o.setId(&quot;1&quot;); o.setName(&quot;apple&quot;); Package p = new Package(); p.setContent(&quot;啊啊&quot;); p.setId(&quot;2&quot;); p.setName(&quot;pac&quot;); MessageProperties properties = new MessageProperties(); properties.setContentType(&quot;application/json&quot;); properties.getHeaders().put(&quot;__TypeId__&quot;,&quot;order&quot;); Message m1 = new Message(JSON.toJSONString(o).getBytes(),properties); rabbitTemplate.send(&quot;001&quot;,m1); properties.getHeaders().put(&quot;__TypeId__&quot;,&quot;package&quot;); Message m2 = new Message(JSON.toJSONString(p).getBytes(),properties); rabbitTemplate.send(&quot;001&quot;,m2);&#125; delegate 方法 1234567public void handleMessage(Order pojos)&#123; System.out.println(pojos+&quot;多对象&quot;);&#125;public void handleMessage(Package pojos)&#123; System.out.println(pojos+&quot;多对象&quot;);&#125; 与springboot集成 配置 12345678910111213141516171819spring.rabbitmq.addresses=localhost:5672spring.rabbitmq.virtual-host=/spring.rabbitmq.username=guestspring.rabbitmq.password=guest# 发送端配置spring.rabbitmq.publisher-returns=truespring.rabbitmq.publisher-confirms=true#消息没有被路由到队列会返回给发送者spring.rabbitmq.template.mandatory=true# 消费端配置spring.rabbitmq.listener.simple.acknowledge-mode=manualspring.rabbitmq.listener.simple.default-requeue-rejected=truespring.rabbitmq.listener.simple.concurrency=5spring.rabbitmq.listener.simple.max-concurrency=10 一般来说我们需要设置发送端监听confrim消息和return消息,并且在消费端关闭自动确认和重回队列 发送端 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Componentpublic class RabbitSender &#123; @Autowired private RabbitTemplate template; final RabbitTemplate.ConfirmCallback confirmCallback = new RabbitTemplate.ConfirmCallback()&#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if(ack)&#123; System.out.println(&quot;corr &quot;+correlationData); &#125;else&#123; System.out.println(cause); &#125; &#125; &#125;; final RabbitTemplate.ReturnCallback returnCallback = new RabbitTemplate.ReturnCallback() &#123; @Override public void returnedMessage(org.springframework.amqp.core.Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; System.out.println(message); System.out.println(replyCode); System.out.println(replyText); System.out.println(exchange); System.out.println(routingKey); &#125; &#125;; public void send(Object message, Map&lt;String,Object&gt; properties)&#123; MessageHeaders headers = new MessageHeaders(properties); Message msg = MessageBuilder.createMessage(message, headers); template.setConfirmCallback(confirmCallback); template.setReturnCallback(returnCallback); CorrelationData cd = new CorrelationData(&quot;only id&quot;); template.convertAndSend(&quot;test_sb&quot;,&quot;sb.ex&quot;,msg,cd) ; &#125; public void sendOrder(Order message, Map&lt;String,Object&gt; properties)&#123; template.setConfirmCallback(confirmCallback); template.setReturnCallback(returnCallback); CorrelationData cd = new CorrelationData(&quot;only id&quot;); template.convertAndSend(&quot;order_ex&quot;,&quot;order.1&quot;,message,cd) ; &#125;&#125; 这里可以看到,在发送端不需要任何配置,我们是直接可以发送对象的,这里CorrelationData一定要保证全局唯一。 消费端 123456789101112131415161718192021222324252627@Componentpublic class RabbitConsumer &#123; @RabbitListener(bindings = @QueueBinding( value = @Queue(value = &quot;test_sb&quot;,durable = &quot;true&quot;), exchange = @Exchange(value = &quot;sb_ex&quot;,type = &quot;topic&quot;), key = &quot;sb.#&quot; )) @RabbitHandler public void onMessage(Message message, Channel channel) throws IOException &#123; System.out.println(new String(message.getBody())); long deliveryTag = message.getMessageProperties().getDeliveryTag(); channel.basicAck(deliveryTag,false); &#125; @RabbitListener(bindings = @QueueBinding( value = @Queue(value = &quot;$&#123;rabbitmq.order.queue&#125;&quot;,durable = &quot;true&quot;), exchange = @Exchange(value = &quot;$&#123;rabbitmq.order.exchange&#125;&quot;,type = &quot;topic&quot;), key = &quot;$&#123;rabbitmq.order.routingKey&#125;&quot; )) @RabbitHandler public void onOrderMessage(@Payload Order order, @Headers Map&lt;String,Object&gt; headers, Channel channel) throws IOException &#123; System.out.println(order); channel.basicAck((Long) headers.get(AmqpHeaders.DELIVERY_TAG),false); &#125;&#125; 这里比较核心的部分就是两个注解@RabbitListener和@RabbitHandler。@RabbitListener会自动创建queue,exchange和bingding。第一个RabbitHandler是我们默认的处理方式,第二个RabbitHandler我们将Message分离为两个注解,@Payload表示消息体,@Headers表示头信息。AMQP帮我们进行了封装,不需要我们在进行手动设置。 除此之外,类似队列名,交换机名称等可以通过配置文件进行配置,通过@Value注入,这样比较规范。]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis底层数据结构]]></title>
    <url>%2F2018%2F09%2F18%2Fredis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[redis中常用的数据结构包括String,Hash,List,Set,Sorted Set,每种都有对应的底层C语言结构。如下图所示 12345String : SDSHash : zipList/hashtableList : quickListSet : intSet/hashtableSorted Set : skipList SDS123456struct SDS&lt;T&gt; &#123; T capacity; // 数组容量 T len; // 数组长度 byte flags; // 特殊标识位 byte[] content; // 数组内容&#125; SDS全称为simple dynamic string,由于c语言中的字符串,每次进行len()操作的时候,都要进行遍历,复杂度为O(n),对于单线程的redis来说,O(n)复杂度都是不可接受的,所以在C语言的String基础上改造成了SDS类型。 SDS内部会维护当前content的长度记为len,capacity为容量,&gt;=len。在字符串进行扩展是,redis会分配一部分额外的空间放置频繁的进行扩张 ZipList1234567struct ziplist&lt;T&gt; &#123; int32 zlbytes; // 整个压缩列表占用字节数 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点 int16 zllength; // 元素个数 T[] entries; // 元素内容列表，挨个挨个紧凑存储 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF&#125; 顾名思义,ZipList是一个紧凑的list,用于Hash结构元素较少的时候使用。压缩列表是一块连续的内存空间，元素之间紧挨着存储，没有任何冗余空隙。各个元素之间是双向的连接,配合zltail_offset可以实现从后向前遍历。 但是ZipList也存在局限性,导致它并不适合在大量元素的情况下使用。 由于ZipList是一块连续的内存区域,那么存在一种情况就是添加元素时已经没有地方realloc,那么这时候就需要重新找一块连续的内存进行分配,这时就需要将这块内存全部拷贝到新的地址空间上去。 QuickListList结构早期元素少时用 ziplist，元素多时用linkedlist。但是linkedlist会导致内存碎片化严重,并且linkedlist指针成本很高,所以在zipList和LinkedList的基础上改造成了QuickList。 1234567891011121314151617181920struct ziplist_compressed &#123; int32 size; byte[] compressed_data;&#125;struct quicklistNode &#123; quicklistNode* prev; quicklistNode* next; ziplist* zl; // 指向压缩列表 int32 size; // ziplist 的字节总数 int16 count; // ziplist 中的元素数量 int2 encoding; // 存储形式 2bit，原生字节数组还是 LZF 压缩存储&#125;struct quicklist &#123; quicklistNode* head; quicklistNode* tail; long count; // 元素总数 int nodes; // ziplist 节点的个数 int compressDepth; // LZF 算法压缩深度&#125; 可见QuickList中的每个节点都是一个ZipList,ZipList之间通过指针双向连接。同时QuickList可以进行数据压缩,默认为0即不压缩。为1则表示QuickList首尾不压缩,2则表示就表示 quicklist 的首尾第一个 ziplist 以及首尾第二个 ziplist 都不压缩。 DICDic内部包含了两个hashtable,dict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。 数据量较大的hash以及存储了非整数的set内部都是用了DIC结构,Hashtable和java中的HashTable非常类似。 渐进式rehash与java中的hashTable不同的是,redis中的hashtable使用的是渐进式的rehash,因为redis中的hashtable数据量可能非常大,redis单线程进行复制可能会造成阻塞。一般来说rehash操作会隐藏在一些指令之后,如果没有执行完成,redis会交给后台的定时任务去完成。 扩容/缩容hashtable扩容后会变为原数组的两倍大小。如果Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict_can_resize)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (dict_force_resize_ratio)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。 当元素的个数小于数组大小的10%,就会进行缩容,缩容不需要考虑bgsave。 SkipListredis的sorted list内部使用skipList(跳表)实现。skipList的结构与java中的skipList几乎一致。SkipList首先要求是一个有序的列表,redis 通过set 一个score来实现。拿到这样一个list之后,redis会从list中利用算法均匀的筛选一些元素组成上层list,如此循环,redis中的跳表共有64层。理想情况下,跳表最终会形成如下的形状,也就是一个正态分布图。利用这种结构,redis每次从上到下进行匹配,可已将查询的复杂度从O(n)降低到O(1) intSetinSet是一个整数类型的集合,包括16位整数,32位整数,64位整数类型。个人理解这个结构是某些场景下用来节省空间的。例如set中只有整数类型是,当元素大小可以用16位表示,则这个set的encoding就是int16,当出现有元素必须用32位表示时,那么所有的整数都升级为int32,int64以此类推。但是当你删除了int32的数据,intSet是不会降级为int16的。也就是说只能升级不能降级。当set中出现了非整数类型时,redis使用hashtable代替intSet。 总结redis的底层数据结构,几乎都针对redis本身进行了优化。无论在提高性能还是节省空间上,作者都花了很多功夫。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq高级特性]]></title>
    <url>%2F2018%2F09%2F18%2Frabbitmq%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[消息可靠投递 什么是生产端的可靠性投递 保证消息发出 保证MQ接收到消息 发送端收到MQ的应答 消息补偿机制 方案一:消息落库并设置状态 通过上面的图示很容易理解这种方案的做法。首先要保证在第一步两个入库操作都要成功,这里必定涉及到事务,要做到同时成功,失败则要fail-fast。如果涉及到不同的库或者数据源还可能涉及分布式事务。所以这个设计最大的性能阻塞点就在这里,添加事务就无法应对高并发的场景。 分布式定时任务用来做消息补偿,重跑一些异常状态的消息。这里有一个可能存在一个问题,当一个消息刚发送出去,定时任务就启动了,导致消息重复发送的情况。所以定时任务出了要判断消息状态,还应该对间隔时间做一个限制。例如查询状态=1并且距离更新时间大于一分钟的消息进行补偿重试。 方案二:消息延迟投递,做二次确认,回调检查 上面说了方案一并不适合在高并发的场景下使用,那么方案二就是应对高并发场景下的常用设计。 首先上游业务模块将数据入库并发送到broker的业务队列,同时生成一条deley check消息发送到另一个队列,设置延迟发送时间几秒或几分钟之后 下游业务收到消息并消费后发送confirm消息到broker的一个队列 callback服务收到确认消息,做消息持久化。 当延迟确认消息到来之后,如果数据库中有,则成功,否则要callback服务需要进行rpc调用上游服务再次发送一遍消息 消息幂等性方案一利用唯一ID+指纹码机制,利用数据库主键去重 select count(1) from db where id = 唯一ID+指纹码 好处 实现简单 坏处 存在数据库写入瓶颈 解决方案: 根据id分库分表进行路由 方案二利用redis的原子特性,使用exist 获取这set指令 优点: 性能高 缺点: 考虑是否需要落库,如果落库如何做到数据库和redis的一致。如果不落库,定时同步策略怎样做。而且缓存不可靠 消息投递: confirm/returnconfirm机制 如何开启 channel 上确认开启channel.confirmSelect() 在channel上添加addConfirmListener,监听结果 1234567891011121314151617181920212223242526272829303132public class Producer &#123; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; ConnectionFactory cf = new ConnectionFactory(); cf.setVirtualHost(&quot;/&quot;); cf.setHost(&quot;localhost&quot;); cf.setPort(5672); cf.setNetworkRecoveryInterval(3000); cf.setAutomaticRecoveryEnabled(true); Connection connection = cf.newConnection(); Channel channel = connection.createChannel(); channel.confirmSelect(); channel.addConfirmListener(new ConfirmListener() &#123; @Override public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println(&quot;yes &quot;+deliveryTag); &#125; @Override public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println(&quot;no &quot;+deliveryTag); &#125; &#125;); String exchange = &quot;test_confirm&quot;; String routingKey = &quot;confrim.save&quot;; channel.basicPublish(exchange,routingKey,null,&quot;confirm&quot;.getBytes()); Thread.sleep(10000000); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334public class Consumer &#123; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; ConnectionFactory cf = new ConnectionFactory(); cf.setVirtualHost(&quot;/&quot;); cf.setHost(&quot;localhost&quot;); cf.setPort(5672); cf.setNetworkRecoveryInterval(3000); cf.setAutomaticRecoveryEnabled(true); Connection connection = cf.newConnection(); Channel channel = connection.createChannel(); channel.confirmSelect(); channel.addConfirmListener(new MyConfirmListener()); String exchange = &quot;test_confirm&quot;; String routingKey = &quot;confrim.save&quot;; String queue_name = &quot;confirm_queue&quot;; channel.exchangeDeclare(exchange,&quot;topic&quot;,true); channel.queueDeclare(queue_name,false,false,false,null); channel.queueBind(queue_name,exchange,routingKey); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queue_name,true,qc); while (true)&#123; QueueingConsumer.Delivery delivery = qc.nextDelivery(); System.out.println(delivery.getBody()); &#125; &#125;&#125; return 消息机制Return Listener用于处理一些不可路由的消息 生产者通过exchange和routingkey将消息送到某个队列中去,消费者监听队列即可。 在某些情况下,如果exchange不存在或者routingkey不存在,如果我们需要监听这种不可达的消息,那么就需要return机制 关键配置: Mandatory:如果为true则监听不可达消息。如果为false,则会自动删除消息。默认为false 1234567891011121314151617181920212223242526272829303132public class Producer &#123; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; ConnectionFactory cf = new ConnectionFactory(); cf.setVirtualHost(&quot;/&quot;); cf.setHost(&quot;localhost&quot;); cf.setPort(5672); cf.setNetworkRecoveryInterval(3000); cf.setAutomaticRecoveryEnabled(true); Connection connection = cf.newConnection(); Channel channel = connection.createChannel(); channel.confirmSelect(); channel.addReturnListener(new ReturnListener() &#123; @Override public void handleReturn(int replyCode, String replyText, String exchange, String routingKey, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;reply code&quot;+replyCode); System.out.println(&quot;reply text&quot;+replyText); System.out.println(&quot;exchange&quot;+exchange); System.out.println(&quot;routingKey&quot;+routingKey); System.out.println(&quot;properties&quot;+properties); System.out.println(&quot;body&quot;+new String(body)); &#125; &#125;); String exchange = &quot;test_return&quot;; String routingKey = &quot;return.a&quot;; channel.basicPublish(exchange,routingKey,true,null,&quot;confirm&quot;.getBytes()); Thread.sleep(10000000); &#125;&#125; 1234567891011121314151617181920212223242526272829303132public class Consumer &#123; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; ConnectionFactory cf = new ConnectionFactory(); cf.setVirtualHost(&quot;/&quot;); cf.setHost(&quot;localhost&quot;); cf.setPort(5672); cf.setNetworkRecoveryInterval(3000); cf.setAutomaticRecoveryEnabled(true); Connection connection = cf.newConnection(); Channel channel = connection.createChannel(); String exchange = &quot;test_return&quot;; String routingKey = &quot;return.b&quot;; String queueName = &quot;return&quot;; channel.exchangeDeclare(exchange,&quot;topic&quot;,true); channel.queueDeclare(queueName,false,false,false,null); channel.queueBind(queueName,exchange,routingKey); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName,true,qc); while (true)&#123; QueueingConsumer.Delivery delivery = qc.nextDelivery(); System.out.println(delivery.getBody()); &#125; &#125;&#125; 自定义消费者自定义消费者可以实现更好的解耦,也是更常见的一种编码方式。之前使用的都是mq提供的QueueingConsumer耦合在代码中,现在我们自定义消费者,只要重写handleDelivery方法即可,如果有特殊的需要,可以重写其他方法。 1channel.basicConsume(&quot;test01&quot;, false, new MyConsumer(channel)); 123456789101112131415161718public class MyConsumer extends DefaultConsumer &#123; /** * Constructs a new instance and records its association to the passed-in channel. * * @param channel the channel to which this consumer is attached */ public MyConsumer(Channel channel) &#123; super(channel); &#125; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(consumerTag); System.out.println(envelope.getDeliveryTag()); System.out.println(properties); System.out.println(new String(body)); &#125;&#125; ACK与重回队列对于消息的手动签收可以调用,注意需要将自动签收关闭 basicAck(String deleveryTag,bool mutil) basicNack(String devertyTag,bool multi,bool requeue) 第一个表示确认签收,第二个表示不签收。mutil参数表示是否支持批量签收,requeue参数如果设置为true则表示对于签收失败的消息,可以再次添加到队列的尾部,重新消费,也就是重回队列机制。但是实际上一般都会讲重回队列机制关闭 1channel.basicConsume(queue_name, false, new MyConsumer(channel)); 123456789101112131415161718public class MyConsumer extends DefaultConsumer &#123; private Channel channel; public MyConsumer(Channel channel) &#123; super(channel); this.channel=channel; &#125; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;收到消息 手动签收&quot;); if(true)&#123; channel.basicNack(envelope.getDeliveryTag(),false,false); &#125; channel.basicAck(envelope.getDeliveryTag(),false); &#125;&#125; 消息限流假设一个场景,mq中囤积了上万条消息,当我们启动一个消费端时,巨量的消息瞬间推过来,会将服务压垮。所以消费端需要做限流 rabbitmq提供了qos(服务质量保证)功能,即在非自动确认的消息的前提下,如果有一定数目的消息未被消费,则不能消费新的消息 void basicQos(unit prefetchSize,uShort prefetchCount,bool golable); 第一个参数为消息的大小,一般设置为0不限制就好。 第二个是告诉mq每次推送不要超过n个消息,一旦有n个消息没有ack,则直接将consumer block,直到consumer ack。 第三个参数true/false 表示将限制设置为channle级别还是consumer级别 一定要注意设置为手动ack,不能做自动ack! 123channel.basicQos(0,3,false);channel.basicConsume(&quot;test01&quot;, false, new MyConsumer(channel)); 12345678910111213public class MyConsumer extends DefaultConsumer &#123; private Channel channel; public MyConsumer(Channel channel) &#123; super(channel); this.channel=channel; &#125; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;收到消息 手动签收&quot;); channel.basicAck(envelope.getDeliveryTag(),false); &#125;&#125; TTL消息TTL即time to live(生存时间),rabbitmq支持消息过期,在发送时指定限制时间。同时rabbitmq也支持队列级别的过期时间,从消息入队时间算起,一旦超过队列设置的过期时间,都会删除消息。 从rabbitmq的控制台中我们可以再创建队列的时候设置参数,点击message TTL就可以自动添加,然后设置时间即可,单位是ms。 通过这种设置方式,当队列中的消息,10s内没有被消费,则会被自动清除。 另一种方式是在发送端,通过properties设置,这条消息本身10s内没有被消费则会过期。 123AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration(&quot;10s&quot;).build();channel.basicPublish(exchange,routingKey,properties,&quot;hello mq ack&quot;.getBytes()); 死信队列DLX即Dead-Letter-Exchange。利用DLX,当一条消息在一个队列中变成死信(dead message)后,会被重新publish到另一个exchange,这个exchange就是DLX。 消息变成dead message的情况 消息被拒绝 （basic.reject/basic.nack） requeue=false TTL过期 队列达到最大长度 死信队列设置Exchange : dlx.exQueue : dlx_qroutingKey: # 在队列上添加参数 “x-dead-letter-exchange”:”dlx.ex”,代码如下 12345678910111213141516171819//首先声明普通队列作为死信队列String exchange = &quot;dlx.ex&quot;;String routingKey = &quot;#&quot;;String queue_name = &quot;dlx.q&quot;;channel.exchangeDeclare(exchange,&quot;topic&quot;,true);channel.queueDeclare(queue_name,false,false,false,null);channel.queueBind(queue_name,exchange,routingKey);//声明一个普通队列String t_exchange = &quot;test_dlx.ex&quot;;String t_routingKey = &quot;#&quot;;String t_queue_name = &quot;test_dlx.q&quot;;channel.exchangeDeclare(exchange,&quot;topic&quot;,true);Map&lt;String,Object&gt; arg = new HashMap&lt;&gt;();arg.put(&quot;x-dead-letter-exchange&quot;,exchange);arg.put(&quot;x-message-ttl&quot;,10000);channel.queueDeclare(queue_name,false,false,false,arg);channel.queueBind(queue_name,exchange,routingKey); 通过监听死信队列，10s后test_dlx.q的数据过期,数据会自动发送过来。]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统学习ElasticSearch-分布式架构(5)]]></title>
    <url>%2F2018%2F09%2F08%2FElasticSearch%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84-5%2F</url>
    <content type="text"><![CDATA[ES是一套天生支持分布式的系统,分布式的目的是解决大数据量的问题。但是在我们使用的过程中,并没有对其分布式特性进行特殊配置。这时因为ES对用户隐藏了复杂的分布式机制,包括分片,集群发现,负载均衡,replica,路由,扩容以及reIndex。使得用户通过简单的配置就可以对ES实现开箱即用。但是对于开发人员,我们还是要理解ES隐藏的机制和架构,做到知其然也知其所以然。 ES集群 当ES节点启动后,会通过多播(multi cast)的方式寻找集群中的其他节点,并与之建立联系。在集群中，一个节点被选举成主节点(master node)。这个节点负责管理集群的状态，当群集的拓扑结构改变时把索引分片分派到相应的节点上。 寻找的依据就是配置文件中的 1cluster.name: 默认为elasticsearch。 ES集群的主节点与其他中间件主节点的区别在于,主节点并不会处于一个特殊的地位。用户不需要知道哪个节点是主节点，因为所有操作都可以分发到任意的节点,任何节点都可以将查询语句分发到其他节点,将结果聚合之后再返回给用户。节点之间通过P2P的方式通信,而并非需要主节点进行中转。 集群状态ES集群状态分为red/yellow/green,红色表示存在shard不可用的情况,黄色表示所有shard可用,但有replica不可用,绿色表示所有shard可用,并且replica也可用。 节点失效Master节点会负责监控集群中的其他节点，若节点出现故障,这时就会启动容灾策略。由于节点不可用,其他节点会接管发送到这个节点的请求,同时新的主分片会从replica中选举出来 Shard&amp;Replica 一个index可以有多个shard 每个shard都是一个最小的工作单元,是一个lucence实例，有完整的建立索引处理请求的能力。 增减节点，会触发shard的负载均衡 选举机制ES的选举通过zenDiscovery模块进行,通过ping所有节点获取response过滤出有资格进行选举的节点。然后根据nodeId进行排序,选出nodeId排在第一的节点对它进行投票,如果这个节点本身也选择了自己并且票数达到了n(节点数量)/2+1,那么这次投票就是成功的,否则继续进行。 如何避免脑裂 当集群数量不小于3，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题； 当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。 TransLoglucene索引过程中，数据会首先据缓存在内存中直到达到一个阈值才会写入到磁盘。这就会带来一个风险，如果在写入磁盘前系统崩溃，那么这些缓存数据就会丢失。ES的解决方式与HBase一致,通过预写日志来保证数据可恢复。也就是ES的Translog，每次写操作都会写入一个临时文件translog中，这样如果系统需要恢复数据可以从translog中读取 ES Search分析首先search应区别于对单个文档的操作,search是指对于某种查询条件,对集群中所有节点来进行数据匹配。若一个index被分为N个shard,则至少有N个节点会参与到search中。 ES search数据的过程可以成为query then fetch,找到匹配的文档并抓取。 query在初始查询阶段时，查询会广播到索引中每一个分片副本（主分片或者副分片）。 每个分片在本地执行搜索并构建一个匹配文档的 优先队列。优先队列大小为分页参数 from + size。 QUERY_THEN_FETCH 搜索类型的查询阶段有以下步骤: 客户端发送 search 请求到 Node 3。 Node 3 将查询请求转发到索引的每个主分片或副分片中。 每个分片在本地执行查询，并使用本地的Term/Document Frequency信息进行打分，添加结果到大小为 from + size 的本地有序优先队列中 每个分片返回各自优先队列中所有文档的 ID 和排序值给协调节点，它合并这些值到自己的优先队列，产生一个全局排序后的列表。协调节点广播查询请求到所有相关分片时，可以是主分片或副分片，协调节点将在之后的请求中轮询所有的分片副本来分摊负载。 fetchQuery 阶段知道了要取哪些数据，但是并没有取具体的数据，这就是 fetch 阶段要做的。 Fetch 阶段由以下步骤构成： 协调节点向相关 node 发送 GET 请求 分片所在节点向协调节点返回数据 协调节点等待所有文档被取得，然后返回给客户端 分片所在节点在返回文档数据时，处理有可能的_source 字段以及高亮参数。 参考 https://www.easyice.cn/archives/257 ES 写流程分析 参考 https://www.easyice.cn/archives/180 协调节点负责创建索引,将请求转发到主分片节点 主分片将数据写到本地,转发写副本分片请求,回复协调节点 协调节点将信息返回给客户端]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hbase数据存取过程]]></title>
    <url>%2F2018%2F09%2F08%2FHbase%E6%95%B0%E6%8D%AE%E5%AD%98%E5%8F%96%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Hbase数据存储客户端在提交之前,Hbase client回去请求zk,从mate表中确定要存取regionServer的位置。根据rowKey找到对应的regionServer。拿到地址之后,默认情况下像put、delete这类操作是默认提交的,会直接提交到对应的regionServer上,也可以设置autoflush为false,当到达默认的2M的缓存阈值后才会异步批量提交到服务端。 至此,客户端的操作就完成了 服务端到达服务器之后,首先获取到行锁(RowLock),保证同一行数据操作的互斥。接着把数据写入Hlog(WAL机制),保证数据的可靠性。接着将数据写入memstore。完成这一系列操作之后,释放行锁和共享锁。 接着,HlogSyncer线程会异步将Hlog写到Hdfs,memsotre如果大于阈值会异步刷写为storefile,默认为64M。直到storefile的数量大于阈值,会进行compaction操作,将多个storefile合并为一个大的storefile,同时进行版本合并和数据删除。但是storefile可能会无限的增长,当大于某一个阈值之后,会触发split操作。将当前的region split为两个region,并通知Master,HMaster会分配新生成的两个region的位置,有可能会分配到其它regionServer上,保证负载均衡。 至此,服务端的操作也就完成了。 HBase数据获取客户端同上 服务端regionServer接到客户端的Get或者Scan请求会做两件事情。首先构建scanner体系:首先在确定的region上构建一个regionScanner,准备检索。region会根据列族构建storeScanner,再去根据Hfile的数量构建StoreFileScanner去文件上执行检索。同时会对memstore构建一个memstoreScanner。通过这样的检索,就找到了KV结构的数据,接着封装为ResultSet返回客户端。 Hbase优化策略服务端优化 jvm与gc配置 hbase-site.xml配置 hbase.hregion.majorcompaction建议设置为0,因为在生产环境中这个周期会持续几个小时,可以手动写脚本在业务低峰的时候执行。 Hbase常用优化 预先分区 Column优化 rowkey优化 schema优化 预先分区创建Hbase表的时候会自动创建一个region分区,而region的split操作是十分耗时的而且会阻塞其他动作,造成无法访问。我们可以在创建Hbase表的时候预先创建一些空的region,指定不同的rowkey分配到不同的region。除此之外,预先分区还可以解决数据倾斜的问题,将访问量大的数据放到一个region,访问量少的放在一个region Rowkey优化 利用HBase默认排序的特点,将一起访问的数据放到一起。 防止热点问题,避免使用时序或者单调增减 尽可能短 Column优化 列族的名称和列的描述尽量短 同一张表中的CF尽量不要超过3个 schema优化 宽表: 列多行少的设计 高表: 列少行多的设计 对于查询来说,高表的性能更好,高表的元数据开销比较大。由于Hbase的事务是建立在行上,所以宽表的事务性更好。 Hbase写优化策略Hbase写数据的流程为:数据先写入memstore,再写入Hlog。当memstore里面的数据达到一定的阈值之后会将memstore里面的数据flush到hdfs上的hfile中。当我们使用开发的程序执行写入操作的时候,我们需要考虑: 同步批量提交or异步批量提交 WAL优化(默认开启,表示写入memstore的同时也要写入hfile),也就是说我们的业务能否忍受当发生异常的时候,部分数据丢失。如果我们需要更高的吞吐量,则可以将WAL关闭。 Hbase读优化策略 客户端: scan缓存设置,批量获取数据 服务端: BlockCache配置是否合理,Hfile是否过多]]></content>
      <categories>
        <category>Hbase</category>
      </categories>
      <tags>
        <tag>Hbase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hbase基础]]></title>
    <url>%2F2018%2F09%2F07%2FHbase%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[简介Hbase是一个分布式的、面向列的开源数据库 Hbase在Hadoop之上提供了类似于Bigtable(源自google,建立在GFS之上)的能力 Hbase适合存储非结构化数据 列是数据库是什么 可以看到,列式数据库和传统的关系型数据库相比,旋转了90度,将关系型数据库的一列保存为一行。列式存储的主要优点之一就是可以大幅降低系统的I/O，尤其是在海量数据查询时,因为对一列的查询时一个连续的物理空间。行式更适合OLTP，比如传统的基于增删改查操作的应用。列式更适合OLAP，非常适合于在数据仓库领域发挥作用，比如数据分析、海量存储和商业智能；涉及不经常更新的数据。 Hbase和HDFSHbase建立在Hadoop文件系统之上,利用了Hadoop系统的容错能力 Hbase提供对数据随机实时读写访问 Hbase内部使用哈希表,并存储索引,可将在HDFS文件中的数据进行快速查找 ###Hbase使用场景 瞬间写入量很大,使用关系型数据库成本很高 数据需要长久保存,并且持续增长 不涉及join,多级索引或复杂表操作 Hbase基本概念 NameSpace: 可以理解为RDBMS的数据库 Table: 表,表名必须是一个文件路径中的合法名字 Row: 在表中,每一行代表一个数据对象,每一个行有唯一行键(Row Key)来进行唯一标示,以二级制字节来存储,不可变。 Column: Hbase的列由Column Family和Column qualifier组成,由冒号:进行间隔。Column Family是列的集合,Column Family一经定义便不可变,但其中包含的column可以动态添加或删除。Column qualifier可以理解为列名。 基础架构 简单搭建一个伪分布式的Hbase,其中Hmaster、HRegionServer和HQuorumPeer(zookeeper)属于hbase系统,依次看一下作用 HMasterHMaster是hbase主从集群架构中的中央节点,用于将region分配给RegionServer,协调regionServer负载并维护集群的状态。region就是Hbase中存储的最小单元.Hmaster还负责维护表和region的元数据,不参与数据的输入输出过程 RegionServer维护HMaster分配的region,处理这些region的io请求,并且对运行过程中增大的region进行切分 ZookeeperHbase集群的协调器,保存Hbase的一个mate信息,维护hbase regionserver的状态信息 HBase存储设计Log Structured Merge Trees （LSM）LSM是日志结构合并树,它是由两个或两个以上存储数据的结构组成。每个数据结构各自对应一种存储介质。简易LSM由两个树状结构组成。分别为C0、C1。 C0比较小,并全部存储于内存之中,而C1存储于磁盘上。当有数据时,先插入到C0中,如果这一次C0的插入超过了阈值,C0中的数据片段会刷写到C1上。一般来说,第一层是以快速读写为目标,第二层提供持久化,可以继续扩展第三层,作用是对第二层的持久化文件进行合并拆分。 LSM在Hbase中的体现 当数据到达regionServer,数据并不会直接写到硬盘之中,为了加速随机读写。而是写到log和memstore中,写日志是因为内存中的数据易丢失不稳定。 当memsotre的数据超过阈值,后台线程会将这部分数据flush到磁盘,生成storefile 系统不断刷写会产生很多小文件,这样不利于查询和读写。在某一时刻,hbase会将这些小文件合并为一个大文件，也就是一个多路归并算法。 Hbase各级组织模块 RegionServer包含多个Hregion,Hregion是我们可见的存储数据的最小单元。每个region包含的数据都是互斥的。 每个Region包含多个store,Store对应Hbase表的列族。每个store都包含一个memstore,它是一个内存式的数据结构。Memstore满了之后写到storefile中,最后会将storefile刷写成hdfs上的hfile文件。 每个regionServer都有一个Hlog实例,用于实现WAL。HLog+Memstore构成了Hbase LSM的第一层结构。storefile+hfile构成了第二次结构,实现了不可靠数据的持久化。 Hbase Region解析 每个Region都存在于一个确定的RegionServer上,Hbase表在行键的方向上分割为多个Region,是Hbase分布式存储的最小单元。并且Hbase保证了一行数据只可能在一个region上。当列族的大小到达一定的阈值,一个region会被分为两个region,region在regionServer运行过程中会出现移动,当一个regionServer挂掉,Hmaster会将这些region分配到其它regionServer上去。每个region都有三个参数标识:表名、startRowKey、createTime(最早的数据插入时间)。总结如下: region 是Hbase负载均衡和分布式存储的最小单元，并不是存储的最小单元 region 的数量太多性能就会下降,太少就会降低并行能力(region数量不要低于hbase节点数量) region 的分割操作是不可见的,做法是先将这个region下线,然后将子region加入到meta信息中, 然后加入原有的region,最后同步到master HFile解析HFile是Hbase存储数据的最基本组织形式,底层是Hadoop的二进制格式文件。 Hfile可以分为四个部分: scanned block: 用户数据存储区域 Nonscanned block: 元数据区 Load on open: regionServer启动时加载到内存,主要是Hfile的元数据 trailer: 记录了Hfile的基本信息,各部分的偏移量,寻址信息,也可以理解为元数据的一部分 用户的数据真正存储于scanned block区域中的data block中,Data block是一种key-value的结构 可以看出key的结构非常复杂,通过rowkey+cf+cq+timestamp+keyType才能唯一确定一个value值 WAL数据写入时首先会在Hlog中记录一条日志,然后在写入memstore内存中 WAL即预写日志,最重要的功能就是灾难恢复。用于恢复那些写入memstore但没有来得及flush到磁盘就丢失的数据。 compactioncompaction即从一个hregion的store中选取一些storefile文件进行合并。先从待合并的文件中读取key-value数据,在按照rowkey从小到大排序写到一个新的文件,新的文件就会替代合并的文件向外提供服务。 为什么会有compaction这样的机制呢,因为文件过多会降低查询的效率并且不易维护。 compaction分为两类: minor compaction和major compaction。 minor compaction是指合并一些临近的较小的storefile为一个较大的storefile major compaction是指将所有的storefile合并为一个大的storefile,在这个过程中还会执行一些清理操作 将那些标记为删除的数据进行物理删除 删除ttl过期的数据 版本号超过最大版本的数据 compaction触发时机 memstore flush数据到storefile,文件数量到达阈值会触发 后台线程(compaction checker)周期性检查，首先会判断文件数量是否达到阈值,之后会检查是否达到一个设定的合并时间范围,默认为[7-7*0.2,7+7*0.2]，也就是周期性的进行大合并。]]></content>
      <categories>
        <category>Hbase</category>
      </categories>
      <tags>
        <tag>Hbase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(10) Netty中的性能调优]]></title>
    <url>%2F2018%2F07%2F22%2FNetty-10-Netty%E4%B8%AD%E7%9A%84%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[单机百万调优 如何模拟百万连接 如何突破局部文件句柄的限制 如何突破全局文件句柄的限制 首先第一个问题,当我们启动一个服务端,我们会绑定一个端口。当客户端去连接,默认连接数是有限制的,是65535,并且1024以下只能被root使用,所以单机只有6W左右的连接可以介入。所以可以采取的办法就是服务端开启8000-8100共100个端口,客户端使用1025~65535去连接服务端。100*6w大约600W连接。 代码 服务端 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class MillionServer &#123; public static void main(String[] args) &#123; &#125; private static void start(int start,int n)&#123; System.out.println(&quot;opening&quot;); EventLoopGroup boss = new NioEventLoopGroup(); EventLoopGroup worker = new NioEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(boss,worker); bootstrap.channel(NioServerSocketChannel.class); bootstrap.childOption(ChannelOption.SO_REUSEADDR,true); bootstrap.childHandler(new ConnectionCountHandler()); for(int i=0;i&lt;n;i++)&#123; int port = start+i; bootstrap.bind(port).addListener((ChannelFutureListener)future -&gt; &#123; System.out.println(&quot;connection &quot;+port); &#125;); &#125; System.out.println(&quot;start&quot;); &#125;&#125;public class ConnectionCountHandler extends ChannelInboundHandlerAdapter &#123; private AtomicInteger conn = new AtomicInteger(); public ConnectionCountHandler()&#123; Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(()-&gt;&#123; System.out.println(&quot;count&quot;+conn.get()); &#125;,0,2, TimeUnit.SECONDS); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; conn.getAndIncrement(); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; conn.getAndDecrement(); &#125;&#125; 客户端 123456789101112131415161718192021222324252627282930313233343536public class Client &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; EventLoopGroup worker = new NioEventLoopGroup(); final Bootstrap bootstrap = new Bootstrap(); bootstrap.group(worker); bootstrap.channel(NioSocketChannel.class); bootstrap.option(ChannelOption.SO_REUSEADDR,true); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; &#125; &#125;); int index = 0; int port; while (!Thread.interrupted())&#123; port = 8000+index; ChannelFuture future = bootstrap.connect(&quot;localhost&quot;, port); future.addListener((ChannelFutureListener)future1 -&gt;&#123; if(!future1.isSuccess())&#123; System.out.println(&quot;bye&quot;); System.exit(0); &#125; &#125; ); future.get(); if(++index==100)&#123; index=0; &#125; &#125; &#125;&#125; 将代码打包后成jar放在两台服务器上运行 1-Xms6.5G -Xmx6.5G -xx newSize5.5G -xx:MaxDirectMemorySize=1g 将项目启动后,可以发现连接数到800左右就已经停止服务 突破连接数限制在linux下执行 ulimit -n 可以查看系统支持单个进程打开的最大文件句柄数 要突破这个限制修改配置文件 vim /etc/security/limits.conf 末尾添加 hard nofile 1000000 soft nofile 1000000 接着我们重新启动服务,发现连接数可以增加到9000左右,比之前的几百高了十倍。 突破全局文件句柄限制 cat /proc/sys/fs/file-max vim /etc/sysctl.conf 在文件末尾添加 fs.file-max = 1000000 sysctl -p 经过这样一番折腾,应该能达到90W左右,可能会受限于本机的配置。 应用性能调优12345678910public class BuzHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt;&#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception &#123; ByteBuf data = Unpooled.directBuffer(); data.writeBytes(msg); //耗时业务处理 Object res = data; ctx.pipeline().writeAndFlush(res); &#125;&#125; 1假设有这样一个业务handler,我们定位到耗时的业务处理代码,这时我们可以使用线程池来提高性能 12345678910111213141516public class BuzHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt;&#123; private static ExecutorService threadPool = Executors.newFixedThreadPool(1000); @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception &#123; ByteBuf data = Unpooled.directBuffer(); data.writeBytes(msg); //耗时业务处理 threadPool.submit(()-&gt;&#123; Object res = data; ctx.pipeline().writeAndFlush(res); &#125;); &#125;&#125; 2如果不想手动创建线程池,Netty同样支持将业务代码放入NioEventLoop中执行 12NioEventLoopGroup buz = new NioEventLoopGroup(1000);socketChannel.pipeline().addLast(buz,new BizHandler()); 虽然这样做看起来代码更简洁,但是业务逻辑中如果有分配buffer的代码,这样做就会造成将buffer分配到业务线程中,所以在性能要求高的地方还是推荐第一个种。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(9) Netty中的设计模式]]></title>
    <url>%2F2018%2F07%2F22%2FNetty-9-Netty%E4%B8%AD%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例 一个类全局只有一个对象 延迟加载 线程安全 ReadTimeOutException 12345678public final class ReadTimeoutException extends TimeoutException &#123; private static final long serialVersionUID = 169287984113283421L; public static final ReadTimeoutException INSTANCE = new ReadTimeoutException(); private ReadTimeoutException() &#123; &#125;&#125; 这里通过private修饰保证了全局只有一个实例 当我们没有使用到这个类的时候,static变量保证了它是不会被初始化的,这样就保证了延迟加载 最后我们注意到这个class 使用final修饰的,这样在初始化的时候jvm会默认加上一个同步代码块,保证线程安全 策略模式 封装一系列可替换的算法家族 支持动态选择某个策略 1234567public EventExecutorChooser newChooser(EventExecutor[] executors) &#123; if (isPowerOfTwo(executors.length)) &#123; return new PowerOfTowEventExecutorChooser(executors); &#125; else &#123; return new GenericEventExecutorChooser(executors); &#125;&#125; 这里根据executors的长度选择不同的chooser策略。 装饰者模式 装饰者和被装饰者继承同一个接口 装饰者给被装饰者动态修改行为 一般来说使用装饰者模式都会有wrap关键字,Netty也不例外,比如WrappedByteBuf 在构造这个对象的时候,会传入一个被装饰者ByteBuf,WrappedByteBuf最终会被委托到ByteBuf的方法中。WrappedByteBuf算是ByteBuf的一个装饰基类,基本都是直接调用了ByteBuf的方法,接着ByteBuf有子类UnreleasableByteBuf、AdvancedLeakAwareByteBuf、SimpleLeakAwareByteBuf。 以SimpleLeakAwareByteBuf为例 1234567public boolean release() &#123; boolean deallocated = super.release(); if (deallocated) &#123; leak.close(); &#125; return deallocated;&#125; 首先调用了父类的release方法,接下来的代码就是一些装饰的作用,也就是在原有方法上额外做的一些工作。 观察者模式 观察者和被观察者 观察者订阅消息,被观察者发布消息 订阅消息才可以收到消息 Netty中最常见的观察者模式就是channelFuture.addListener() 责任链模式 责任处理器接口 创建添加责任处理器接口 上下文 责任终止 通过上面的描述,大家肯定都能猜到这是pipeline,责任链的每个节点就是hanlder。责任处理则是我们每次复写类所完成的方法,pipeline的头尾有head和tail节点以保证事件传播的终止。ChannelHandlerContext则负责保存上下文信息。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(8) 性能优化工具类]]></title>
    <url>%2F2018%2F07%2F09%2FNetty-8-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[Netty中有两个比较常见的优化工具类 FastThreadLocal Recycler对象池 12345678910111213141516171819public class FastThreadLocalTest &#123; private static FastThreadLocal&lt;Object&gt; threadLocal = new FastThreadLocal&lt;Object&gt;()&#123; @Override protected Object initialValue() throws Exception &#123; return new Object(); &#125; &#125;; public static void main(String[] args) &#123; new Thread(()-&gt;&#123; Object o = threadLocal.get(); System.out.println(o); &#125;).start(); new Thread(()-&gt;&#123; Object o = threadLocal.get(); System.out.println(o); &#125;).start(); &#125;&#125; 通过这个简单的test,多次打印object的内存地址,就会发现一个object被多次复用。 FastThreadLocal机制FastThreadLocal创建123456public FastThreadLocal() &#123; index = InternalThreadLocalMap.nextVariableIndex();&#125;private final int index;int index = nextIndex.getAndIncrement(); FastThreadLocal的初始化只有一行代码,设定了一个final的index值,并且这个值是通过一个原子类进行赋值的。当第一个次初始化时index=0,第二次index=1…通过index便可以唯一标识一个FastThreadLocal。 FastThreadLocal get()123获取ThreadLocalMap直接通过索引取出对象初始化 首先判断当前线程是否是FastThreadLocalThread,如果是则执行fastGet,通常情况下我们初始化一个线程都是使用的普通线程,所以先进入slowGet,slowGet方法就是通过JDK的ThreadLocal获取变量 12345678public static InternalThreadLocalMap get() &#123; Thread thread = Thread.currentThread(); if (thread instanceof FastThreadLocalThread) &#123; return fastGet((FastThreadLocalThread) thread); &#125; else &#123; return slowGet(); &#125;&#125; 如果是Netty创建的FastThreadLocalThread,它的内部维护了一个变量InternalThreadLocalMap,这样每次取数据的时候就是去它自己的成员变量里面去取,这也是fast和slow的区别 1234567private static InternalThreadLocalMap fastGet(FastThreadLocalThread thread) &#123; InternalThreadLocalMap threadLocalMap = thread.threadLocalMap(); if (threadLocalMap == null) &#123; thread.setThreadLocalMap(threadLocalMap = new InternalThreadLocalMap()); &#125; return threadLocalMap;&#125; 紧接着,由于每个FastThread都有一个index唯一标识,那么通过这个标识,可以直接拿到当前线程对应的ThreadLocalMap。ThreadLocalMap是一个一维数组,index就是这个一位数组的一个下标,通过这个下表可以拿到这个线程的对象。 1Object v = threadLocalMap.indexedVariable(index); FastThreadLocal set()set的方法比较简单,核心就是下面一句。将index对应的数组下表的值设置为value 123456789public final void set(InternalThreadLocalMap threadLocalMap, V value) &#123; if (value != InternalThreadLocalMap.UNSET) &#123; if (threadLocalMap.setIndexedVariable(index, value)) &#123; addToVariablesToRemove(threadLocalMap, this); &#125; &#125; else &#123; remove(threadLocalMap); &#125;&#125; 轻量级对象池Recycler一个简单的demo看一下Recycler的使用。 123456789101112131415161718192021222324public class RecyclerTest &#123; private static final Recycler&lt;Users&gt; RECYCLER = new Recycler&lt;Users&gt;() &#123; @Override protected Users newObject(Handle&lt;Users&gt; handle) &#123; return new Users(handle); &#125; &#125;; private static class Users&#123; private final Recycler.Handle&lt;Users&gt; handle; public Users(Recycler.Handle&lt;Users&gt; handle) &#123; this.handle = handle; &#125; public void recycle()&#123; handle.recycle(this); &#125; &#125; public static void main(String[] args) &#123; Users u = RECYCLER.get(); u.recycle(); Users u2 =RECYCLER.get(); System.out.println(u==u2); &#125;&#125; 创建Recycler的作用是每次创建对象的时候不需要每次都new出来,如果Recycler有这个对象,那么就从Recycler里面取出来重用,不需要这个对象的时候,就放回Recycler。 可以看到每个Recycler都维护了一个Stack对象 123456789101112131415161718192021private final FastThreadLocal&lt;Stack&lt;T&gt;&gt; threadLocal = new FastThreadLocal&lt;Stack&lt;T&gt;&gt;(); private final FastThreadLocal&lt;Stack&lt;T&gt;&gt; threadLocal = new FastThreadLocal&lt;Stack&lt;T&gt;&gt;() &#123; @Override protected Stack&lt;T&gt; initialValue() &#123; return new Stack&lt;T&gt;(Recycler.this, Thread.currentThread(), maxCapacityPerThread, maxSharedCapacityFactor, ratioMask, maxDelayedQueuesPerThread); &#125; &#125;; Stack(Recycler&lt;T&gt; parent, Thread thread, int maxCapacity, int maxSharedCapacityFactor, int ratioMask, int maxDelayedQueues) &#123; this.parent = parent; this.thread = thread; this.maxCapacity = maxCapacity; availableSharedCapacity = new AtomicInteger(max(maxCapacity / maxSharedCapacityFactor, LINK_CAPACITY)); elements = new DefaultHandle[min(INITIAL_CAPACITY, maxCapacity)]; this.ratioMask = ratioMask; this.maxDelayedQueues = maxDelayedQueues; &#125; 可以看到stack都与当前线程绑定,每个handle就是我们回收的对象,radioMask控制对象的回收比例,也就是说并不是每个对象都可以回收。maxCapacity表示栈的最大容量。maxDelayedQueues比较特殊,表示有多少个其他线程可以缓存这个对象,当我们在其他线程中需要销毁这个对象时,并不会直接跨线程去销毁,而是把这个对象添加到weakOrderQueue中去做销毁 获取123456789101112public final T get() &#123; if (maxCapacityPerThread == 0) &#123; return newObject((Handle&lt;T&gt;) NOOP_HANDLE); &#125; Stack&lt;T&gt; stack = threadLocal.get(); DefaultHandle&lt;T&gt; handle = stack.pop(); if (handle == null) &#123; handle = stack.newHandle(); handle.value = newObject(handle); &#125; return (T) handle.value;&#125; 首先判断当前线程maxCapacityPerThread,如果为0,则表示当前线程不能回收对象,所以直接创建返回。 下面从当前线程中获取stack,接着pop拿出一个对象。如果这个对象为null,表示当前stack为空,new一个对象,然后将对象关联到这个hanlde,返回handle。 我们可以进入pop()方法,大部分代码都是常规的stack的pop操作,有一个方法scavenge(),这个方法功能是:如果当前栈为空,那么这个对象可能在其他线程中正在等待删除,那么就去这些线程中看一下是否有这种情况,如果有则取消它的销毁状态,将对象拿回来。 回收对象的回收要考虑两种情况 同线程的对象回收 异线程的对象回收 对象的回收最终会调用到stack.push(obj)方法 1234567891011void push(DefaultHandle&lt;?&gt; item) &#123; Thread currentThread = Thread.currentThread(); if (thread == currentThread) &#123; // The current Thread is the thread that belongs to the Stack, we can try to push the object now. pushNow(item); &#125; else &#123; // The current Thread is not the one that belongs to the Stack, we need to signal that the push // happens later. pushLater(item, currentThread); &#125;&#125; 首先会去判断当前线程是否是创建这个stack的线程,如果是则执行pushNow 同线程回收 12345678910111213141516private void pushNow(DefaultHandle&lt;?&gt; item) &#123; if ((item.recycleId | item.lastRecycledId) != 0) &#123; throw new IllegalStateException(&quot;recycled already&quot;); &#125; item.recycleId = item.lastRecycledId = OWN_THREAD_ID; int size = this.size; if (size &gt;= maxCapacity || dropHandle(item)) &#123; // Hit the maximum capacity or should drop - drop the possibly youngest object. return; &#125; if (size == elements.length) &#123; elements = Arrays.copyOf(elements, min(size &lt;&lt; 1, maxCapacity)); &#125; elements[size] = item; this.size = size + 1;&#125; 这里将回收的对象设定了一个OWN_THREAD_ID,表示在整个Recycler中是唯一的。接着判断stack是否已经满了,满了则丢弃,由于Recycler并不会一开始就创建maxSize这么大的数组,如果判断当前size不足,则扩容为原来的两倍,将对象放进去。 异线程回收 12345678910111213141516171819202122private void pushLater(DefaultHandle&lt;?&gt; item, Thread thread) &#123; Map&lt;Stack&lt;?&gt;, WeakOrderQueue&gt; delayedRecycled = DELAYED_RECYCLED.get(); WeakOrderQueue queue = delayedRecycled.get(this); if (queue == null) &#123; if (delayedRecycled.size() &gt;= maxDelayedQueues) &#123; // Add a dummy queue so we know we should drop the object delayedRecycled.put(this, WeakOrderQueue.DUMMY); return; &#125; // Check if we already reached the maximum number of delayed queues and if we can allocate at all. if ((queue = WeakOrderQueue.allocate(this, thread)) == null) &#123; // drop object return; &#125; delayedRecycled.put(this, queue); &#125; else if (queue == WeakOrderQueue.DUMMY) &#123; // drop object return; &#125; queue.add(item);&#125; 首先获取WeakOrderQueue,这个数据结构就存储了需要释放的在其他线程中存储的对象。如果要回收的对象的线程之前没有绑定过,则创建一个weakOrderQ与之绑定,否则直接将对象插入队列 总结FastThreadLocal主要解决变量的线程隔离 问题。Recycler则是解决频繁创建大对象的问题,减少YoungGC,但是如果对象很小,创建频率不高可能得不偿失]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(7) 编码]]></title>
    <url>%2F2018%2F07%2F08%2FNetty-7-%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[一个问题 Netty如何将对象编码成字节流,写到socket底层 这里我们在 服务端添加两个handler 123456789101112131415161718192021new Encoder();new BizHandler();public class BizHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; User u = new User(&quot;sc&quot;,12); ctx.channel().writeAndFlush(u); &#125;&#125;public class Encoder extends MessageToByteEncoder&lt;User&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, User user, ByteBuf out) throws Exception &#123; byte[] bytes = user.getName().getBytes(); out.writeInt(4+bytes.length); out.writeInt(user.getAge()); out.writeBytes(bytes); &#125;&#125; 这里的Encode方法使用了如下的编码方式:第一个字段为正整数长度,在java平台上统一为4字节,第二个Age正整数,为4个字节,Name是可变长度的string类型。 1234567/** * ------------------------- * | Length | Age | Name| * --------------------------- * | 4 | 4 | ?? | * -------------------------- */ writeAndFlush抽象步骤123从tail节点向前传播逐个调用channelHandler的wirite方法 逐个调用channelHandler的flush方法 首先进入writeAndFlush方法,定位到 1tail.writeAndFlush(msg); 可见这个方法是从pipeLine的tail节点开始传播,接着调用write方法,判断该线程是否是eventLoop里面的线程,如果是则执行,否则封装成task扔进队列中。 1executor.inEventLoop() 接着会调用,也就是说如果我们自定义的handler实现了write方法,则会进行调用,但是我们在encoder类中实现的是一个encode方法。这时因为Encoder继承自MessageToByteEncoder,而父类的write方法调用了encode方法,所以我们只需要重写encode方法即可。最终会传播到头结点的write方法:unsafe.write(msg, promise); 1((ChannelOutboundHandler) handler()).write(this, msg, promise); 接着会进行flush操作,因为一般我们自定义的handler很少会去复写handler方法,所以大部分情况下它会一直传播到头结点。并最终调用unsafe.flush(); 1((ChannelOutboundHandler) handler()).flush(this); HeadContext.write()123direct化byteBuf插入写队列设置写状态 首先对于传入的msg调用此方法,这个方法首先会判断是否是ByteBuf,如果是directBuffer则直接返回,如果是heapBuff则包装成DirectBuf 12345678910msg = filterOutboundMessage(msg);if (msg instanceof ByteBuf) &#123; ByteBuf buf = (ByteBuf) msg; if (buf.isDirect()) &#123; return msg; &#125; return newDirectBuffer(buf);&#125; 接着将buf加入到写队列中,这里可以看到是三个Entry:tailEntry/flushedEntry/unflushedEntry,可以理解为三个指针。 12345678910111213141516171819outboundBuffer.addMessage(msg, size, promise);public void addMessage(Object msg, int size, ChannelPromise promise) &#123; Entry entry = Entry.newInstance(msg, size, total(msg), promise); if (tailEntry == null) &#123; flushedEntry = null; tailEntry = entry; &#125; else &#123; Entry tail = tailEntry; tail.next = entry; tailEntry = entry; &#125; if (unflushedEntry == null) &#123; unflushedEntry = entry; &#125; incrementPendingOutboundBytes(size, false); &#125; 三个指针的排列状况如下:把队列分为了两个部分,前面一个部分表示已经flush过得数据,后面一部分表示没有flush过得数据。 1Entry(flushedEntry) --&gt; ... Entry(unflushedEntry) --&gt; ... Entry(tailEntry) 最后是设置写状态,每次添加数据之后,Netty都要统计一个有多少数据需要写出。这里会比较一个buffer水位值getWriteBufferHighWaterMark(),默认是64K。如果超过这个值,就会在pipeline中传播一个无法写入的状态。 12345678910private void incrementPendingOutboundBytes(long size, boolean invokeLater) &#123; if (size == 0) &#123; return; &#125; long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size); if (newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()) &#123; setUnwritable(invokeLater); &#125;&#125; HeadContext.flush()123添加刷新标志并设置写状态遍历buffer队列,过滤ByteBuf调用jdk的api写入 进入到addFlush方法,首先将当前指向为flushedEntry标记为已刷新。接着decrementPendingOutboundBytes会减去flush的数据的大小,直到空间小于默认的32K时,pipeline会传播一个可写的状态。 123456789101112131415Entry entry = unflushedEntry; if (entry != null) &#123; if (flushedEntry == null) &#123; flushedEntry = entry; &#125; do &#123; flushed++; if (!entry.promise.setUncancellable()) &#123; int pending = entry.cancel(); decrementPendingOutboundBytes(pending, false, true); &#125; entry = entry.next; &#125; while (entry != null); unflushedEntry = null; &#125; 接着进入flsuh0的doWrite方法,通过一个for循环,通过in.current()每次拿到一个flushedEntry 1Object msg = in.current(); 这里Netty获取一个自旋锁,默认为16.通过自旋锁提高内存的使用率并提高吞吐量 1writeSpinCount = config().getWriteSpinCount(); 接着将Netty的ByteBuf塞进jdk的ByteBuffer里面,调用JDK的write方法 123456789ByteBuffer tmpBuf; if (internal) &#123; tmpBuf = internalNioBuffer(); &#125; else &#123; tmpBuf = memory.duplicate(); &#125; index = idx(index); tmpBuf.clear().position(index).limit(index + length); return out.write(tmpBuf);]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(6) 解码]]></title>
    <url>%2F2018%2F07%2F07%2FNetty-6-%E8%A7%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[所谓解码,就是讲二进制数据流解析为指定协议的数据包,之后交给业务逻辑进行处理。 两个问题 解码器抽象的解码过程 Netty有哪些开箱即用的解码器 基类ByteToMessageDecoder123累加字节流调用子类的decode方法进行解析将解析的ByteBuf向下传播 进入channelRead方法,这里将传入的数据包装为bytebuf然后交给cumulator,将数据进行累加。然后调用callDecode方法,利用不同的子类实现进行解析,将解析后的结果放在List out中 123cumulation = cumulator.cumulate(ctx.alloc(), cumulation, data);callDecode(ctx, cumulation, out); 基于固定长度解码器FixedLengthFrameDecoder是Netty中最为简单的一个解码器,他只有一个成员变量frameLength,这个解码器只能根据指定的长度来对数据进行解码。 123456789101112131415protected final void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; Object decoded = decode(ctx, in); if (decoded != null) &#123; out.add(decoded); &#125;&#125;dprotected Object decode( ChannelHandlerContext ctx, ByteBuf in) throws Exception &#123; if (in.readableBytes() &lt; frameLength) &#123; return null; &#125; else &#123; return in.readRetainedSlice(frameLength); &#125;&#125; 这里的in就是父类中的累加器,这里的decode方法判断如果累加器传入的数据长度小于frameLength,则不进行处理,否则调用readRetainedSlice将数据切分,解析之后将对象添加到list中。 行解码器LineBasedFrameDecoder是指以\r\n或者\n结尾的数据为结束符进行数据解析。 首先从bytebuf中找到标志换行的字符标记为eol 1final int eol = findEndOfLine(buffer); 接下来判断是否是discarding的状态,因为LineBasedFrameDecoder内部有最大长度的限制,所以如果超过了最大长度,就会丢弃消息,discarding为True,这里默认为False。 这里会进行一次判断,如果当前读取到一行的数据超过了最大长度,那么readIndex会指向分隔符的下一个字符,也就是说,当超过了最大长度,Netty会将这部分数据完全抛弃。当没有找到换行符,就把当前取到的数据丢弃到。 12345if (length &gt; maxLength) &#123; buffer.readerIndex(eol + delimLength); fail(ctx, length); return null;&#125; 接着看看丢弃模式处理逻辑,如果截取到了换行符,那么直接将这一段丢弃,然后将丢弃模式设置为false,那么下一次处理的时候就会进入上面的处理逻辑。 1234567891011121314if (eol &gt;= 0) &#123; final int length = discardedBytes + eol - buffer.readerIndex(); final int delimLength = buffer.getByte(eol) == &apos;\r&apos;? 2 : 1; buffer.readerIndex(eol + delimLength); discardedBytes = 0; discarding = false; if (!failFast) &#123; fail(ctx, length); &#125;&#125; else &#123; discardedBytes += buffer.readableBytes(); buffer.readerIndex(buffer.writerIndex()); &#125;return null; 分隔符解码器 DelimiterBasedFrameDecoder分隔符处理器会要求传递两个参数,第一个是最大处理的数据长度,第二就是分隔符 123if (lineBasedDecoder != null) &#123; return lineBasedDecoder.decode(ctx, buffer);&#125; 首先会判断分割符是否是行分隔符,如果是则交给lineBasedDecoder去处理。 由于netty支持传递多个分割符进行分割,所以接下来Netty遍历分隔符集合,然后找出数据量最少的那个 1234567for (ByteBuf delim: delimiters) &#123; int frameLength = indexOf(buffer, delim); if (frameLength &gt;= 0 &amp;&amp; frameLength &lt; minFrameLength) &#123; minFrameLength = frameLength; minDelim = delim; &#125;&#125; 也就是先找到readIndex到A的数据 接下来进行解码,首先还是会对数据长度和maxLength以及丢弃策略进行判断,丢弃不合法的数据包,逻辑上与行分隔符很像,代码也比较清晰,所以就不一个一个分析了。 基于长度域解码器 LengthFieldBasedFrameDecoderLengthFieldBasedFrameDecoder有两个最重要的参数,lengthFieldOffset表示数据的长度数据从第几个字节开始,lengthFieldLength表示长度数据占了几个字节 除此之外,长度解码器还有两个重要的参数lengthAdjustment和initialBytesToStrip,下面的例子展示了他们组合起来的作用 1 这是一种最简单的情况,Length字段从0开始占用了2个字节 12345678910lengthFieldOffset = 0lengthFieldLength = 2lengthAdjustment = 0initialBytesToStrip = 0 * BEFORE DECODE (14 bytes) AFTER DECODE (14 bytes) * +--------+----------------+ +--------+----------------+ * | Length | Actual Content |-----&gt;| Length | Actual Content | * | 0x000C | &quot;HELLO, WORLD&quot; | | 0x000C | &quot;HELLO, WORLD&quot; | * +--------+----------------+ +--------+----------------+ 2 这个例子显示了initialBytesToStrip的作用,就是跳过从头开始的N个字节,这里我们一般可以设置一个数值,将长度字段过滤掉,将数据包交给业务逻辑处理即可。 12345678910lengthFieldOffset = 0lengthFieldLength = 2lengthAdjustment = 0initialBytesToStrip = 2 * BEFORE DECODE (14 bytes) AFTER DECODE (12 bytes) * +--------+----------------+ +----------------+ * | Length | Actual Content |-----&gt;| Actual Content | * | 0x000C | &quot;HELLO, WORLD&quot; | | &quot;HELLO, WORLD&quot; | * +--------+----------------+ +----------------+ 3 在大多数情况下,Length字段的含义是数据段的长度,但是有的协议长度字段是Length字段的长度+数据段的长度,那么这时我们可以调整lengthAdjustment为正数或者负数,表示增加或减少N个长度,用来减去Length字段所占用的长度。 12345678910lengthFieldOffset = 0lengthFieldLength = 2lengthAdjustment = -2initialBytesToStrip = 0 * BEFORE DECODE (14 bytes) AFTER DECODE (14 bytes) * +--------+----------------+ +--------+----------------+ * | Length | Actual Content |-----&gt;| Length | Actual Content | * | 0x000E | &quot;HELLO, WORLD&quot; | | 0x000E | &quot;HELLO, WORLD&quot; | * +--------+----------------+ +--------+----------------+ 源码中的decode方法比较复杂,大概可分为三个步骤 123计算需要抽取的数据包长度跳过字节处理逻辑丢弃模式下的处理]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(5) ByteBuf]]></title>
    <url>%2F2018%2F07%2F06%2FNetty-5-ByteBuf%2F</url>
    <content type="text"><![CDATA[三个问题 内存的类别有哪些 如何减少多线程内存分配的竞争 不同大小的内存是如何进行分配的 内存与内存管理器的抽象12345678* &lt;pre&gt;* +-------------------+------------------+------------------+* | discardable bytes | readable bytes | writable bytes |* | | (CONTENT) | |* +-------------------+------------------+------------------+* | | | |* 0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity* &lt;/pre&gt; byteBuf有三个非常重要的指针,readerIndex/writerIndex/capacity。0到readerIndex是已经读完,可以丢弃的数据,readerIndex和writerIndex之间是可读区域,writerIndex到capacity是可写区域。 不同大小和不同类型的内存分配策略Netty中对ByteBuf进行分配的基类是ByteBufAllocator,提供了一些内存分配的抽象方法。在注释中可以看到关于直接内存和堆内存的不同分配。 可以看到ByteBufAllocator是一个最顶层的抽象,AbstractByteBufAllocator实现了接口的大部分功能,然后最终暴露出两个方法(new DirectByteBuf和new HeapByteBuf)。这两个方法就交给子类pool和unpool,创建堆内和堆外内存的实现。 UnpooledByteBufAllocator 堆内分配 12345@Overrideprotected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) &#123; return PlatformDependent.hasUnsafe() ? new UnpooledUnsafeHeapByteBuf(this, initialCapacity, maxCapacity) : new UnpooledHeapByteBuf(this, initialCapacity, maxCapacity);&#125; 首先看堆内存的分配,判断JDK是否有unsafe对象,这是由JDK平台决定的。如果有则new一个unpool/unsafe/heap三维度的bytebuf,否则创建一个unpool/safe/heap的bytebuff。这两个类的初始化都是调用了相同的函数,那么这个safe是如何体现的。 当使用UnpooledUnsafeHeapByteBuf时,调用getByte方法 123static byte getByte(byte[] data, int index) &#123; return UNSAFE.getByte(data, BYTE_ARRAY_BASE_OFFSET + index);&#125; UnpooledHeapByteBuf的getByte方法 123static byte getByte(byte[] memory, int index) &#123; return memory[index];&#125; 可以看到两者的区别在于获取字节时unsafe调用的是jdk底层的api,通过指针获取数据。而safe则是通过数组以及下表获取数据。理论上来说,unsafe的方式会更快。 堆外分配 12345678@Overrideprotected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &#123; ByteBuf buf = PlatformDependent.hasUnsafe() ? UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) : new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); return disableLeakDetector ? buf : toLeakAwareBuffer(buf);&#125; 同样是根据JDK的api来区分safe or unsafe。 首先来看UnpooledDirectByteBuf,源码中传入了一个参数 setByteBuffer(ByteBuffer.allocateDirect(initialCapacity)); 这里就是调用了JDK底层的ByteBuffer并分配堆外内存。下面看UnpooledUnsafeDirectByteBuf,跟进到底层后发现有这样的一段代码 12345final void setByteBuffer(ByteBuffer buffer, boolean tryFree) &#123; ... memoryAddress = PlatformDependent.directBufferAddress(buffer); ...&#125; 这里通过unsafe,计算出byteBuf在内存中的地址然后保存。这样做的目的就是调用getByte()时可以直接使用这个地址加上一个偏移量,获取数据。而通过safe的方式getByte,就是传递一个index参数,从字节数组获取数据。 总结来说safe和unsafe的区别在于一个直接操作内存地址,一个操作数组。 PooledByteBufAllocator进入PooledByteBufAllocator.newHeapBuffer和newDirectBuffer,一个很明显的特征就是出现了cache,两个方法很相似,所以就拿 newDirectBuffer做一个简单的分析 1234567891011121314151617protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &#123; PoolThreadCache cache = threadCache.get(); PoolArena&lt;ByteBuffer&gt; directArena = cache.directArena; ByteBuf buf; if (directArena != null) &#123; buf = directArena.allocate(cache, initialCapacity, maxCapacity); &#125; else &#123; if (PlatformDependent.hasUnsafe()) &#123; buf = UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity); &#125; else &#123; buf = new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); &#125; &#125; return toLeakAwareBuffer(buf);&#125; 大概梳理一下: 12拿到线程局部缓存 PoolThreadCache在线程局部的Area上分配内存 在初始化PoolThreadCache,可以看到内部初始化了两个PoolArena,一个用于分配堆内存,一个用于分配堆外内存,并保存为成员变量。heapArena和directArena都是在PooledByteBufAllocator初始化的时候进行的初始化,两个区域都是Arena类型的数组,默认情况下回初始化cpu核数2的大小。这里其实是因为NioEventLoop初始化的时候默认是cpu核数2,这样做就可以默认情况下每个线程有一个Arena数组,不会产生竞争。 12345678protected synchronized PoolThreadCache initialValue() &#123; final PoolArena&lt;byte[]&gt; heapArena = leastUsedArena(heapArenas); final PoolArena&lt;ByteBuffer&gt; directArena = leastUsedArena(directArenas); return new PoolThreadCache( heapArena, directArena, tinyCacheSize, smallCacheSize, normalCacheSize, DEFAULT_MAX_CACHED_BUFFER_CAPACITY, DEFAULT_CACHE_TRIM_INTERVAL);&#125; 除此之外还可以看到 tinyCacheSize, smallCacheSize, normalCacheSize这三个参数。这三个参数可以分别去初始化对应规格的缓存。 directArena分配direct内存流程 从对象池拿到PooledByteBuf进行复用 入口方法 1buf = directArena.allocate(cache, initialCapacity, maxCapacity); 最终定位到PoolArena.allocate方法 1234567891011121314 protected PooledByteBuf&lt;ByteBuffer&gt; newByteBuf(int maxCapacity) &#123; if (HAS_UNSAFE) &#123; return PooledUnsafeDirectByteBuf.newInstance(maxCapacity); &#125; else &#123; return PooledDirectByteBuf.newInstance(maxCapacity); &#125; &#125;static PooledUnsafeDirectByteBuf newInstance(int maxCapacity) &#123; PooledUnsafeDirectByteBuf buf = RECYCLER.get(); buf.reuse(maxCapacity); return buf; &#125; 首先会newByteBuf,由于默认情况下HAS_UNSAFE为True,然后通过RECYCLER获取,从名字可以看出RECYCLER是一个带有回收性质的对象池。如果有则拿出一个,否则创建。然后调用reuse方法,将buf的状态初始化。至此拿到一个干净的Bytebuf。 之后会进入一个非常长的allocate方法,也就是主要的内存分配逻辑,首先会尝试从在缓存buf中分配,如果分配失败,则直接到内存上去分配,并且对于不同大小的内存,分配逻辑是不一样的。 可以看到大于16M,就到内存堆上去分配,这是因为系统内存申请是以chunk为单位,后续所有的内存分配都是在chunk里面做操作。比如现在我需要一个1MB的空间,那么我首先到操作系统申请1个chunk也就是16MB,然后取1m分配。8K则是操作系统的一个page,也就是把chunk切分成2048个page。0~8K的空间也有个名字,叫做subpage 命中缓存的逻辑 与缓存命中逻辑相关的数据结构就是MemeoryRegionCache 12345MemoryRegionCache(int size, SizeClass sizeClass) &#123; this.size = MathUtil.safeFindNextPositivePowerOfTwo(size); queue = PlatformDependent.newFixedMpscQueue(this.size); this.sizeClass = sizeClass;&#125; 关于MemoryRegionCache结构其实相当复杂,对于sizeClass{tiny,small,normal}又进行了细分。比如对于tiny一个512B的空间,每8个Byte又分了一个小空间,每个小空间组成一个queue,这样将tiny类型就凑成了一个chunk,当需要分配一个空间时,去拿一个最接近的空间即可。small和normal也是同理。 以tiny为例可以看源码:tinyCacheSize默认是512B,第二个值默认为512/16=32 1tinySubPageHeapCaches = createSubPageCaches(tinyCacheSize, PoolArena.numTinySubpagePools, SizeClass.Tiny); 这里首先创建了一个MemoryRegionCache[32]的数组,然后对于每个数组在进入循环,创建subpage 123456789101112private static &lt;T&gt; MemoryRegionCache&lt;T&gt;[] createSubPageCaches( int cacheSize, int numCaches, SizeClass sizeClass) &#123; if (cacheSize &gt; 0) &#123; MemoryRegionCache&lt;T&gt;[] cache = new MemoryRegionCache[numCaches]; for (int i = 0; i &lt; cache.length; i++) &#123; cache[i] = new SubPageMemoryRegionCache&lt;T&gt;(cacheSize, sizeClass); &#125; return cache; &#125; else &#123; return null; &#125;&#125; 下面进入allocate代码的逻辑,首先会进行代码规格化。具体做法就是若申请分配的长度属于tiny,则以16为倍数进行自增。small和normal则是2的幂次方。 1final int normCapacity = normalizeCapacity(reqCapacity); 接着就会找到对应size的MemoryRegionCache,如果大小是16B则除以16=1,到第一个queue中取,32则到第二个queue,以此类推。 123static int tinyIdx(int normCapacity) &#123; return normCapacity &gt;&gt;&gt; 4;&#125; 接着就会从queue从弹出一个entry给ByteBuf进行初始化,然后将弹出的entry扔到对象池进行复用。如果这里对象不进行复用,后面有个能被gc掉,这也是netty在最大化复用对象,减少对象的创建和销毁。 123456789101112public final boolean allocate(PooledByteBuf&lt;T&gt; buf, int reqCapacity) &#123; Entry&lt;T&gt; entry = queue.poll(); if (entry == null) &#123; return false; &#125; initBuf(entry.chunk, entry.handle, buf, reqCapacity); entry.recycle(); // allocations is not thread-safe which is fine as this is only called from the same thread all time. ++ allocations; return true; &#125; arena、chunk、page、subpage这是Netty内存分配过程中非常重要的几个概念。 arena 在每个线程去分配对应的内存的时候,首先会通过threadLocal的方式,获取到PoolThreadCache。通过PoolThreadCache.allocate方法去分配内存,这个PoolThreadCache分为两部分:一部分是不同规格大小的cache(MemoryRegionCache),另一部分就是arena(PoolArena),区别在于缓存是直接缓存了一块内存，Arena是直接开辟了一块内存。 chunk arena的数据结构如图所示 内部是多个chunklist,每个chunklist以双向链表的方式进行连接。chunklist的节点是chunk,也就是向操作系统申请的最小内存空间–16M。这里的链表结构是因为Netty会实时进行每个chunk的使用情况,按照内存使用率分别组成chunklist,方便以后进行分配能够快速找到一个合适的内存块。这里初始化的时候可以看到,第一个参数就是list的名字,第二个参数是最小使用率,第三个参数是最大使用率 12345678910111213private final PoolChunkList&lt;T&gt; q050;private final PoolChunkList&lt;T&gt; q025;private final PoolChunkList&lt;T&gt; q000;private final PoolChunkList&lt;T&gt; qInit;private final PoolChunkList&lt;T&gt; q075;private final PoolChunkList&lt;T&gt; q100;q100 = new PoolChunkList&lt;T&gt;(null, 100, Integer.MAX_VALUE, chunkSize);q075 = new PoolChunkList&lt;T&gt;(q100, 75, 100, chunkSize);q050 = new PoolChunkList&lt;T&gt;(q075, 50, 100, chunkSize);q025 = new PoolChunkList&lt;T&gt;(q050, 25, 75, chunkSize);q000 = new PoolChunkList&lt;T&gt;(q025, 1, 50, chunkSize);qInit = new PoolChunkList&lt;T&gt;(q000, Integer.MIN_VALUE, 25, chunkSize); page 由于内存申请时很少有需要16M内存的时候,那么把16M进行切分,分为一个一个8K的页,则能更好的利用空间。Netty认为8K还是太大,于是继续细分了page,分为4个2K的subpage 这里就可以知道Netty的内存分配策略,如果申请的空间大于8K,则按照page进行分配,如果申请的空间小于8K,则找到一个page,切分为多个subpage,使用subpage进行分配。 page级别的内存分配 allocateNormal123456789101112131415private synchronized void allocateNormal(PooledByteBuf&lt;T&gt; buf, int reqCapacity, int normCapacity) &#123; if (q050.allocate(buf, reqCapacity, normCapacity) || q025.allocate(buf, reqCapacity, normCapacity) || q000.allocate(buf, reqCapacity, normCapacity) || qInit.allocate(buf, reqCapacity, normCapacity) || q075.allocate(buf, reqCapacity, normCapacity)) &#123; ++allocationsNormal; return; &#125; // Add a new chunk. PoolChunk&lt;T&gt; c = newChunk(pageSize, maxOrder, pageShifts, chunkSize); long handle = c.allocate(normCapacity); ++allocationsNormal; assert handle &gt; 0; c.initBuf(buf, handle, reqCapacity); qInit.add(c);&#125; 这部分代码大致有两层。首先尝试在现有的chunk上进行分配,也就是if代码块的内容,首次进入的话都没有初始化。所以进入下面新建chunk的逻辑。新建chunk之后进行分配内存,返回一个handle指向chunk中的一块连续内存区域。最后初始化ByteBuf 这里Netty快速定位一个page使用了一种完全二叉树的结构,可以将查找一个page的时间复杂度稳定在logn。 subpage级别的内存分配 allocateTiny 定位一个page对象 创建一个subpage 初始化bytebuf 这里subpage的大小不一定是2K,这与需要分配的空间大小有关。例如在初始化时,若申请1K的空间,则会将page的8K分为8份1K的空间。 内存的释放通过调用bytebuf.realease()方法可以将内存释放 123456789protected final void deallocate() &#123; if (handle &gt;= 0) &#123; final long handle = this.handle; this.handle = -1; memory = null; chunk.arena.free(chunk, handle, maxLength, cache); recycle(); &#125;&#125; 这里首先将这块内存的handle标记为-1,表示无法索引到这块区域,将memeory置为null。接着free()和recycle()做了以下几件事 123连续的内存区段加到缓存标记内存区段为未使用ByteBuf加入对象池 总结ByteBuf的分类可以按照三个维度来分,堆内堆外、safe和unsafe、pool和unpool direct和heap的区别在于,堆内是基于字节数组进行分配,堆外是基于JDK的API进行分配。Unsafe是基于JDK的unsafe对象对物理内存地址进行读写,非unsafe是通过jdk的api进行读写。unpool每次直接申请物理内存,而pool则是预先分配好内存,需要使用的时候根据算法取出一块连续空间。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(4) Pipeline]]></title>
    <url>%2F2018%2F07%2F04%2FNetty-4-Pipeline%2F</url>
    <content type="text"><![CDATA[三个问题 Netty如何判断ChannelHandler类型(in out) ChannelHandler添加应按照什么样的顺序 用户手动触发事件传播,不同的触发方式有什么区别 Pipeline的初始化在之前的代码分析中,不管服务端还是客户端,最后都会进入AbstractChannel,创建PipeLine 123456protected AbstractChannel(Channel parent, ChannelId id) &#123; this.parent = parent; this.id = id; unsafe = newUnsafe(); pipeline = newChannelPipeline();&#125; 添加或删除ChannelHandler在我们自己编写的代码中,大多会写到ch.pipeline().addLast(xxx),此方法就是添加PipeLine的入口。最终跟进到ChannelPipeline.addLast() 默认情况下回创建头尾两个节点,并连接为双向列表。这两个节点都是ChannelHandlerContext数据结构,所以pipeline中的节点都是ChannelHandlerContext。 123456789protected DefaultChannelPipeline(Channel channel) &#123; this.channel = ObjectUtil.checkNotNull(channel, &quot;channel&quot;); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;&#125; 接着看一下头结点 123456789HeadContext(DefaultChannelPipeline pipeline) &#123; super(pipeline, null, HEAD_NAME, false, true); unsafe = pipeline.channel().unsafe(); setAddComplete();&#125;TailContext(DefaultChannelPipeline pipeline) &#123; super(pipeline, null, TAIL_NAME, true, false); setAddComplete();&#125; 这里第三个和第四个参数分别是inbound和outbound。与我们直觉相反,head节点是outbound而tail是inbound。另外一个不同在于,tail节点内部的操作一般都为空,而head节点都会原模原样向后传播。并且读写操作会调用unsafe进行。 123判断是否重复添加创建节点并添加到链表回调添加完成事件 在addLast的具体过程中,可以看到节点实际上是添加到了尾节点的前一个节点1234567private void addLast0(AbstractChannelHandlerContext newCtx) &#123; AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; newCtx.next = tail; prev.next = newCtx; tail.prev = newCtx;&#125; 添加handler是一个非常常见的场景,但是删除一个handler却很少见，删除handler主要用在权限校验的场景上。 我们可以自己实现一个AuthHandler 12345678910111213public class AuthHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception &#123; if(isPass(msg))&#123; ctx.pipeline().remove(this); &#125;else &#123; ctx.close(); &#125; &#125; private boolean isPass(ByteBuf pwd)&#123; return false; &#125;&#125; 在这里如果通过权限校验就删除这个handler,没有通过就关闭连接,以此实现一个高效的权限校验。 remove的操作也是一个标准的链表删除方式,删除掉之后会进行用户回调,完成删除。 123456private static void remove0(AbstractChannelHandlerContext ctx) &#123; AbstractChannelHandlerContext prev = ctx.prev; AbstractChannelHandlerContext next = ctx.next; prev.next = next; next.prev = prev;&#125; InBound事件传播 首先看一下顶级的接口ChannelHanlder有哪些功能,包括channel添加,删除,抛出异常方法以及一个Sharable注解,表示这个handler可以被多个channel共享。 ChannelInboundHandler继承自ChannelHanlder,并添加了一些register,active,read这样一些事件,其中主要的是channelRead方法。 添加三个自定义的handler 12345678910111213141516171819202122232425262728293031323334socketChannel.pipeline().addLast(new HandlerA());socketChannel.pipeline().addLast(new HandlerB());socketChannel.pipeline().addLast(new HandlerC());public class HandlerA extends ChannelInboundHandlerAdapter&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(&quot;A &quot;+msg); ctx.fireChannelRead(msg); &#125;&#125;public class HandlerB extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.channel().pipeline().fireChannelRead(&quot;hello &quot;); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(&quot;B &quot; + msg); ctx.fireChannelRead(msg); &#125;&#125;public class HandlerC extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(&quot;c &quot;+msg); ctx.fireChannelRead(msg); &#125;&#125; 输出A helloB helloc hello 可以看到inbound的read顺序和添加顺序相关,按顺序进行读取,并且可以在中间开始传播。其中还隐藏了不少细节,其实inbound事件都是从head节点开始传播,但是head节点什么都不做,只是fire这条消息,所以没有感觉,如果消息是bytebuff类型,在tail节点会调用realse方法进行释放。所以如果一个节点接收到消息不需要向后传播时,应该手动进行realse,否则会占用空间导致内存泄漏。考虑到这一点,Netty提供了SimpleChannelInboundHandler类,可以继承这个类,Netty会帮我们释放不用的bytebuffer。 outBound事件传播outBound的传播主要体现在write方法 1234567891011121314151617181920212223242526272829303132333435socketChannel.pipeline().addLast(new OutA());socketChannel.pipeline().addLast(new OutB());socketChannel.pipeline().addLast(new OutC());public class OutA extends ChannelOutboundHandlerAdapter &#123; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; System.out.println(&quot;A &quot;+msg); ctx.write(msg,promise); &#125;&#125;public class OutB extends ChannelOutboundHandlerAdapter &#123; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; System.out.println(&quot;B &quot;+msg); ctx.write(msg,promise); &#125; @Override public void handlerAdded(final ChannelHandlerContext ctx) throws Exception &#123; ctx.executor().schedule(()-&gt;&#123; ctx.channel().write(&quot;hello&quot;); &#125;,3, TimeUnit.SECONDS); &#125;&#125;public class OutC extends ChannelOutboundHandlerAdapter &#123; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; System.out.println(&quot;C &quot;+msg); ctx.write(msg,promise); &#125;&#125; 输出C helloB helloA hello 可以看到,outBound的添加顺序与执行顺序相反,后添加的先执行。这里我们看到了两种write的写法,那么有什么区别呢: 12ctx.write(msg);ctx.channel().write(&quot;hello&quot;); 首先看ctx.channel().write(“hello”),可以看到首先调用了内部的pipeline,然后进入尾节点,也就是从tail节点向前写。 12345678@Overridepublic ChannelFuture write(Object msg) &#123; return pipeline.write(msg);&#125;@Overridepublic final ChannelFuture write(Object msg) &#123; return tail.write(msg);&#125; 而ctx.write(msg)的作用则是从当前节点开始传播,不会从尾节点开始 异常传播 假设我们已经添加了 A B C三个handler,各有一个inbound处理器和一个outbound处理器,目前的pipeline状况为head&lt;-&gt;A&lt;-&gt;B&lt;-&gt;C&lt;-&gt;tail 现在手动在A抛出一个异常,则打印错误为 1234567Inboud B ExceptionInboud C ExceptionOnboud A ExceptionOnboud B ExceptionOnboud C ExceptionA的错误日志。。。。 可见异常并没有像之前的inbound和outbound与添加顺序相同或相反,而是只与handler的添加顺序有关,并且从当前节点向后传播。 默认情况下如果不做处理,异常会一直传播,那么异常处理的最佳实践就是在最后添加一个异常处理器,对异常进行处理,否则错误最后会抛出,影响程序运行。 123456789public class ExceptionHandler extends ChannelInboundHandlerAdapter &#123; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; //业务处理 if(cause instanceof RuntimeException)&#123; //deal with exception &#125; &#125;&#125; 开头的问题 Netty如何判断ChannelHandler类型(in out) 用户自定义的handler会选择继承自Inbound或者OutBound,Netty会用instance判断 ChannelHandler添加应按照什么样的顺序 InbundHandler事件的传播与添加顺序正相关,OutbundHandler事件的传播与添加顺序逆相关 用户手动触发事件传播,不同的触发方式有什么区别 通过channel触发事件时,从head或者tail节点开始传播,如果从当前节点触发,那么事件只会从当前节点开始触发。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(3) 新连接接入]]></title>
    <url>%2F2018%2F07%2F03%2FNetty-%E6%96%B0%E8%BF%9E%E6%8E%A5%E6%8E%A5%E5%85%A5-3%2F</url>
    <content type="text"><![CDATA[提出两个问题 Netty在哪里检测到新连接的接入 新连接怎样注册到NioEventLoop线程 我们知道Nio的多路复用是指多个连接复用一条线程,对应netty就是nioeventloop,新连接处理主要有四个步骤 检测新连接: 新连接通过服务端Channel绑定的selector轮询出ACCEPT事件 创建Channel:基于JDK的nioChannel创建出Netty NioSocketChannel Netty给客户端channel分配NioEventLoop,并将channel绑定 向selector注册读事件 检测新连接1234processSelectedKey(key,channel) [入口] NioMessageUnsafe.read() doReadMessage() [while 循环] javaChannel().accept() 创建NioSocketChannel123456new NioSocketChannel(parent,ch) [入口] AbstractNioByteChannel(p,ch,opread) configBlocking(false) &amp; interest_op [注册事件] create id,unsafe,pipeline new NioSocketChannelConfig() [创建绑定配置] setTcpNoDelay(true) [禁止Nagle算法,小数据包尽量快发送] 跟进到NioServerSocketChannel.doReadMessages(buf): 123456789@Overrideprotected int doReadMessages(List&lt;Object&gt; buf) throws Exception &#123; SocketChannel ch = SocketUtils.accept(javaChannel()); try &#123; if (ch != null) &#123; buf.add(new NioSocketChannel(this, ch)); return 1; &#125; &#125; 首先创建一个jdk的channel,然后将jdk的channel与当前类this,共同构造一个Netty的NioSocketChannel 12345678public NioSocketChannel(Channel parent, SocketChannel socket) &#123; super(parent, socket); config = new NioSocketChannelConfig(this, socket.socket());&#125;protected AbstractNioByteChannel(Channel parent, SelectableChannel ch) &#123; super(parent, ch, SelectionKey.OP_READ);&#125; 在这里跟进到父类,发现Netty默认传递了一个OP_READ事件 12345678protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try &#123; ch.configureBlocking(false); &#125; .... 在这里,将read事件注册到了channel,并且设置为非阻塞模式,继续向上跟进父类,就会创建id,unsafe,pipeline组件。NioSocketChannelConfig主要作用就是设置setTcpNoDelay(true)。如果是false,则会将小的数据包尽量集合成大的数据包然后发送出去,而Netty默认是关闭的,如果运行在Android系统上,则默认开启。 Netty中Channel的分类Channel层级关系 顶层接口channel主要定义了网络IO的读写,绑定,是一个最顶级的抽象。AbstractChannel是一个抽象的实现,并且定义了重要的成员变量。 接着是AbstractNioChannel,他有两个子类channel,这两个子类差别主要是向AbstractNioChannel注册的io事件不同,可以看一下构造函数 12345678public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());&#125;protected AbstractNioByteChannel(Channel parent, SelectableChannel ch) &#123; super(parent, ch, SelectionKey.OP_READ);&#125; 可以看到服务端channel感兴趣的是accept事件,而客户端channel感兴趣的是read事件。除此之外可以发现,服务端channel和客户端channel对应的unsafe不同,对于服务端NioMessageUnsafe处理的是连接的读取,而客户端NioByteUnsafe是字节读取。 客户端和服务端都有相应的config进行配置 新连接NioEventLoop分配和selector注册方法的入口为MultithreadEventLoopGroup 1234@Overridepublic ChannelFuture register(Channel channel) &#123; return next().register(channel);&#125; 这里会next()返回一个NioEventLoop,然后chooser选择一个NioEventLoop,调用register方法,过程中利用了串行无锁化技术,调用底层jdk channel,注册一个accept事件 NioSocketChannel读事件注册入口方法位于AbstractChannel的register0() 1234567if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125;&#125; 这里因为新连接已经介入,所以isActive()返回true,并且firstRegistration也为true。调用 pipeline.fireChannelActive();后续会调用readIfIsAutoRead(),默认情况下是自动读的,AbstractNioChannel.beginRead()。 123456789101112131415@Overrideprotected void doBeginRead() throws Exception &#123; // Channel.read() or ChannelHandlerContext.read() was called final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; 这里由于初始化设置interestOps为0,所以会再添加一个readInterestOp,也就可以监听OP_READ事件了。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(2) NioEventLoop]]></title>
    <url>%2F2018%2F07%2F02%2FNetty-NioEventLoop-2%2F</url>
    <content type="text"><![CDATA[相关的三个问题 默认情况下,Netty服务端起多少线程,何时启动 Netty如何解决JDK空轮训bug Netty如何保证异步串行无锁化 NioEventLoop创建1234new NioEventLoopGroup() [线程组,默认cpu*2] new ThreadPerTaskExecutor() [线程创建器] for()&#123;new Child()&#125; [构造Eventloop] chooserFactory.newChooser()[线程选择器] 从用户代码进入 12NioEventLoopGroup boss = new NioEventLoopGroup(1);NioEventLoopGroup worker = new NioEventLoopGroup(); 跟进到这里可以看到,默认不传参数的eventgroup会赋予一个DEFAULT_EVENT_LOOP_THREADS大小的线程,为cpu数量的2倍。123protected MultithreadEventLoopGroup(int nThreads, Executor executor, Object... args) &#123; super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, args);&#125; 接着进入父类可以进入方法MultithreadEventExecutorGroup 首先创建线程选择器 123if (executor == null) &#123; executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());&#125; 接着构造一个Eventloop数组并循环创建,最后 chooser = chooserFactory.newChooser(children); 创建一个线程选择器 ThreadPerTaskExecutor 每次执行任务都会创建一个线程实体 123456executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());@Overridepublic void execute(Runnable command) &#123; threadFactory.newThread(command).start();&#125; Netty线程命名规则 nioEventLoop-x-xx FastThreadLocalThread 这里Netty创建的线程是FastThreadLocalThread,这种Thread对JDK底层的Thread进行了包装,优化了ThreadlocalMap 123protected Thread newThread(Runnable r, String name) &#123; return new FastThreadLocalThread(threadGroup, r, name); &#125; newChild() 保存线程执行器ThreadPerTaskExecutor 创建一个MpscQueue 创建一个selector 我们通过children[i] = newChild(executor, args);进入NioEventLoopGroup 123456789101112131415NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); if (selectorProvider == null) &#123; throw new NullPointerException(&quot;selectorProvider&quot;); &#125; if (strategy == null) &#123; throw new NullPointerException(&quot;selectStrategy&quot;); &#125; provider = selectorProvider; final SelectorTuple selectorTuple = openSelector(); selector = selectorTuple.selector; unwrappedSelector = selectorTuple.unwrappedSelector; selectStrategy = strategy;&#125; 这里一个nioeventLoop和一个selector作绑定,继续跟进父类 12345678910protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) &#123; super(parent); this.addTaskWakesUp = addTaskWakesUp; this.maxPendingTasks = Math.max(16, maxPendingTasks); this.executor = ObjectUtil.checkNotNull(executor, &quot;executor&quot;); taskQueue = newTaskQueue(this.maxPendingTasks); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;); &#125; 这部分代码比较清晰,首先将线程执行器保存起来,因为后面创建NioEventloop底层线程要用到。 然后创建了一个taskQueue,这个taskQ是用在一些外部线程执行Netty任务,如果判断不是在NioEventloop里面去执行,它会放到一个任务队列里,然后由NioEventloop里对应的一个线程去执行。这里创建了一个newMpscQueue,这里的MpscQ意思是Mutli producer single consumer的意思,这里的consumer就是NioEventloop 创建Chooserchooser的作用就是当一个连接进入,chooser选择一个NioEventloop进行服务,例如NioEventLoop大小为N。第一个请求分配nioEventLoop[0],第N个分配nioEventLoop[N-1]。第n+1个分配nioEventLoop[0],如此循环往复。但是在这样简单的功能中,netty也做了优化 123456chooser = chooserFactory.newChooser(children); isPowerOfTwo[判断nioeventloop长度是否是2的幂] PowerOfTwoEventExecutorChooser [优化] index++&amp;(length-1) GenericEventExecutorChooser [未优化] abs(index++%length) 在DefaultEventExecutorChooserFactory类下的next方法可以看到区别 123return executors[Math.abs(idx.getAndIncrement() % executors.length)];return executors[idx.getAndIncrement() &amp; executors.length - 1]; 通过上面的几个小过程,就完成了NioEventLoop的创建 NioEventLoop启动NioEventLoop的启动依赖于两大触发器 服务端启动绑定接口 新连接接入,绑定一个NioEventLoop 先以第一个为例 12345bind()-&gt;execute(task) [入口] startThread() ThreadPerTaskExecutor.execute() thread = Thread.currentThread NioEventLoop.run() [启动] 回到AbstractBootStrap的dobind0()12345678910channel.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; if (regFuture.isSuccess()) &#123; channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; else &#123; promise.setFailure(regFuture.cause()); &#125; &#125; &#125;); 跟进execute方法到SingleThreadEventExecutor 在这里判断了当前线程是否在NioEventLoop中,在这里返回一个False,所以进入startThread()-&gt;doStartThread() 这部分代码首先做的就是把当前线程进行一个保存,也就是绑定到NioEventLoop,接着调用一个run()最终启动 NioEventLoop执行逻辑NioEventLoop的执行逻辑从SingleThreadEventExecutor.doStartThread()中SingleThreadEventExecutor.this.run();开始 1234run()-&gt;for(;;) select [轮询注册到selector上的事件] processSelectedKeys [处理轮询出来的事件] runAllTasks [处理异步任务队列] 首先select的过程比较简单,不在多说。然后对selectKeys进行处理 123456789101112131415if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); &#125; finally &#123; runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125;&#125; 可以看到这里根据ioRatio进入了不同的分支。这里的ioRatio默认是50,所以进入了else分支。ioRatio是用来控制processSelectedKeys和runAllTasks的执行时间,processSelectedKey处理io相关的逻辑,runAllTasks是用来处理外部线程扔到taskQ里面的任务,这里的taskQ之前说过是一个MpscQ. 在else分支中,首先记录一下开始时间,处理完成计算完成时间，由于radio是50,所以runAllTask也可以处理相同的时间,更细致的分析以后再写 select检测io事件 deadline以及任务穿插逻辑处理 阻塞式select 避免jdk空轮训的bug 123456789for (;;) &#123; long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; if (timeoutMillis &lt;= 0) &#123; if (selectCnt == 0) &#123; selector.selectNow(); selectCnt = 1; &#125; break;&#125; 首先,通过long currentTimeNanos = System.nanoTime();获取当前时间 long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); 这里是因为nioEventLoop底层有一个定时任务队列,它是按照任务截止从小到大排列。这样做的目的是判断是否有定时任务需要启动接着进入for循环,先计算当前是否超时,如果超时并且没有select,则进行一次非阻塞的select,那么本次select操作就结束了。 12345if (hasTasks() &amp;&amp; wakenUp.compareAndSet(false, true)) &#123; elector.selectNow(); selectCnt = 1; break;&#125; 接着判断taskQ是否为空,及MpscQ是否为空,如果有任务,则调用一个非阻塞的select方法 如果上面的条件都不满足,则调用一个阻塞式的select操作,timeout就是本次可以select的最大时间12int selectedKeys = selector.select(timeoutMillis);selectCnt ++; 接下来的操作可以避免JDK空轮询的bug 1234567891011121314long time = System.nanoTime();if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123; selectCnt = 1; &#125; else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; logger.warn( &quot;Selector.select() returned prematurely &#123;&#125; times in a row; rebuilding Selector &#123;&#125;.&quot;, selectCnt, selector); rebuildSelector(); selector = this.selector; selector.selectNow(); selectCnt = 1; break;&#125; 当执行到这里表明已经执行过一次阻塞式的select操作,在这里判断当前时间减去阻塞式执行的时间是否大于等于进入这个方法的时间,如果小于,则可能进行了空轮询,那么这个时候会判断空轮训的次数是否大于一个阈值(默认512次),如果大于,执行rebuildSelector()操作。 123newSelectorTuple = openSelector();for (SelectionKey key: oldSelector.keys()) &#123;...&#125;selector = newSelectorTuple.selector; rebuildSelector的主要内容就是创建一个新的NioEventLoop,将原来的NioEventLoop上的时间重新注册到新的,并将Netty的channel绑定,接着将新的NioEventLoop保存,将旧的释放掉 处理io事件io事件的处理主要涉及processSelectedKeys()的执行逻辑 selected KeySet优化 processSelectedKeysOptimized() 对于io事件轮询的优化,在selector创建的时候体现,即openSelector() 首先调用jdk的api去创建一个selector 1unwrappedSelector = provider.openSelector(); 接着判断是否需要优化,默认情况下这里为false,所以需要进行优化 123if (DISABLE_KEYSET_OPTIMIZATION) &#123; return new SelectorTuple(unwrappedSelector);&#125; 接着创建了这样一种数据结构,替换了原生JDK的selectionKey的数据结构,进入源码看一看哪里做了优化 1final SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet(); 这里由于keySet并不需要jdk底层的一些方法,只需要关注add方法即可。所以这里用一个一维数组替换了原有的HashSet。在极端情况下,将复杂度从O(n)降低到O(1) 回到源码,Netty继续通过反射的方式获取到JDK的selector以及属性,并且将自己实现的数据结构赋予了JDK的selector 12345Field selectedKeysField = selectorImplClass.getDeclaredField(&quot;selectedKeys&quot;);Field publicSelectedKeysField = selectorImplClass.getDeclaredField(&quot;publicSelectedKeys&quot;);...selectedKeysField.set(unwrappedSelector, selectedKeySet);publicSelectedKeysField.set(unwrappedSelector, selectedKeySet); 这个过程就是Netty对selectionKey作优化,即使用数组对hashset作替换,将时间复杂度稳定到O(1) 接下来调用processSelectedKeysOptimized()处理优化后的selector,进入代码中的processSelectedKey方法。如果这个Key是合法的,这里就列出了可处理的事件,包括读/写/连接请求 123456789101112if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &#125; if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; ch.unsafe().forceFlush(); &#125; if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; unsafe.read(); &#125; task执行task的执行入口在 12runAllTasks()runAllTasks(ioTime * (100 - ioRatio) / ioRatio); task分类和添加 任务聚合 任务执行 Netty中默认有两个任务队列,一个是普通任务队列MpscQ,在创建NioEventLoop时就创建了。定时任务队列是一个普通的PriorityQ,如果是当前Eventloop添加定时任务,则直接添加,否则创建一个新的线程去添加任务,这样才是线程安全的。 首先进入代码到fetchFromScheduledTaskQueue(),这会从定时任务Q拉去第一个任务,我们说过这是一个优先级队列,他排序的标准就是两个任务的截止时间,时间相同按照添加顺序进行排序,那么第一个任务必定是最早结束的一个。 1taskQueue.offer(scheduledTask) 这里拿到定时任务以后,把它加入到普通的任务队列,如果失败则重新添加到定时任务队列。完成这个方法之后,所有需要执行的定时任务都放入普通队列中了。 拿到任务之后计算一下截止时间.当任务执行的数量到64的时,比较一下截止时间,如果超出时间就退出,任务队列中的任务只能等下次再执行。如果时间没有超过,则继续执行任务 123456if ((runTasks &amp; 0x3F) == 0) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); if (lastExecutionTime &gt;= deadline) &#123; break; &#125;&#125;]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty源码(1)-服务端启动]]></title>
    <url>%2F2018%2F07%2F02%2FNetty%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%90%AF%E5%8A%A8-1%2F</url>
    <content type="text"><![CDATA[服务端代码12345678910111213141516171819202122232425public static void main(String[] args) &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); EventLoopGroup boss = new NioEventLoopGroup(1); EventLoopGroup worker = new NioEventLoopGroup(); try &#123; serverBootstrap.group(boss, worker) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, false) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel socketChannel) throws Exception &#123; ocketChannel.pipeline().addLast(new MyHandler()); &#125; &#125;); ChannelFuture channelFuture = serverBootstrap.bind(8080).sync(); channelFuture.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; boss.shutdownGracefully(); worker.shutdownGracefully(); &#125; &#125; 以上是一段Netty官网提供的一个最简单的server端代码,通过这段代码来分析Netty服务端的启动过程 Netty服务端启动流程 创建服务端Channel 初始化服务端Channel 注册Selector 端口绑定 我们知道Netty其实是对JAVA NIO 底层API进行了一些封装,那么我们首先提出两个问题 服务端socket在哪里初始化 在哪里accept连接 带着问题我们逐步分析上述的过程 创建服务端Channel大致梳理一下源码 123bind() [用户代码入口] initAndRegister() [初始化并注册] newChannel() [创建服务端Channel] 我们首先根据代码 1serverBootstrap.bind(8080).sync(); 进入bind()方法,并最终进入到doBind(),看到第一行代码 1final ChannelFuture regFuture = initAndRegister(); 进入initAndRegister 1channel = channelFactory.newChannel(); 这里就可以看到Netty创建了一个Channel,我们这部分主要的目的就是看Netty创建一个Channel具体做了些什么 通过newChannel(),进入实现类ReflectiveChannelFactory 12345678@Overridepublic T newChannel() &#123; try &#123; return clazz.newInstance(); &#125; catch (Throwable t) &#123; throw new ChannelException(&quot;Unable to create Channel from class &quot; + clazz, t); &#125;&#125; 可以看出Netty用反射的方式去创建了一个Channel,那么这个clazz是什么呢。那么我们需要返回到channelFactory,看看它是怎么初始化的,初始化的时候传递了哪种Channel 回到我们自己写的用户代码,可以找到我们传递的一个Channel类 1.channel(NioServerSocketChannel.class) 进入源码,果然初始化了ReflectiveChannelFactory 123456public B channel(Class&lt;? extends C&gt; channelClass) &#123; if (channelClass == null) &#123; throw new NullPointerException(&quot;channelClass&quot;); &#125; return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass));&#125; 所以Netty是通过反射的方式,创建了一个用户指定类型的Channel,那么接下来我们要去看看NioServerSocketChannel的构造函数,看它在初始化的时候做了哪些事情。由于这个类比较复杂,先给出梳理后的结果再仔细分析: 12345new Socket() [通过JDK创建底层jdk channel]NioServerSocketChannelConfig() [tcp参数配置]AbstractNioChannel() configureBlocking(false) [阻塞模式] AbstractChannel(创建ID,unsafe,pipline) 进入构造函数 123456789101112public NioServerSocketChannel() &#123; this(newSocket(DEFAULT_SELECTOR_PROVIDER));&#125; private static ServerSocketChannel newSocket(SelectorProvider provider) &#123; try &#123; return provider.openServerSocketChannel(); &#125; catch (IOException e) &#123; throw new ChannelException( &quot;Failed to open a server socket.&quot;, e); &#125;&#125; 在这里其实就是调用了JDK底层的API,创建了一个serverSocketChannel,来自java.nio 继续进入构造函数 1234public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());&#125; Netty将JDK的channel传入config,进行一些封装,将一些tcp参数配置进去,接着进入父类 123456789101112131415161718192021222324252627 protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try &#123; ch.configureBlocking(false); &#125; catch (IOException e) &#123; try &#123; ch.close(); &#125; catch (IOException e2) &#123; if (logger.isWarnEnabled()) &#123; logger.warn( &quot;Failed to close a partially initialized socket.&quot;, e2); &#125; &#125; throw new ChannelException(&quot;Failed to enter non-blocking mode.&quot;, e); &#125; &#125; protected AbstractChannel(Channel parent) &#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();&#125; 这里我们看到了原生API的常见代码,将channel设置为非阻塞模式 1ch.configureBlocking(false); 通过父类,创建了ID,unsafe,pipeline三个属性。ID是一个channel的唯一标示,unsafe做一些channel的读写操作,pipeline是Netty的一个重要抽象,我们所做的大部分工作都在pipeline上进行 至此,一个服务端的Channel创建也就完成了 初始化服务端Channel我们继续回到AbstractBootstrap.initAndRegister(),上面完成了Channel的创建,下面将返回的channel传入init(channel)方法,进行一些初始化,具体看一下init Channel的过程,首先总结一些 12345init(channel) [入口] set ChannelOptions ChannelAttrs set ChildOptions ChildAttrs config handler [配置服务端pipeline] add ServerBootstrapAcceptor [添加连接器] 进入ServerBootStrap.init(),这部分代码逻辑清晰,直接在源码上做标注 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Override void init(Channel channel) throws Exception &#123; //set ChannelOptions ChannelAttrs final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) &#123; channel.config().setOptions(options); &#125; final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) &#123; for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) &#123; @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); &#125; &#125; ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; //set ChildOptions ChildAttrs synchronized (childOptions) &#123; currentChildOptions = childOptions.entrySet().toArray(newOptionArray(childOptions.size())); &#125; synchronized (childAttrs) &#123; currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(childAttrs.size())); &#125; //配置pipeline p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; //添加 ServerBootstrapAcceptor [添加连接器],处理新连接的接入,Netty默认会添加的一个handler ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;); &#125; 注册SelectorChannel初始化完成之后,要把Channel注册到事件轮询器Selector上面去。我们继续回到AbstractBootstrap.initAndRegister()。在init()之后执行方法 ChannelFuture regFuture = config().group().register(channel); 这段代码最终会调用到AbstractChannel的Register()方法,先对这个方法的流程进行一个概括: 123456AbstractChannel.Register() this.eventLoop = eventLoop [绑定Nio线程] register0() [实际注册] doRegister() [调用底层api进行注册] invokerHandlerIfNeeded [事件回调] fireChannelRegister() [注册成功进行广播] 源码的逻辑比较清晰,会看到doRegister()这个方法,直接进入AbstractNioChannel的doRegister()方法中,这是Netty注册Selector调用JDK底层API的代码 1selectionKey = javaChannel().register(eventLoop().selector(), 0, this); 这里javaChannel就是Netty创建的JDK底层Channel,0表示这个Channel不关心任何监听事件,只是简单的绑定上去。this表示Attachment属性,在这里就是服务端的Channel,通过attachment绑定到selector上面去。这样做的目的就是当Selector将这个javaChannel轮询出来,那么就可以拿到这个attachment,针对Netty的channle做事件的传播。 服务端端口绑定12345AbstractUnsafe.bind()[入口] doBind() javaChannel().bind() [jdk底层] pipeline.fireChannelActive() [传播事件] headContext.readIfIsAutoRead() 对于JDK底层的绑定代码,可以定位到NioServerSocketChannel中 12345678@Overrideprotected void doBind(SocketAddress localAddress) throws Exception &#123; if (PlatformDependent.javaVersion() &gt;= 7) &#123; javaChannel().bind(localAddress, config.getBacklog()); &#125; else &#123; javaChannel().socket().bind(localAddress, config.getBacklog()); &#125;&#125; 接着进入DefaultChannelPipline.channelActive。首先执行fireChannelActive方法,传播ChannelActive事件,如果用户代码重写了这个方法,那么现在就会执行,接着readIfIsAutoRead(),进入这个方法,可以发现这个方法作用在pipeline上,从head到tail都会执行,最后进入AbstractNioChannel.doBeginRead() 12345678910111213protected void doBeginRead() throws Exception &#123; final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; 我们在注册这个Channel的时候,selectKey赋予了0,在这里重新注册了accept事件(readInterestOp),也就是说从此开始,selector再轮询到新的连接接入事件,就可以交给这个NettyChannel来处理了。 总结 首先创建一个JDK底层Channel,然后Netty将它包装为自己的Channel,同时创建一些基本的组件并绑定。然后调用init方法,初始化channel,最重要的就是为服务端Channel创建一个连接处理器,随后调用register注册Selector,即将JDK底层Channel绑定到Selector,并将Netty的服务端channel作为attachement绑定,最后调用dobind,并重新注册一个OP_ACCEPT事件,这样Netty就可以接收新的连接了。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka架构与核心概念]]></title>
    <url>%2F2018%2F06%2F24%2FKafka-%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[架构Kafka是是一个高性能跨语言分布式发布订阅消息队列系统,具有消息持久化,吞吐量高,支持消息分区等特点。Kafka自0.10版本提供对流式计算的支持。 Producer 提供消息的系统 Consumer 消费消息的系统 Broker 一个Kafka实例就是一个Broker,多个Kafka就是多个Broker构成的Kafka集群。Producer向某个Topic发送消息,Broker负责向订阅这个topic的所有consumer传递消息。 TopicKafka消息的发送和接收都依赖于Topic这个概念,producer把消息send到topic A,consumer订阅topic A,当producer发送消息,consumer就会接收到消息 Partition每个Topic都可以设置多个Partition,Partition是一个有序的队列,是topic物理上的分组,即一个磁盘上的文件夹,这样做的目的是为了提高Kafka的吞吐量。 实际上Producer发送一条消息到broker,消息会被分发到这个topic下的某个partition中,consuemr按照consumer group来接收数据.每个partition的数据只能由同一个consumer group的同一个consumer来消费,如果同时想要多个consumer消费一个partition,则需要设置不同的consumer group。 所以在设置Partition的数量时最好和consumer的数量保持一致,consumer多,则有的consumer没有数据可以消费,consumer少则其他的consumer负载就会过大。 在 Kafka 内部存在两种默认的分区分配策略：Range 和 RoundRobin,通过Java API我们可以更加灵活的控制消息分配到哪个Partition以及指定consumer消费哪个partition Range策略 Kafka的默认分配策略,首先对同一个topic里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序,如果除不尽,则前面的consumer group会多得到几个partition。例如，排完序的分区将会是0, 1, 2, 3, 4, 5, 6, 7, 8, 9；消费者线程排完序将会是C1-0, C2-0, C2-1。 123C1-0 将消费 0, 1, 2, 3 分区C2-0 将消费 4, 5, 6 分区C2-1 将消费 7, 8, 9 分区 offset每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset，用于partition唯一标识一条消息。Kafka对于消息可靠性的保证都是围绕着offset这一概念展开的。 对于一个消息系统,客户消费了哪些信息,即消费状态是一个消息系统必须提供的功能,Kafka提供3种消息传输一致性语义: at most once 消息最多发送一次,这种有可能造成数据丢失。consumer fetch消息,然后commit offset并处理消息。但是在消息处理过程中consumer进程失效(crash),导致消息未能完成处理.那么此后可能其他consumer会接管当前consumer的数据,但是因为offset已经commit,那么新的consumer将不能fetch到未处理完成的数据,这就是”at most once”. at least once 消息最少发送一次,会造成消息的重复消费。consumer fetch消息,然后处理消息commit offset.如果消息处理成功之后,但是在commit offset阶段zookeeper异常或其他原因,导致commit offset失败,这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是”at least once”. exactly once  并不是指真正只传输一次，只不过有一个机制。确保不会出现“数据被重复处理”和“数据丢失”的情况。最少1次＋consumer的输出中额外增加已处理消息最大编号：由于已处理消息最大编号的存在，不会出现重复处理消息的情况。 ReplicationKafka通过多副本机制实现故障自动转移，当Kafka集群中一个Broker失效情况下仍然保证服务可用。replication策略是基于partition,而不是topic。kafka将每个partition数据复制到多个server上,任何一个partition有一个leader和多个follower(可以没有)。replica的个数可以通过broker配置文件来设定。leader处理所有的read-write请求,follower需要和leader保持同步.Follower就像一个”consumer”,消费消息并保存在本地日志中。当生产者发送一条消息到Broker,leader写入消息。一条消息只有被ISR里的所有follower都从leader复制过去才会被认为已提交。而对于producer而言，它可以选择是否等待消息 commit，这可以通过 request.required.acks 来设置。消息复制延迟受最慢的follower限制,重要的是快速检测慢副本,如果follower”落后”太多或者失效,leader将会把它从replicas从ISR移除。 ISR队列 ISR即In-Sync Replica,Replica定期的主动向Leader请求同步数据。在默认情况下,只有在Isr中的replica才有资格进行leader 选举。如果配置了unclean.election=true,这种情况下虽然保证了可用性,但是会造成数据的大量丢失,也叫脏选举。 一个replica在isr中表示,这个副本与leader的状态非常接近,即使leader crash,这个副本也可以保证数据的丢失在可容忍的范围内。具体可以看两条配置: replica.lag.max.messages=3 replica.lag.time.max=500ms 表示副本的数据与leader相比最多相差三条,否则被踢出isr队列,同时必须在500ms内发送同步请求,否则也会被踢出isr。 Reblance触发rebalane 的时机 消费者加入或退出消费者组 消费者组订阅的topic出现分区数量变化 消费者调用unsubscrible取消对某topic的订阅 过程总体上可以分为两步:Join和Sync Join 所有成员都向协调器发送JoinGroup请求，请求入组。一旦所有成员都发送了JoinGroup请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader Sync 这一步leader开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进SyncGroup请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了 Leader 选举 如果partition所在的leader发生故障导致不可用，kafka会从该分区的其他的副本中选择一个作为新的Leader。之后所有的读写就会转移到这个新的Leader上。显然，只有那些跟Leader保持同步的Follower才应该被选作新的Leader。 Kafka会在Zookeeper上针对每个Topic维护一个称为ISR（in-sync replica，已同步的副本）的集合，该集合中是一些分区的副本。如果某个分区的Leader不可用，Kafka就会从ISR集合中选择一个副本作为新的Leader。 如果所有的ISR副本都失败了怎么办 此时有两种方法可选，一种是等待ISR集合中的副本复活，一种是选择任何一个立即可用的副本，而这个副本不一定是在ISR集合中(unclean.election).如果要等待ISR副本复活，虽然可以保证一致性，但可能需要很长时间。而如果选择立即可用的副本，则很可能该副本并不一致。]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka Streaming 分支]]></title>
    <url>%2F2018%2F06%2F24%2FKafka-Streaming-%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[Branch首先创建一个输入源 topic s-in,有多个partition ./kafka-topics.sh –create –topic s-in –partitions 3 –zookeeper localhost:2181 –replication-factor 1 ./kafka-topics.sh –create –topic s1 –partitions 1 –zookeeper localhost:2181 –replication-factor 1 ./kafka-topics.sh –create –topic s2 –partitions 1 –zookeeper localhost:2181 –replication-factor 1 我们可以通过一定的业务逻辑判断,让stream将不同的消息处理后发送给不同的topic,这里简单的通过判断字符串长度,发送给s1和s2两个不同的topic 1234567891011121314151617public class BranchStream &#123; public static void main(String[] args) &#123; Properties properties = new Properties(); properties.put(StreamsConfig.APPLICATION_ID_CONFIG,&quot;branch&quot;); properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;localhost:9092&quot;); properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass()); properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG,Serdes.String().getClass()); KStreamBuilder builder = new KStreamBuilder(); KStream&lt;String, String&gt;[] branch = builder.stream(Serdes.String(), Serdes.String(), &quot;s-in&quot;).branch((k, v) -&gt; v.length() &gt; 12, (k, v) -&gt; v.length() &lt;= 12); branch[0].mapValues(String::toUpperCase).to(&quot;s1&quot;); branch[1].mapValues(v-&gt;&quot;enhance&quot;+v).to(&quot;s2&quot;); KafkaStreams streams = new KafkaStreams(builder,properties); streams.start(); &#125;]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka Streaming 入门]]></title>
    <url>%2F2018%2F06%2F24%2FKafka-Streaming-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[什么是流式计算流的本质特征是one pass和sequence。可以想象一条管道,数据经过管道,在管道内经过一系列计算。数据以流的形式,不可逆的向前流动。大多数将响应异步的返回,然后增量地更新。一句话概括就是持续输入,持续输出,各个输入输出之间没有明显的边界。 Kafka Stream 优势在哪 目前流式计算已经有了很多成熟的框架,如spark streaming,strom以及flink。这些框架对于kafka的劣势就在于过于笨重,非常依赖于框架本身的调度,需要将流式的作业提交到计算平台,通过平台来计算。而Kafka流式计算则是提供一个库,通过调用Api即可实现流式计算,但是这些Api的数据来源都必须是一个Topic。所以相比于其他流式计算框架,Kafka streaming 更加轻量,仅依赖kafka本身。 但是Kafka streaming并不可能去替代spark streaming这样一种流计算框架,可以把它视作spark streaming的local model 由于kafka本身提供了诸如partition,replica,reblance,数据持久化等机制,所以Kafka streaming可以在线动态调整并行度,实现重新消费或者数据回滚等操作 Hello World实现一个简单的Kafka streaming的demo,需要本地运行Kafka环境。Demo的效果就是producer发送小写的hello world到topic “stream-in”,consumer 订阅 “stream-out” topic,而stream连接”stream-in”和”stream-out”,将输入的小写数据转换为大写 Maven 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt; &lt;version&gt;0.11.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-streams&lt;/artifactId&gt; &lt;version&gt;0.11.0.2&lt;/version&gt;&lt;/dependency&gt; 生产者 1234567891011121314151617public class AsyncSender &#123; public static void main(String[] args) &#123; Properties properties = FireAndForgetSender.initProps(); KafkaProducer&lt;String,String&gt; producer = new KafkaProducer&lt;String, String&gt;(properties); for (int i = 0; i &lt; 10; i++) &#123; ProducerRecord&lt;String,String&gt; record = new ProducerRecord&lt;String, String&gt;(&quot;stream-in&quot;,String.valueOf(i),&quot;hello word&quot;); producer.send(record, new Callback() &#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123; System.out.println(&quot;callback &quot; + recordMetadata.topic() ); &#125; &#125;); &#125; producer.flush(); producer.close(); &#125;&#125; 消费者 123456789101112131415161718192021222324public class SimpleConsumer &#123; public static Properties init()&#123; Properties properties = new Properties(); properties.put(&quot;bootstrap.servers&quot;,&quot;localhost:9092&quot;); properties.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); properties.put(&quot;value.deserializer&quot;,&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); properties.put(&quot;group.id&quot;,&quot;test&quot;); return properties; &#125; public static void main(String[] args) &#123; KafkaConsumer&lt;String,String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(init()); consumer.subscribe(Collections.singletonList(&quot;stream-out&quot;)); while (true)&#123; ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(100); consumerRecords.forEach(i-&gt;&#123; System.out.println(i.key()); System.out.println(i.value()); System.out.println(&quot;---------------&quot;); &#125;); &#125; &#125;&#125; stream 123456789101112131415public class Stream &#123; public static void main(String[] args) &#123; Properties properties = new Properties(); properties.put(StreamsConfig.APPLICATION_ID_CONFIG,&quot;SC&quot;); properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;localhost:9092&quot;); properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass()); properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG,Serdes.String().getClass()); KStreamBuilder builder = new KStreamBuilder(); builder.stream(Serdes.String(),Serdes.String(),&quot;stream-in&quot;).mapValues(String::toUpperCase).to(&quot;stream-out&quot;); KafkaStreams streams = new KafkaStreams(builder,properties); streams.start(); &#125;&#125;]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka消息可靠性保证]]></title>
    <url>%2F2018%2F06%2F24%2FKafka%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81%2F</url>
    <content type="text"><![CDATA[Reliability Guaranteeskafka会把每个topic分为若干个partition。可以把topic理解为一个表,partition就是它的多个分区,一个partition会存放到单独的一个磁盘。每个partition都有多个副本(replica),其中一个会被选举为leader,所有的读写操作都是由leader来执行，其他的副本仅仅是用来维持一个In-Sync的状态,也就是说follower会不断地向leader发起一些fetch request，获取数据。 一个副本被认为是处于In-Sync(可参与leader选举)的状态必须满足几个条件: 与zookeeper保持有效的连接 在一定时间内没有向leader发起fetch data 的 request(默认10秒) 不满足条件的broker会被加入到out-sync队列中,直到broker恢复与zk的连接,并且将数据同步到一个最小的临界值(LogEndOffset) Broker prevent data loss 副本机制保证了Kafka集群的可用性也保证了kafka的可靠性,通过配置副本因子N,允许丢失N-1个broker，但是这样会牺牲一些性能,参数的设置需要进行权衡。官方推荐的副本因子在3-5之间。 当leader挂掉之后,kafka集群会进行选举。处于In-Sync Replica(ISR)的副本有权力进行投票选举,详细可以看这篇文章 http://www.importnew.com/25247.html Unclean Election: 当leader挂掉,ISR队列没有可用的副本,那么Kalfk只能从(Out-sync Replica)OSR中选择一个副本作为leader,那么这样就造成了数据的丢失。在0.11的版本中,Kafka对这种情况的默认配置进行了修改,Kalfka不允许选择OSR中的replica作为leader,必须等到一个ISR中的Replica可用,这个partition才可以继续使用。在0.11版本之前是可以选举OSR中的replica进行读写操作的。也就是说在0.11之后,Kalfka增强了CP,减弱了AP.可以设置 unclean.leader.election.enable min.insync.replicas 这个配置用于指定多少个ISR中的副本同步到这个数据之后才返回写入成功,否则会返回一个Not Enough Replica异常 Producer deliver reliable一个非常关键的配置就是acks,提供了0,1,all三个选项。默认配置为0，表示producer只把数据发送出去,并不在乎数据到底有没有写入partition。1表示leader必须返回ack才认为这条数据写入成功,all则是该partition的leader和follower必须全部都同步到数据才会返回ack。为了保证数据的可靠性,acks显然不能设置为0 Consumer deliver reliableconsumer保证数据可靠性的一个重要参数就是offset,consumer每次会从broker拿到一批数据,并记录这批数据消费到了哪一个offset. 当同一个consumer group的一个consumer挂掉,另一个consumer会捡起挂掉consumer的工作，那么这台consumer就需要知道挂掉consumer的offset是多少。consumer对于offset的处理关乎数据的可靠性,吞吐量。 一种解决方式就是配置每次都从头开始读取数据(auto.offset.reset),但是这样有个限制,consumer不能是同一个group,否则还是会从offset开始处理,另外消息重复消费需要靠业务代码进行控制。 enable.auto.commit 该参数默认为true,但是自动提交并没有想象中的那样好用。例如consumer从broker拉取了30条数据,但是在处理到第10条数据的时候可能就会将offset=30提交，那么这样就可能造成10-30的数据丢失,所以要求数据可靠性时最好把这个参数关掉,手动控制offset的提交,一种比较推荐的代码格式如下: 1234567891011121314151617181920212223/** * 在try里面 异步提交 不会自动retry 降低吞吐量,在finally块里进行同步提交 * @param args */ public static void main(String[] args) &#123; KafkaConsumer&lt;String,String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(init()); consumer.subscribe(Collections.singletonList(&quot;fireAndForget&quot;)); try &#123; while (true) &#123; ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(100); consumerRecords.forEach(i -&gt; &#123; System.out.println(i.key()); System.out.println(i.value()); System.out.println(&quot;---------------&quot;); &#125;); consumer.commitAsync(); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; consumer.commitSync(); &#125; &#125; Consumer Reblance,由于rebalace的操作对导致整个group停止向 broker fetch data的操作,并重新分配message,这时就有可能造成数据的duplicate]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统学习ElasticSearch-简单聚合分析(4)]]></title>
    <url>%2F2018%2F03%2F31%2F%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0ElasticSearch-%E8%81%9A%E5%90%88%E5%88%86%E6%9E%90-4%2F</url>
    <content type="text"><![CDATA[环境方面继续使用上一篇的数据环境,根据模拟不同的需求,体验不同的聚合分析语法 简单聚合: 计算每个tag下的商品数量 12345678910GET /ecomic/product/_search&#123; &quot;aggs&quot;: &#123; &quot;group_by_tag&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;tags&quot; &#125; &#125; &#125;&#125; 语法如上,但是返回结果可能会出现如下错误: default. Set fielddata=true on [tags] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory. Alternatively use a keyword field instead.” 这段错误提示的意思就是需要对索引进行一些额外的配置,fielddata=true,因为我们在使用聚合功能的时候,ES会对索引进行正排,并且把正排数据放入内存中来进行聚合分析操作,具体的fielddata会在以后解释。 这里我们需要一些操作 123456789PUT /ecomic/_mapping/product&#123; &quot;properties&quot;:&#123; &quot;tags&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;fielddata&quot;:true &#125; &#125;&#125; 这样再次使用聚合查询就可以了,并且在返回结果中多了这样一个字段 12345678910111213141516171819&quot;aggregations&quot;: &#123; &quot;group_by_tags&quot;: &#123; &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;fangzhu&quot;, &quot;doc_count&quot;: 4 &#125;, &#123; &quot;key&quot;: &quot;meibai&quot;, &quot;doc_count&quot;: 4 &#125;, &#123; &quot;key&quot;: &quot;sb&quot;, &quot;doc_count&quot;: 3 &#125; ] &#125; 其中bucket就是对聚合结果进行分组,每个tag就是一个bucket。这样就是一个简单的数据聚合,可以发现,聚合数据还返回了原有的全部数据,如果不想返回这些数据,只需要添加size:0就可以了。 1234567891011GET ecomic/product/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_tags&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;tags&quot; &#125; &#125; &#125;&#125; 聚合+搜索: 对名称中包含gaolujie的商品,计算每个tag的商品数量 12345678910111213141516GET ecomic/product/_search&#123; &quot;size&quot;: 0, &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;name&quot;: &quot;gaolujie&quot; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;group_by_tags&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;tags&quot; &#125; &#125; &#125;&#125; 很简单,aggs+query就可以做到先搜索再分析 嵌套聚合:计算每个tag下商品的平均价格 123456789101112131415161718GET ecomic/product/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_tags&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;tags&quot; &#125;, &quot;aggs&quot;: &#123; &quot;avg_price&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;price&quot; &#125; &#125; &#125; &#125; &#125;&#125; 可以看到我们先用aggs对tag进行了分组,分组之后再嵌套了一层aggs对价格求avg也就是平均值 加入排序: 我们使用3的数据,并对聚合价格进行降序排序 123456789101112131415161718192021GET ecomic/product/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_tags&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;tags&quot;, &quot;order&quot;: &#123; &quot;avg_price&quot;: &quot;desc&quot; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;avg_price&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;price&quot; &#125; &#125; &#125; &#125; &#125;&#125; 按照指定的价格范围区间进行分组.然后在每组内再按照tag进行分组,最后再计算每组的平均价格(这个需求看起来很复杂,单其实就是三层的aggs嵌套) 12345678910111213141516171819202122232425262728293031323334353637GET ecomic/product/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_price&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;price&quot;, &quot;ranges&quot;: [ &#123; &quot;from&quot;: 0, &quot;to&quot;: 30 &#125;,&#123; &quot;from&quot;: 30, &quot;to&quot;: 50 &#125;,&#123; &quot;from&quot;: 50, &quot;to&quot;: 100 &#125; ] &#125;, &quot;aggs&quot;: &#123; &quot;group_by_tags&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;tags&quot; &#125;, &quot;aggs&quot;: &#123; &quot;avg_price&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;price&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 如上,相比于需求4,增加了一个range字段,用于进行分组]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统学习ElasticSearch-多种搜索方式(3)]]></title>
    <url>%2F2018%2F03%2F30%2F%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0ElasticSearch-%E5%A4%9A%E7%A7%8D%E6%90%9C%E7%B4%A2%E6%96%B9%E5%BC%8F-3%2F</url>
    <content type="text"><![CDATA[ES中提供了多种索引的搜索方式,总结起来应该有六种,那么依次展示以下这些搜索方式,环境基于上一篇CRUD的数据。 Query String Search例如我想查找所有的商品信息,那么可以这样做 GET /索引名称/类型名称/_search 下面解释一下返回信息中几个关键字段的含义: 12345took: 耗费了多少毫秒shards: 这里数据被拆成了五个分配,那么对于搜索请求,会打到所有的primary shard(或者它的某个replica shard)上去,共成功了五个。hits.total: 查询结果的数量,共3个documentmax_score: document对于一个search的相关度的匹配分数,越相关分数就越高hits.hits:包含了匹配搜索的document的详细数据 接下来进行一下复杂一点的查询,要求商品名称包含gaolujie,并且按价格降序排序 get /ecomic/product/_search?q=name:gaolujie&amp;sort=price:desc 对于Query String这种方式来说,我们在生产环境中其实很少会用,因为它把参数全部放入了url中,所以构建一个复杂查询是非常困难的,仅限于学习测试。 Query DSLDSL全程是Domain Specified Language 特定领域语言,也就是ES中的特定语法 同样是查询所有商品,我们看一下语法: 1234Get /索引名称/类型名称/_search&#123; &quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125; DSL会将所有的查询条件放入query的body中,这样构建复杂的查询语法就比较容易 条件查询: 1234567891011GET /ecomic/product/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;name&quot;:&quot;gaolujie&quot; &#125; &#125;, &quot;sort&quot;:[ &quot;price&quot;:&quot;desc&quot; ]&#125; 这里有个细节要注意,如果使用Kibana,GET/POST/PUT/DELETE 一定要大写,否则返回值可能就是错误的 分页查询: GET /ecomic/product/_search { “query”:{“match_all”:{}}, “from”:1, “size”:2} 表示从第一条数据开始,共查询两条数据 指定要查询的字段: GET /ecomic/product/_search{ “query”:{“match_all”:{}}, “_source”: [“name”,”price”]} 这样查询就只包含name和price两个字段 Query Filter例如我们需要搜索商品名称包含gaolujie,并且售价大于30的商品 12345678910111213141516171819GET /ecomic/product/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;: &#123; &quot;must&quot;:&#123; &quot;match&quot;:&#123; &quot;name&quot;:&quot;gaolujie&quot; &#125; &#125;, &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;gt&quot;: 30 &#125; &#125; &#125; &#125; &#125;&#125; 与上面不同的是,查询的条件全都包含在query这个body中,这里bool的意思先不用理会,条件must表示必须匹配name:gaoluejie这个关键字,并且过滤出价格大于30的索引 全文检索全文检索本身的语法并不复杂 12345678GET /ecomic/product/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;: &#123; &quot;name&quot;: &quot;gaolujie yunnanbaiyao&quot; &#125; &#125;&#125; 可以看到就是使用了 query.match字段,这里的意图就是查询name中包含gaolujie或yunnanbaiyao的记录,这里因为我们使用的是英文,所以默认会按照空格进行分词,如果使用中文的话,我们需要对分词器进行配置,这一项后面会涉及到,所以目前都使用汉语拼音。 上面的请求就可以查询到name包含gaoluejie和yunnanbaiyao的记录,从下面的返回结果我们可以看出,不同的匹配词,_score的分数是不同的。在全文检索这个过程中,name首先会被拆分并建立倒排索引,根据倒排索引所匹配到的次数计算得分。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: 0.2876821, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;ecomic&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 0.2876821, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;yunnanbaiyao&quot;, &quot;desc&quot;: &quot;meibai&quot;, &quot;price&quot;: 40, &quot;producer&quot;: &quot;gaolujie&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot;, &quot;sb&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;ecomic&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;put2&quot;, &quot;_score&quot;: 0.25811607, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;gaolujie yagao1&quot;, &quot;desc&quot;: &quot;meibai&quot;, &quot;price&quot;: 40, &quot;producer&quot;: &quot;gaolujie&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot;, &quot;sb&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;ecomic&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.25811607, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;gaolujie yagao1&quot;, &quot;desc&quot;: &quot;meibai&quot;, &quot;price&quot;: 30, &quot;producer&quot;: &quot;gaolujie&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot;, &quot;sb&quot; ] &#125; &#125; ] &#125;&#125; Phrase Search(短语搜索)和全文检索相反,全文检索会将输入的字符串拆解,并到倒排索引中去匹配,只要能匹配上任意一个拆解后的单词,就可以返回 Phrase Search要求输入的字符串必须完整的存在于文本中,才能算匹配并返回 12345678GET /ecomic/product/_search&#123; &quot;query&quot;:&#123; &quot;match_phrase&quot;: &#123; &quot;name&quot;: &quot;gaolujie yunnanbaiyao&quot; &#125; &#125;&#125; 这样我们就完全命中不到数据了 高亮搜索这种搜索是非常常见的一种形式,例如我们百度搜索一下关键字都会用红色字体标注,比如我们进行全文检索,并对匹配到的关键词用标签进行包裹 12345678910111213GET /ecomic/product/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;: &#123; &quot;name&quot;: &quot;gaolujie yunnanbaiyao&quot; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123; &quot;name&quot;: &#123;&#125; &#125; &#125;&#125; 结果如下,匹配到的单词会被标注出来 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&#123; &quot;took&quot;: 27, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: 0.2876821, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;ecomic&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 0.2876821, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;yunnanbaiyao&quot;, &quot;desc&quot;: &quot;meibai&quot;, &quot;price&quot;: 40, &quot;producer&quot;: &quot;gaolujie&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot;, &quot;sb&quot; ] &#125;, &quot;highlight&quot;: &#123; &quot;name&quot;: [ &quot;&lt;em&gt;yunnanbaiyao&lt;/em&gt;&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;ecomic&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;put2&quot;, &quot;_score&quot;: 0.25811607, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;gaolujie yagao1&quot;, &quot;desc&quot;: &quot;meibai&quot;, &quot;price&quot;: 40, &quot;producer&quot;: &quot;gaolujie&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot;, &quot;sb&quot; ] &#125;, &quot;highlight&quot;: &#123; &quot;name&quot;: [ &quot;&lt;em&gt;gaolujie&lt;/em&gt; yagao1&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;ecomic&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.25811607, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;gaolujie yagao1&quot;, &quot;desc&quot;: &quot;meibai&quot;, &quot;price&quot;: 30, &quot;producer&quot;: &quot;gaolujie&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot;, &quot;sb&quot; ] &#125;, &quot;highlight&quot;: &#123; &quot;name&quot;: [ &quot;&lt;em&gt;gaolujie&lt;/em&gt; yagao1&quot; ] &#125; &#125; ] &#125;&#125; 以上就是ES中常用的几种搜索方式]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统学习ElasticSearch-CRUD(2)]]></title>
    <url>%2F2018%2F03%2F29%2F%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0ElasticSearch-CRUD-2%2F</url>
    <content type="text"><![CDATA[环境 ES 5.5 kibana 5.5 电商案例假设我们有一个java pojo 1234567public class product&#123; private String name; private String desc; private Integer price; private String producer; private List tags;&#125; 那么我们首先将pojo对应的一条数据存储到ES中,相信大家都知道将上上面的pojo存储到数据库中应该怎么做,ES是面向文档(document)的搜索分析引擎,文档中存储的数据结构,与面向对象的数据结构是一样的,基于这样的数据结构,ES可以提供复杂的索引,全文检索,分析聚合等功能,ES的document使用json来表达。 新增使用kibana的dev tools,新增的语法为: PUT /索引名称/类型名称/ID {数据} 如上我们建立了一个索引放入ES中,就像对数据库的表中加入了一条记录 查询查询的语法相对比较简单,这里的查询是指单单查找这一条记录,而不是根据条件进行搜索。 GET /索引名称/类型名称/ID {数据} 可以看到索引的一些基本信息,数据信息是在source下的,同时有一个version字段,表示这条索引的修改次数，同时也可以用于并发控制 修改修改索引有两种方式,第一种是替换,另一种是更新 先来看替换 PUT /索引名称/类型名称/ID {数据} 使用这种方式,对于没有更新的数据也要带上,否则就会认为没有这个字段 这里我们修改一下name字段,可以看到version自增,reslut和created字段也表明了更新成功。 更新文档方式 POST /索引名称/类型名称/ID/_update { “doc”:{“字段名”:数据}} 这种方式对于不需要修改的字段,不需要添加进去 可以看到通过这种方式,我们就将想修改的字段单独做了修改 删除 delete /索引名称/类型名称/ID 这样在使用get方式就无法查询到这条数据啦]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统学习ElasticSearch-概念(1)]]></title>
    <url>%2F2018%2F03%2F27%2F%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0ElasticSearch-%E6%A6%82%E5%BF%B5-1%2F</url>
    <content type="text"><![CDATA[Lucene和ESlucene是最强大最先进的搜索库,但是直接基于lucene开发,api非常复杂,不易扩展,需要深入理解原理(索引结构)。 ES直接基于lucene，隐藏复杂性，提供便利的rest API接口，强大之处在于 分布式,便于扩展 既可以作为搜索引擎,也可以作为数据分析引擎 支持PB级数据 开箱即用,优秀的默认设置,完全开源 核心概念 NRT(近实时):从数据写入到数据可以被搜索，延迟在秒级别。基于ES的搜索和分析耗时也在秒级别。 Cluster(集群): 包含多个节点,节点属于哪个集群是通过集群名称来进行配置的,(默认elasticsearch) Node(节点): 每个节点都有名称(默认随机分配),默认会加入elasticsearch这个集群,如果启动一堆节点,就会自动加入elasticsearch集群。 Document(文档): es中最小的数据单元,一个document可能是一条客户数据,一条订单数据,通常用json数据表示。每个index下的type，都可以存储多个document,每个document里都有多个field,一个field就是一个字段 Index(索引): 包含一堆有相似结构的文档数据,比如有一个客户索引,订单索引等,索引都有名称,index可以包含多个document Type(类型): 每个索引里都有一个或多个type,type是index中的一个逻辑分类,一个type下的document,都有相同的field。比如一个blog,有用户数据type,博客评论type,评论数据type shard: 单台机器无法存储大量的数据,es可以将索引中的数据切分为多个shard,分布在多台机器上存储。有了shard就可以横向扩展，提高吞吐量和性能,每个shard都是一个lucene index replica: 任何一个服务器都有可能随时宕机,此时shard就有可能丢失,因此可以给shard创建多个replica副本,用于备份容灾 对比数据库ES 数据库 Document 行 Type 表 Index 库]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-自己动手写跳表(13)]]></title>
    <url>%2F2018%2F03%2F02%2FJUC-%E8%B7%B3%E8%A1%A8-12%2F</url>
    <content type="text"><![CDATA[什么是跳表在我们日常工作中经常接触链表。对于链表这种数据结构我们再熟悉不过，那么我们也知道链表的一个缺点就是查找速度慢，因为它只能进行顺序的查找。那么如何对链表进行优化提高它的查询速度呢?我们可以借鉴AVL或者说二分查找的思路。首先链表必须有序,然后按照某种算法提取链表中的一些元素，我们对提取出来的元素做比较，就可以知道目标元素的大概位置。理论上,我们可以将查找的时间复杂度从O(n)降低到O(lgn)。在某些状态下，跳表这种数据结构可以和红黑树相媲美。用图形来展示可以更直观的理解跳表 如图所示就是跳表的一个简单结构,这里画的不太标准，其实每个元素之间是双向的连接，包括上下元素之间也是双向的。最底层就是我们的原链表,通过算法抽取其中的元素再向上加层。其实很容易理解，跳表这种数据结构就是一种典型的空间换时间算法,同时我们理想中的跳表结构就是这种小山的形状，因为这样最大程度上模拟了红黑树,将时间复杂度降为logN。 java8中提供了多种跳表的数据结构,因为这种结构看起来比较容易实现，所以我们可以先自己写代码模拟一下，因为这样可以发现难点在哪里。 自己写一个跳表首先观察跳表的整体结构,头结点、尾节点以及数据节点，我们对他们作标记 123private final static byte HEAD_NODE=(byte)-1;private final static byte DATA_NODE=(byte)0;private final static byte TAIL_NODE=(byte)-1; 可以将每个节点封装为Node，每个Node节点有上下左右四个方向的相邻节点。 1234567891011121314public static class Node&#123; private Integer value; private Node up,down,left,right; private byte bit; public Node(Integer value,byte bit)&#123; this.value=value; this.bit=bit; &#125; public Node(Integer value)&#123; this(value,DATA_NODE); &#125;&#125; 查找元素的方法,从整个跳表的最高层链表开始查起，如果ele等于目标元素,则直接降到最底层源链表的位置,如果没有找到相等的，则找到最后一个比ele元素小的元素,然后向下层链表查找，如果找到最后一层都没有相等的，则返回最后一个比ele小的元素。 123456789101112131415private Node find(Integer ele)&#123; Node current = head; for (;;)&#123; while (current.right.bit!=TAIL_NODE&amp;&amp;current.right.value&lt;=ele)&#123; current=current.right; &#125; if(current.down!=null)&#123; current =current.down; &#125;else &#123; break; &#125; &#125; return current;&#125; 最复杂的就是add方法,这里因为是双向链表，所以写的时候思路一定要清晰，否则就会出现链表链接乱的情况。 首先找到插入元素的左边和右边，然后修正链接关系。 然后简单的随机判断是否提取元素，如果需要则增加层高 12345678910111213141516171819202122232425262728293031323334353637383940414243public void add(Integer ele)&#123; //调整左右关系 Node near = find(ele); Node newNode = new Node(ele); Node rightNode = near.right; newNode.left=near; newNode.right=rightNode; rightNode.left=newNode; near.right=newNode; //是否增加层高 int currentLevel = 0; while (random.nextDouble()&lt;0.5d)&#123; if(currentLevel&gt;=height)&#123; height++; Node highHead = new Node(null,HEAD_NODE); Node highTail = new Node(null,TAIL_NODE); highHead.right=highTail; highTail.left=highHead; highHead.down=head; head.up=highHead; highTail.down=tail; tail.up=highTail; head=highHead; tail=highTail; &#125; while ((near!=null)&amp;&amp;near.up==null)&#123; near=near.left; &#125; near = near.up; Node upNode = new Node(ele); upNode.left=near; upNode.right=near.right; near.right.left = upNode; near.right=upNode; upNode.down = newNode; newNode.up=upNode; currentLevel++; &#125; size++; &#125; 最后自己又增加了一些简单的方法，便于观测。最终跳表的代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145public class MySkip &#123; private final static byte HEAD_NODE=(byte)-1; private final static byte DATA_NODE=(byte)0; private final static byte TAIL_NODE=(byte)-1; public static class Node&#123; private Integer value; private Node up,down,left,right; private byte bit; public Node(Integer value,byte bit)&#123; this.value=value; this.bit=bit; &#125; public Node(Integer value)&#123; this(value,DATA_NODE); &#125; &#125; private Node head; private Node tail; private int size; private int height; private Random random; public MySkip()&#123; this.head = new Node(null,HEAD_NODE); this.tail = new Node(null,TAIL_NODE); this.size=0; head.right=tail; tail.left = head; this.random = new Random(System.currentTimeMillis()); &#125; public boolean isEmpty()&#123; return size()==0; &#125; public int size()&#123; return size; &#125; private Node find(Integer ele)&#123; Node current = head; for (;;)&#123; while (current.right.bit!=TAIL_NODE&amp;&amp;current.right.value&lt;=ele)&#123; current=current.right; &#125; if(current.down!=null)&#123; current =current.down; &#125;else &#123; break; &#125; &#125; return current; &#125; public boolean contains(Integer ele)&#123; Node node = this.find(ele); if(node.value==ele)&#123; return true; &#125; return false; &#125; public Integer get(Integer ele)&#123; Node node = this.find(ele); return node.value==ele?node.value:null; &#125; public void add(Integer ele)&#123; //调整左右关系 Node near = find(ele); Node newNode = new Node(ele); Node rightNode = near.right; newNode.left=near; newNode.right=rightNode; rightNode.left=newNode; near.right=newNode; //是否增加层高 int currentLevel = 0; while (random.nextDouble()&lt;0.5d)&#123; if(currentLevel&gt;=height)&#123; height++; Node highHead = new Node(null,HEAD_NODE); Node highTail = new Node(null,TAIL_NODE); highHead.right=highTail; highTail.left=highHead; highHead.down=head; head.up=highHead; highTail.down=tail; tail.up=highTail; head=highHead; tail=highTail; &#125; while ((near!=null)&amp;&amp;near.up==null)&#123; near=near.left; &#125; near = near.up; Node upNode = new Node(ele); upNode.left=near; upNode.right=near.right; near.right.left = upNode; near.right=upNode; upNode.down = newNode; newNode.up=upNode; currentLevel++; &#125; size++; &#125; public void dumpList()&#123; Node temp = head; for(int i=height;i&gt;=0;i--)&#123; System.out.printf(&quot;total height [%d] current [%d]&quot;,height+1,i+1); Node node = temp.right; while (node.bit!=TAIL_NODE)&#123; System.out.printf(&quot;-&gt;%d&quot;,node.value); node=node.right; &#125; System.out.printf(&quot;\n&quot;); temp = temp.down; &#125; &#125; public static void main(String[] args) &#123; MySkip mySkip = new MySkip(); Random random = new Random(); for (int i = 0; i &lt; 10; i++) &#123; mySkip.add(random.nextInt(1000)); &#125; mySkip.dumpList(); &#125;&#125; 测试效果可以看到随机算法提取元素并不理想，生成的跳表有明显的偏向性。所以暂时可以得出一个结论，元素的提取算法是一个非常重要的部分，这个算法的好坏直接关系到跳表的可用性。明天继续看看JDK中是怎么解决跳表的这些问题。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch优化总结]]></title>
    <url>%2F2018%2F02%2F27%2FElasticSearch%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[索引结构优化一份没有经过优化的索引结构如下，由于单机版,这里备份数量和分片数量要根据生产中的实际情况来设置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&#123; &quot;settings&quot;: &#123; &quot;number_of_replicas&quot;: 0 &#125;, &quot;mappings&quot;: &#123; &quot;house&quot;: &#123; &quot;dynamic&quot;: false, &quot;properties&quot;: &#123; &quot;houseId&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;price&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;area&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;createTime&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;strict_date_optional_time||epoch_millis&quot; &#125;, &quot;lastUpdateTime&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;strict_date_optional_time||epoch_millis&quot; &#125;, &quot;cityEnName&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;regionEnName&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;direction&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;distanceToSubWay&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;subWayLineName&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;subWayStationName&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;tags&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;street&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;location&quot;:&#123; &quot;type&quot;:&quot;geo_point&quot; &#125;, &quot;district&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;description&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;layoutDesc&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;traffic&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;roundService&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;rentWay&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125; &#125; &#125; &#125;&#125; 文件读写方式优化文件的读写方式在不同的操作系统甚至不同位数的操作系统上都会有不同的实现，默认索引存储方式正是基于文件系统的存储。NIO是Java中一个高效的IO库，可以大幅度提高文件读写的吞吐量,所以我们可以指定使用nio的方式读写文件。由于JAVA NIO在windows系统会出现未修复的错误，所以不建议在windows系统中开启，但是在生产环境中，服务器一般都是linux机器，所以这时是可以打开的。 “index.store.type”:”niofs” 动态映射当ES在文档中碰到一个以前没见过的字段时,它会利用动态映射来决定该字段的类型,并自动地对该字段添加映射。所以当我们的索引结构相对稳定时，可以通过设置 “dynamic”:false 或者 “dynamic”:”strict” 来关闭es索引的动态映射,这个配置默认是true。 禁用_all es中的查询返回中除了_source之外还有一个_all字段，这个字段会将所有的索引字段添加空格并连接起来，有时候会利用这个字段做全文检索，但实际上性能非常差。如果使用最新的es6则不用担心这个问题，因为在es6中,_all已经被废弃了。 “_all”:{“enabled”:false} 默认索引字段 当_all字段不可用时，最佳实践是指定默认检索字段 “index.query.default_field”:”title” 恢复策略 Elasticsearch 将自动在可用节点间进行分片均衡，包括新节点的加入和现有节点的离线。 理论上来说，这个是理想的行为，我们想要提拔副本分片来尽快恢复丢失的主分片。 我们同时也希望保证资源在整个集群的均衡，用以避免热点。 然而，在实践中，立即的再均衡所造成的问题会比其解决的更多。举例来说，考虑到以下情形： Node（节点） 19 在网络中失联了（某个家伙踢到了电源线)Master 立即注意到了这个节点的离线，它决定在集群内提拔其他拥有 Node 19 上面的主分片对应的副本分片为主分片在副本被提拔为主分片以后，master 节点开始执行恢复操作来重建缺失的副本。集群中的节点之间互相拷贝分片数据，网卡压力剧增，集群状态尝试变绿。由于目前集群处于非平衡状态，这个过程还有可能会触发小规模的分片移动。其他不相关的分片将在节点间迁移来达到一个最佳的平衡状态与此同时，那个踢到电源线的倒霉管理员，把服务器插好电源线进行了重启，现在节点 Node 19 又重新加入到了集群。不幸的是，这个节点被告知当前的数据已经没有用了， 数据已经在其他节点上重新分配了。所以 Node 19 把本地的数据进行删除，然后重新开始恢复集群的其他分片（然后这又导致了一个新的再平衡） 如果这一切听起来是不必要的且开销极大，那就对了。是的，不过前提是你知道这个节点会很快回来。如果节点 Node 19 真的丢了，上面的流程确实正是我们想要发生的。 为了解决这种瞬时中断的问题，Elasticsearch 可以推迟分片的分配。这可以让你的集群在重新分配之前有时间去检测这个节点是否会再次重新加入。一般我们可以设置为5分钟。 “index.unassigned.node_left.delayed_timeout”: “5min” 经过一些简单优化之后,索引设置如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&#123; &quot;settings&quot;: &#123; &quot;number_of_replicas&quot;: 0, &quot;index.store.type&quot;:&quot;niofs&quot;, &quot;index.query.default_field&quot;:&quot;title&quot;, &quot;index.unassigned.node_left.delayed_timeout&quot;: &quot;5min&quot; &#125;, &quot;mappings&quot;: &#123; &quot;house&quot;: &#123; &quot;dynamic&quot;: false, &quot;_all&quot;:&#123; &quot;enabled&quot;:false &#125;, &quot;properties&quot;: &#123; &quot;houseId&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;price&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;area&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;createTime&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;strict_date_optional_time||epoch_millis&quot; &#125;, &quot;lastUpdateTime&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;strict_date_optional_time||epoch_millis&quot; &#125;, &quot;cityEnName&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;regionEnName&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;direction&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;distanceToSubWay&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;subWayLineName&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;subWayStationName&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;tags&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;street&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;location&quot;:&#123; &quot;type&quot;:&quot;geo_point&quot; &#125;, &quot;district&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;description&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;layoutDesc&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;traffic&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;roundService&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;analyzed&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;rentWay&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125; &#125; &#125; &#125;&#125; 配置优化 禁用通配符 比如两条索引结构esa和esb,这时我们可以通过es*删除这两条索引。但这时很有可能造成误删，因为es的索引不可恢复，所以出于安全考虑，要禁用通配符 这里的transient可以替换为persistent,区别是transient在es重启后会失效,而persistent不会。 刷新时间 es默认的索引刷新时间是每秒钟进行一次，如果需要更高的性能则可以降低刷新的频率,设置为30s一次。这个配置不支持动态的修改，所以要在配置文件中添加配置项后重启生效。 index.refresh_interval:30s 集群发现超时优化 集群之间需要进行通信，来确定节点是否添加或丢失，进而进行一些决策。当集群压力很大，jvm就会频繁的进行gc，某些节点就可能出现stw现象。节点之间通信失败，就会造成分片数据的重新分配。但其实这个过程是我们不想看到的。短时间内回复几十甚至几百G的消耗都是非常大的。这时我们可以调整ping的参数来避免这种现象。同样要在配置文件中修改: discovery.zen.fd.ping_interval:10sdiscovery.zen.fd.ping_timeout: 120sdivcovery.zen.fd.ping_retries: 5 在5.x以上的版本中，支持通过http动态修改interval,所以在5.x以上版本这样设置是会报错的。所以5.x版本可以这样设置。 各司其职 在配置文件中有这样的默认配置: 123node.name:xxxnode.master:truenode.data:true 这表明这个节点既可以成为master节点，也可以成为数据节点。但其实我们可以让节点只做一项工作，来减少性能的消耗，提高稳定性。比如配置3个节点作为master节点，只用来指挥调度不参与数据存储。更多的节点用于存储数据而不参与指挥调度。具体配置视服务器情况而定。 对于数据节点，我们可以关闭它的http功能，而只留下tcp功能做数据交互。配置如下: http.enable: false 所以这时一些监控插件或者工具就只能运行在master节点上了。 另外还有一种节点叫做负载均衡节点,这种节点master为false,data也是false.主要用来查询时候做负载均衡，由于分布式的原因，我们需要在不同的节点上查询数据最终汇总到客户端，这时这个节点就会用来做汇总工作与客户端交互，但是很多时候我们并不会用es的节点来做负载均衡，因为这样做单节点的压力会非常大，常见的工具就是NGINX，因为它的性能更好。 内存大小 内存的大小并不是越大越好，因为es是运行在jvm上，jvm中会有默认的-Xms和-Xmx限制内存的大小，所以最终是由jvm决定。由于jvm的指针压缩技术在内存大于32G的时候是不会启用的，所以es内存的设置最大不要超过32G，否则很容易就OOM了。及时你可用为64G内存，也应该设置为两个32G的内存。 SSD 由于es是一个基于文件系统的操作，所以使用SSD能更好的发挥性能优势。 基于NGINX负载均衡使用的NGINX版本为1.12,ES版本为5.6。如果使用nginx1.9及以下的版本是需要额外安装模块的。首先nginx需要开启一项配置。 ./configure –with-stream 然后进入nginx.config文件添加配置 12345678910stream&#123; upstream backend&#123; server 127.0.0.1:9300; &#125; server&#123; listen 9999; proxy_timeout:20s proxy_pass backend; &#125;&#125; 这时我们就可以通过9999端口访问ES集群了，新增ES节点只需要在upstream中添加地址就可以了。 基础运维当项目上线,地址都是向外暴露的，所以安全配置是非常重要的。主要是配置一下nginx和es的安全策略。 首先把上面对nginx的配置注释掉，或者使用一个新的nginx。 当我们使用es的时候,可能会启动一些图形化界面来观察es的运行情况与索引结构，这里我用了elasticsearch-head插件,如果插件的启动ip暴露，攻击者就可以看到我们的集群状况并且进行攻击。 首先打开es的配置文件: 可能已经配置了如下的文件,这种就是方便个人开发测试,线上肯定是不合适的 12network.host : 0.0.0.0network.publish_host: xx.xx.xx.xx 对其进行修改 12network.host:127.0.0.1#network.publish_host: xx.xx.xx.xx 这时再使用公网ip就访问不到es了，但是这时你希望可以和其他同事合作，让某些人可以看到，这时就要用到nginx了。 修改nginx配置文件: 12345678910111213141516upstream es&#123; server: 127.0.0.1:9200&#125;server&#123; listen: 8888; server_name: localhost; auth_basic &quot;Protection&quot; auth_basic_user_file /usr/local/nginx/pwd/passwords location / &#123; proxy_pass http://es; proxy_redirect off; &#125;&#125; auth_basic_user_file 这里的路径配置做法是: 1234cd /usr/local/nginx/pwdprintf &quot;sc:$(openssl passwd -crypt 123)\n&quot; &gt; passwords这时路径下会有一个passwords文件,将路径拷贝就可以了 这时访问服务使用8888端口了，但是会发现elasticsearch-head插件还是无法连接。这时访问的路径是: 1xx.xx.xx.xx:9100/?auth_user=sc&amp;auth_password=123&amp;base_uri=http://xx.xx.xx.xx:8888 打开调试可以发现是因为跨域访问的问题，所以如果需要跨域访问可以继续添加配置: 123456789101112131415161718192021server&#123; listen: 8888; server_name: localhost; auth_basic &quot;Protection&quot; auth_basic_user_file /usr/local/nginx/pwd/passwords location / &#123; proxy_pass http://es; proxy_redirect off; if(request_method=&apos;OPTIONS&apos;)&#123; add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;; add_header &apos;Access_Control-Allow-Methods &apos;GET ,POST,PUT,OPTIONS&apos; add_header &apos;Access-Control-Allow-Header&apos; &apos;Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range&apos;; add_header &apos;Access-Control-Max-Age&apos; &apos;172800&apos;; add_header &apos;Content-Type&apos; &apos;text/plain;charset=utf-8&apos;; add_header &apos;Content-Length&apos; 0; return 204; &#125; &#125;&#125; 重启nginx之后,head插件应该就可以使用了，服务也走了安全的代理。同时这里禁止掉了Delete操作，也就是说只有本机才能进行delete操作，通过nginx传过来的请求则不允许删除。 通过以上的配置，就完成对es的安全访问。你可以通过head插件访问 1xx.xx.xx.xx:9100/?auth_user=sc&amp;auth_password=123&amp;base_uri=http://xx.xx.xx.xx:8888 也可以通过 xx.xx.xx.xx:8888输入用户名密码访问 但此时可能发现,有时候我们进行一些get等一些无害的查看操作还是需要验证，比如上面的head插件的url，还是相当于暴露了服务地址，并没有起到作用，对于head插件中查看的一些操作，我们不想进行权限拦截，那么我们可以继续配置nginx，添加location。 123456789101112131415161718192021222324252627282930313233343536location @general &#123; proxy_pass http://es; proxy_redirect off;&#125;location @need_protection&#123; proxy_pass http://es; proxy_redirect off; auth_basic &quot;Protection&quot; auth_basic_user_file /usr/local/nginx/pwd/passwords&#125;location / &#123; if(request_method=&apos;OPTIONS&apos;)&#123; add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;; add_header &apos;Access_Control-Allow-Methods &apos;GET ,POST,PUT,OPTIONS&apos; add_header &apos;Access-Control-Allow-Header&apos; &apos;Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range&apos;; add_header &apos;Access-Control-Max-Age&apos; &apos;172800&apos;; add_header &apos;Content-Type&apos; &apos;text/plain;charset=utf-8&apos;; add_header &apos;Content-Length&apos; 0; return 204; &#125; //状态码设置随意 一般是一些用不到的 error_page 598 @general; error_page 599 @need_protection; if($request_uri ~ ^/(_cat|_cluster)/.*$)&#123; return 598; &#125; return 599; &#125; 通过上面的设置就对用户进行了简单的分组，当访问_cat路径和_cluster下的接口不需要身份验证，其它路径则需要身份验证。这样暴露这些接口可以方便我们自己写代码对es集群的健康状况进行监控.]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-CompletableFuture使用(12)]]></title>
    <url>%2F2018%2F02%2F16%2FJUC-CompletableFuture%E4%BD%BF%E7%94%A8-12%2F</url>
    <content type="text"><![CDATA[简介CompletableFuture是java8中新加入的一个API，主要的目的是解决future的使用痛点:调用get()方法会陷入阻塞。CompletableFuture的思想就是你不需要来问我任务有没有完成而是当我任务完成了主动返回给你。 基本使用Stage 1因为CompletableFuture的参数大部分都是lambda表达式的形式，所以需要有一些lambda表达式的基础，本篇使用了大量java8的新特性。 这是一个CompletableFuture的简单使用，首先通过工厂方法supplyAsync提交一个任务。这里也可以使用new关键字创建一个CompletableFuture对象，然后再来调用方法，只是这样做太多余。supplyAsync提交的任务必须要有返回值，因为没有返回值也就没必要用CompletableFuture来做了，提交的任务简单sleep 2s，main方法中打印一句话验证是否阻塞。 123456789101112131415161718public class cf1 &#123; public static void main(String[] args) &#123; CompletableFuture.supplyAsync(cf1::getSomeThing).whenComplete((v,t)-&gt;&#123; Optional.ofNullable(v).ifPresent(System.out::println); Optional.ofNullable(t).ifPresent(System.out::println); &#125;); System.out.println(&quot; i am not blocked&quot;); &#125; public static String getSomeThing()&#123; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return &quot;success&quot;; &#125;&#125; 结果: i am not blocked 可以发现主线程输出之后直接结束了，这显然不是我们想要的效果，为什么会直接退出呢。 通过看源码可以得到原因: CompletableFuture内部使用了一个ForkJoinPool，ForkJoinPool将内部的线程设置为了守护线程，所以在主线程退出后，异步任务也就退出了。一个解决方法就是在main方法内join()，这样就可以看到CompletableFuture的返回值，但是这样做的缺点是没有中断信号，程序永远不会退出。这个问题可能在实际项目中不太会遇到，因为实际项目是一直跑在服务器的，不会出现提前退出。 实际上我们可以通过Executors框架来使用CompletableFuture，因为Executors工厂类提供的工厂方法将线程都设置为非守护线程,这样看起来就优雅了很多。 12345678910111213141516171819public class cf1 &#123; public static void main(String[] args) throws InterruptedException &#123; ExecutorService pool = Executors.newFixedThreadPool(4); CompletableFuture.supplyAsync(cf1::getSomeThing,pool).whenComplete((v,t)-&gt;&#123; Optional.ofNullable(v).ifPresent(System.out::println); Optional.ofNullable(t).ifPresent(System.out::println); &#125;); System.out.println(&quot; i am not blocked&quot;); &#125; public static String getSomeThing()&#123; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return &quot;success&quot;; &#125;&#125; Stage 2现在我们成功打印出了success,那么如果我想在上面的任务完成以后对success进行一下处理呢，比如说在success之后添加几个字符。 首先添加一个简单的方法 12345678public static String addCharacter(String stage1)&#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return stage1+&quot; success2&quot;;&#125; 调用方法 1234567CompletableFuture .supplyAsync(cf1::getSomeThing,pool) .thenApply(cf1::addCharacter) .whenComplete((v,t)-&gt;&#123; Optional.ofNullable(v).ifPresent(System.out::println); Optional.ofNullable(t).ifPresent(System.out::println); &#125;); 输出结果: 12 i am not blockedsuccess success2 简单模拟调用了CompletableFuture几个最基本的Api，模拟一个实际场景并使用可以很好的记住它。现在假设有个商店，我要对5个商品，根据id取出商品，并对商品的价格*10。对于上面的方法，我们可以对一个商品进行这样的操作，那么5个商品该如何操作呢。 12345678910111213141516171819202122232425public class cf1 &#123; public static void main(String[] args) throws InterruptedException &#123; ExecutorService pool = Executors.newFixedThreadPool(4); List&lt;Integer&gt; ids = Arrays.asList(1, 2, 3, 4, 5); List&lt;Double&gt; res = ids.stream() .map(i -&gt; CompletableFuture.supplyAsync(() -&gt; queryProduct(i), pool)) .map(future -&gt; future.thenApply(cf1::multiply)) .map(CompletableFuture::join) .collect(toList()); System.out.println(res); &#125; public static Double multiply(Double price)&#123; System.out.println(price); return price*10; &#125; public static double queryProduct(int id)&#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return new Random(System.currentTimeMillis()).nextInt(20); &#125; 输出结果: 12345613.013.017.01.04.0[130.0, 130.0, 170.0, 10.0, 40.0] 这里使用java8中的stream语法，当然也可以拆开来做，效果是相同的。 其他APICompletableFuture还有大量的API，但是有很多功能都是相似的。这里挑选几个功能比较典型的来感受一下。 whenComplete&amp; whenCompleteAsync首先还是上面提到的api，简单的调用一下，最后打印11。whenComplete的调用方式是同步的，whenCompleteAsync则是异步的调用，如果你对结果需要进行耗时的处理，那么可以使用异步的方法。 12345CompletableFuture .supplyAsync(()-&gt;1) .thenApply(i-&gt;Integer.sum(i,10)) .whenComplete((v,t)-&gt; System.out.println(v)); TimeUnit.SECONDS.sleep(3); 12345CompletableFuture .supplyAsync(()-&gt;1) .thenApply(i-&gt;Integer.sum(i,10)) .whenCompleteAsync((v,t)-&gt; System.out.println(v));TimeUnit.SECONDS.sleep(3); handle&amp;&amp;handleAsync对于上面的方法，可以使用handle来替换。可以看到hanle方法替换了thenApply，区别就是在这一步handle方法考虑到了出现异常，如果有可能出现异常，那么可以使用handle方法。方法handleAsync就是异步的执行了。 12345678910CompletableFuture .supplyAsync(()-&gt;1) .handle((v,t)-&gt;&#123; if(t!=null)&#123; t.printStackTrace(); &#125; return Integer.sum(v,10); &#125;) .whenCompleteAsync((v,t)-&gt; System.out.println(v)); TimeUnit.SECONDS.sleep(3); thenRun&amp;&amp;thenRunAsyncthenRun方法接受的参数是一个runable,这里简单的调用一下这个方法，效果就是多打印一个空行。那么thenRun和thenRunAsync方法的区别是什么呢，thenRun接受runnable之后则开启一个线程执行，而thenRunAsync则是将runnable交给CompletableFuture的线程池来执行。 1234567891011CompletableFuture .supplyAsync(()-&gt;1) .handle((v,t)-&gt;&#123; if(t!=null)&#123; t.printStackTrace(); &#125; return Integer.sum(v,10); &#125;) .whenCompleteAsync((v,t)-&gt; System.out.println(v)) .thenRun(System.out::println);TimeUnit.SECONDS.sleep(3); thenAccept&amp;&amp;thenAcceptAsync123CompletableFuture .supplyAsync(()-&gt;1) .thenAccept(System.out::println); thenAccept方法接收的参数是一个consumer，也就是说它只会进行消费，没有返回值。当然这个方法在上面的练习中可以替换whenComplete方法 thenCompose&amp;&amp;thenComposeAsyncthenCompose可以用来组合CompletableFuture，也就是一个forkJoinPool调用了另一个ForkJoinPool去执行任务。 12345CompletableFuture .supplyAsync(()-&gt;1) .thenCompose(i-&gt;CompletableFuture.supplyAsync(()-&gt;Integer.sum(i,10))) .thenAccept(System.out::println);TimeUnit.SECONDS.sleep(3); thenCombine&amp;&amp;thenCombineAsyncthenCombine方法用于处理两个CompletableFuture的返回值,这里简单的将两个返回值做了乘法。 1234CompletableFuture .supplyAsync(()-&gt;1) .thenCombine(CompletableFuture.supplyAsync(()-&gt;10),(c1,c2)-&gt;c1*c2) .thenAccept(System.out::println); thenAcceptBoth&amp;&amp;thenAcceptBothAsyncthenAcceptBoth方法的使用和thenCombine方法相同，区别在于thenAcceptBoth没有返回值，也就是无法将操作值继续传递下去。 runAfterBoth&amp;&amp;runAfterBothAsyncrunAfterBoth需要传入两个参数，第一个参数是一个completableFuture，第二个参数是一个runnable。在两个completableFuture任务完成后，会调用runnable。 123456789101112131415 public static void main(String[] args) &#123; CompletableFuture.supplyAsync(()-&gt; &#123; System.out.println(Thread.currentThread().getName()+&quot;done&quot;); return 1; &#125;) .runAfterBoth(CompletableFuture.supplyAsync(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+&quot;done&quot;); return 1; &#125;),()-&gt; System.out.println(&quot;ALL DONE&quot;)); &#125;ForkJoinPool.commonPool-worker-1doneForkJoinPool.commonPool-worker-1doneALL DONE applyToEither&amp;&amp; applyToEitherAsync用法与runAfterBoth相同，却别是applyToEither是等两个completableFuture都完成才可以执行runnable,而applyToEither是任何一个完成就会调用runnable。但是要注意的是，一个任务完成以后，另一个任务不会被杀死，会继续计算，所以一定要注意这种游离线程的回收，否则时间久了可能对服务器造成影响。 1234567891011public static void main(String[] args) throws InterruptedException &#123; CompletableFuture.supplyAsync(()-&gt; &#123; System.out.println(Thread.currentThread().getName()+&quot;done&quot;); return 1; &#125;).applyToEither(CompletableFuture.supplyAsync(()-&gt;&#123; System.out.println(&quot;stage2&quot;); return 2; &#125;),i-&gt;i*10).thenAccept(System.out::println); Thread.currentThread().join();&#125; 另外这里我们可以发现一个规律，带apply关键字的都是有返回值的，accept则没有返回值。 acceptEither&amp;&amp; acceptEitherAsync和上面的函数参数相同，区别就在于第二个参数是一个consumer，只能消耗计算结果，不产生返回值。 runAfterEither&amp;&amp;runAfterEitherAsync和上面的函数参数相同，区别就在于第二个参数是一个runnable，不接收参数，可以用来做一些通知的动作。 allofallof函数接收一个CompletableFuture的数组，等待数组中所有任务完成之后会执行后续的动作。 123456789public static void main(String[] args) throws InterruptedException &#123; List&lt;CompletableFuture&lt;Object&gt;&gt; list = Arrays.asList(1, 2, 3, 4, 5) .stream() .map(i -&gt; CompletableFuture.supplyAsync(cf3::doSomething)) .collect(toList()); CompletableFuture.allOf(list.toArray(new CompletableFuture[list.size()])) .thenRun(()-&gt; System.out.println(&quot;done&quot;)); Thread.currentThread().join();&#125; 这里在allof之后调用了thenRun方法，打印一行通知。 anyofanyof的使用和allof相同，区别在于allof等待所有任务完成，anyof等待任意一个任务完成之后便继续执行。同样剩余的任务也会继续执行，不会被回收，所以调用any类型的方法时应该注意游离线程的回收。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-阻塞队列(11)]]></title>
    <url>%2F2018%2F02%2F13%2FJUC-%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97-11%2F</url>
    <content type="text"><![CDATA[在第十节Executor框架中，看到了阻塞队列这种结构。之前没有仔细看过，今天看看源码，大概都有哪些实现方式。 BlockingQueue的出现，简化了生产者-消费者场景的复杂性。BlockingQueue的特性就是当队列中不存在元素的时候，取出元素方法陷入阻塞。当队列满的时候，插入元素方法陷入阻塞。 BlockingQueue接口阻塞队列的顶级接口BlockingQueue中的方法如图，其中remove(o)移除元素o，drainTo()将当前队列中的元素复制到集合c并清空队列。 12345678910111213141516171819202122232425262728293031323334public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; &#123; //将指定的元素插入到此队列的尾部（如果立即可行且不会超过该队列的容量） //在成功时返回 true，如果此队列已满，则抛IllegalStateException。 boolean add(E e); //将指定的元素插入到此队列的尾部（如果立即可行且不会超过该队列的容量） // 将指定的元素插入此队列的尾部，如果该队列已满， //则在到达指定的等待时间之前等待可用的空间,该方法可中断 boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException; //将指定的元素插入此队列的尾部，如果该队列已满，则一直等到（阻塞）。 void put(E e) throws InterruptedException; //获取并移除此队列的头部，如果没有元素则等待（阻塞）， //直到有元素将唤醒等待线程执行该操作 E take() throws InterruptedException; //获取并移除此队列的头部，在指定的等待时间前一直等到获取元素， //超过时间方法将结束 E poll(long timeout, TimeUnit unit) throws InterruptedException; //从此队列中移除指定元素的单个实例（如果存在）。 boolean remove(Object o); //除了上述方法还有继承自Queue接口的方法 //获取但不移除此队列的头元素,没有则跑异常NoSuchElementException E element(); //获取但不移除此队列的头；如果此队列为空，则返回 null。 E peek(); //获取并移除此队列的头，如果此队列为空，则返回 null。 E poll(); java8提供了以下七种BlockingQueue的实现，blockingQueue的实现都保证是线程安全的。 ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。 PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。 DelayQueue：一个使用优先级队列实现的无界阻塞队列。 SynchronousQueue：一个不存储元素的阻塞队列。 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 ArrayBlockingQueue12345678public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();&#125; 从构造函数可以看出ArrayBlockingQueue是支持公平或非公平的访问，同时队列对非空和非满的情况分别加锁，内部存储的数据结构是Object[]类型。 添加元素 123456789101112131415public boolean offer(E e) &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; if (count == items.length) return false; else &#123; enqueue(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; 逻辑很简单，首先判断添加的元素必须非空，然后加锁，判断长度是否越界，如果没有则入队，否则返回false，最后释放锁。 取出元素 123456789public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; 首先加锁，判断队列是否为空，若不为空则出队一个元素，否则返回null。最后释放锁。 ArrayBlockingQueue的整体实现都比较简单，除了核心的入队出队方法，还提供了一些监控队列的方法。比较简单的一种阻塞队列实现，不作过多分析。 LinkedBlockingQueueLinkedBlockingQueue在内部将每个添加进来的元素封装为一个Node节点，并记录前驱节点。 1234567static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125;&#125; LinkedBlockingQueue按照先进先出排序(FIFO),新的元素插入到tail，每次取出head元素。队列的最大容量是Integer.MAX_VALUE，这里需要注意，如果不手动设置大小，并且生产者生产速度大于消费速度，那么很有可能造成内存泄漏(OOM)。LinkedBlockingQueue内部分别使用了takeLock 和 putLock 对并发进行控制，也就是说，添加和删除操作并不是互斥操作，可以同时进行，这样也就可以大大提高吞吐量。 添加元素 12345678910111213141516171819202122232425262728293031public boolean offer(E e) &#123; //添加元素为null直接抛出异常 if (e == null) throw new NullPointerException(); //获取队列的个数 final AtomicInteger count = this.count; //判断队列是否已满 if (count.get() == capacity) return false; int c = -1; //构建节点 Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; //再次判断队列是否已满，考虑并发情况 if (count.get() &lt; capacity) &#123; enqueue(node);//添加元素 c = count.getAndIncrement();//拿到当前未添加新元素时的队列长度 //如果容量还没满 if (c + 1 &lt; capacity) notFull.signal();//唤醒下一个添加线程，执行添加操作 &#125; &#125; finally &#123; putLock.unlock(); &#125; // 由于存在添加锁和消费锁，而消费锁和添加锁都会持续唤醒等到线程，因此count肯定会变化。 //因为初始化c=-1,这里的if条件表示如果队列中还有1条数据 if (c == 0) signalNotEmpty();//如果还存在数据那么就唤醒消费锁 return c &gt;= 0; // 添加成功返回true，否则返回false &#125; 这里的一个技巧就是对c值的处理，初看起来让人感觉摸不着头脑。首要要明确的是 c = count.getAndIncrement()实际上获取的是元素未入队之前的长度，如果c=0,那么实际上队列中有一个等待被消费的元素。因为消费线程一旦被唤醒是一直在消费的（前提是有数据），所以判断c&gt;0其实没有任何特殊意义。只有当c=0的时候，说明之前队列中没有元素，消费者陷入阻塞，那么这时添加元素之后对其进行唤醒才有意义。(这里还是比较绕的) 取出元素 123456789101112131415161718192021public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; notEmpty.await(); &#125; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125; 与添加元素的逻辑正好相反，理解一个另一个就很好理解，不作过多解释。 PriorityBlockingQueue123456789public PriorityBlockingQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator) &#123; if (initialCapacity &lt; 1) throw new IllegalArgumentException(); this.lock = new ReentrantLock(); this.notEmpty = lock.newCondition(); this.comparator = comparator; this.queue = new Object[initialCapacity];&#125; 根据构造函数可知，可以控制的参数是容量和比较规则，capacity默认大小为11，默认的比较器为null表示自然排序。可以根据需求控制PriorityBlockingQueue优先级从高到低还是从低到高。与ArrayBlockingQueue类似，队列中的元素都封装为object[]。 1private final Condition notEmpty; 可以看到的是PriorityBlockingQueue并不会阻塞数据生产者，而只是在没有可消费的数据时阻塞数据的消费者，因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。 PriorityBlockingQueue的方法都比较简单，没有什么特别坑的地方。 ###DelayQueue DelayQueue的关键元素BlockingQueue、PriorityQueue、Delayed。可以这么说，DelayQueue是一个使用优先队列（PriorityQueue）实现的BlockingQueue，优先队列的比较基准值是时间。 入队的方法比较简单，这里看一下出队的方法 取出元素 1234567891011121314151617181920212223242526272829public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; //可以看出 take方法实际上是一个阻塞式的方法。 for (;;) &#123; E first = q.peek(); if (first == null) &#123; //队列中没有元素 就一直等待 available.await(); &#125; else &#123; long delay = first.getDelay(TimeUnit.NANOSECONDS); if (delay &gt; 0) &#123; //还没到时间，继续等待 long tl = available.awaitNanos(delay); &#125; else &#123; //取出元素执行 E x = q.poll(); assert x != null; if (q.size() != 0) available.signalAll(); // wake up other takers return x; &#125; &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; SynchronousQueueExecutors.newCachedThreadPool()就使用了SynchronousQueue。这个Queue比较有意思:isEmpty()方法永远返回true，remainingCapacity()方法永远返回0，remove()和removeAll() 方法永远返回false，iterator()方法永远返回null，peek()方法永远返回null，故我们不能通过调用peek()方法来看队列中是否有数据元素，因为数据元素只有当你试着取走的时候才可能存在，不取走而只想偷窥一下是不行的，同样遍历这个队列的操作也是不允许的。 并且要注意的是A线程将数据放入队列中，直到有线程将数据取走，A线程都处于阻塞状态。可以理解为一种线程之间一对一传值的模型。 123public SynchronousQueue(boolean fair) &#123; transferer = fair ? new TransferQueue&lt;E&gt;() : new TransferStack&lt;E&gt;();&#125; 根据构造函数，可以发现SynchronousQueue支持公平与非公平的队列。公平队列的实现是TransferQueue，非公平队列的实现是TransferStack。TransferStack与TransferQueue都继承自内部类Transfer。 123abstract static class Transferer&lt;E&gt; &#123; abstract E transfer(E e, boolean timed, long nanos);&#125; Transfer只提供了一个transfer抽象方法，子类提供具体实现。 SynchronousQueue的插入和删除元素方法都是调用transfer方法: 12345678910111213public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); return transferer.transfer(e, true, 0) != null;&#125;public E take() throws InterruptedException &#123; E e = transferer.transfer(null, false, 0); if (e != null) return e; Thread.interrupted(); throw new InterruptedException();&#125; 所以研究这个阻塞队列，关键的就是研究两个实现类的transfer方法。 TransferQueue代码看起来很复杂。。。但是可以先梳理一下思路，既然是公平队列，而且名字以Queue结尾，那么应该是FIFO的方式，关键在于看他怎么处理头结点和尾节点的逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363static final class TransferQueue extends Transferer &#123; 本算法实现拓展了Scherer-Scott双队列算法，不同的是用节点模式， 而不是标记指针来区分节点操作类型。这个算法比栈算法的实现简单， 因为fulfillers需要明确指定节点，同时匹配节点用CAS操作QNode的 元素field即可，put操作从非null到null，反则亦然，take从null到非null。 /** Node class for TransferQueue. */ static final class QNode &#123; volatile QNode next; // next node in queue 后继 volatile Object item; // CAS&apos;ed to or from null 节点元素 volatile Thread waiter; // to control park/unpark 等待线程 final boolean isData; //是否为DATA模式 //设置元素和模式 QNode(Object item, boolean isData) &#123; this.item = item; this.isData = isData; &#125; //设置节点的后继 boolean casNext(QNode cmp, QNode val) &#123; return next == cmp &amp;&amp; UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); &#125; //设置节点的元素 boolean casItem(Object cmp, Object val) &#123; return item == cmp &amp;&amp; UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); &#125; /** * Tries to cancel by CAS&apos;ing ref to this as item. 取消节点等待，元素指向自己 */ void tryCancel(Object cmp) &#123; UNSAFE.compareAndSwapObject(this, itemOffset, cmp, this); &#125; //是否取消等待 boolean isCancelled() &#123; return item == this; &#125; /** * Returns true if this node is known to be off the queue * because its next pointer has been forgotten due to * an advanceHead operation. 是否出队列 */ boolean isOffList() &#123; return next == this; &#125; // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long itemOffset; private static final long nextOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class k = QNode.class; itemOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;item&quot;)); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;next&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; /** Head of queue 队列头节点*/ transient volatile QNode head; /** Tail of queue 队列尾节点*/ transient volatile QNode tail; /** * Reference to a cancelled node that might not yet have been * unlinked from queue because it was the last inserted node * when it cancelled. 刚入队列的节点，取消等待，但还没有出队列的节点， */ transient volatile QNode cleanMe; TransferQueue() &#123; //构造队列 QNode h = new QNode(null, false); // initialize to dummy node. head = h; tail = h; &#125; /** * Tries to cas nh as new head; if successful, unlink * old head&apos;s next node to avoid garbage retention. 尝试设置新的队头节点为nh，并比较旧头节点，成功则，解除旧队列头节点的next链接，及指向自己 */ void advanceHead(QNode h, QNode nh) &#123; if (h == head &amp;&amp; UNSAFE.compareAndSwapObject(this, headOffset, h, nh)) h.next = h; // forget old next &#125; /** * Tries to cas nt as new tail. 尝试设置队尾 */ void advanceTail(QNode t, QNode nt) &#123; if (tail == t) UNSAFE.compareAndSwapObject(this, tailOffset, t, nt); &#125; /** * Tries to CAS cleanMe slot. 尝试设置取消等待节点为val。并比较旧的等待节点是否为cmp */ boolean casCleanMe(QNode cmp, QNode val) &#123; return cleanMe == cmp &amp;&amp; UNSAFE.compareAndSwapObject(this, cleanMeOffset, cmp, val); &#125; /** * Puts or takes an item. 生产或消费一个元素 */ Object transfer(Object e, boolean timed, long nanos) &#123; /* Basic algorithm is to loop trying to take either of * two actions: * 基本算法是循环尝试，执行下面两个步中的，其中一个： * 1. If queue apparently empty or holding same-mode nodes, * try to add node to queue of waiters, wait to be * fulfilled (or cancelled) and return matching item. * 1.如果队列为空，或队列中为相同模式的节点，尝试节点入队列等待， 直到fulfilled，返回匹配元素，或者由于中断，超时取消等待。 * 2. If queue apparently contains waiting items, and this * call is of complementary mode, try to fulfill by CAS&apos;ing * item field of waiting node and dequeuing it, and then * returning matching item. * 2.如果队列中包含节点，transfer方法被一个协同模式的节点调用， 则尝试补给或填充等待线程节点的元素，并出队列，返回匹配元素。 * In each case, along the way, check for and try to help * advance head and tail on behalf of other stalled/slow * threads. * 在每一种情况，执行的过程中，检查和尝试帮助其他stalled/slow线程移动队列头和尾节点 * The loop starts off with a null check guarding against * seeing uninitialized head or tail values. This never * happens in current SynchronousQueue, but could if * callers held non-volatile/final ref to the * transferer. The check is here anyway because it places * null checks at top of loop, which is usually faster * than having them implicitly interspersed. 循环开始，首先进行null检查，防止为初始队列头和尾节点。当然这种情况， 在当前同步队列中，不可能发生，如果调用持有transferer的non-volatile/final引用， 可能出现这种情况。一般在循环的开始，都要进行null检查，检查过程非常快，不用过多担心 性能问题。 */ QNode s = null; // constructed/reused as needed //如果元素e不为null，则为DATA模式，否则为REQUEST模式 boolean isData = (e != null); for (;;) &#123; QNode t = tail; QNode h = head; //如果队列头或尾节点没有初始化，则跳出本次自旋 if (t == null || h == null) // saw uninitialized value continue; // spin if (h == t || t.isData == isData) &#123; // empty or same-mode //如果队列为空，或当前节点与队尾模式相同 QNode tn = t.next; if (t != tail) // inconsistent read //如果t不是队尾，非一致性读取，跳出本次自旋 continue; if (tn != null) &#123; // lagging tail //如果t的next不为null，设置新的队尾，跳出本次自旋 advanceTail(t, tn); continue; &#125; if (timed &amp;&amp; nanos &lt;= 0) // can&apos;t wait //如果超时，且超时时间小于0，则返回null return null; if (s == null) //根据元素和模式构造节点 s = new QNode(e, isData); if (!t.casNext(null, s)) // failed to link in //新节点入队列 continue; //设置队尾为当前节点 advanceTail(t, s); // swing tail and wait //自旋或阻塞直到节点被fulfilled Object x = awaitFulfill(s, e, timed, nanos); if (x == s) &#123; // wait was cancelled //如果s指向自己，s出队列，并清除队列中取消等待的线程节点 clean(t, s); return null; &#125; if (!s.isOffList()) &#123; // not already unlinked //如果s节点已经不再队列中，移除 advanceHead(t, s); // unlink if head if (x != null) // and forget fields s.item = s; s.waiter = null; &#125; //如果自旋等待匹配的节点元素不为null，则返回x，否则返回e return (x != null) ? x : e; &#125; else &#123; // complementary-mode //如果队列不为空，且与队头的模式不同，及匹配成功 QNode m = h.next; // node to fulfill if (t != tail || m == null || h != head) //如果h不为当前队头，则返回，即读取不一致 continue; // inconsistent read Object x = m.item; if (isData == (x != null) || // m already fulfilled x == m || // m cancelled !m.casItem(x, e)) &#123; // lost CAS //如果队头后继，取消等待，则出队列 advanceHead(h, m); // dequeue and retry continue; &#125; //否则匹配成功 advanceHead(h, m); // successfully fulfilled //unpark等待线程 LockSupport.unpark(m.waiter); //如果匹配节点元素不为null，则返回x，否则返回e，即take操作，返回等待put线程节点元素， //put操作，返回put元素 return (x != null) ? x : e; &#125; &#125; &#125; /** * Spins/blocks until node s is fulfilled. * 自旋或阻塞直到节点被fulfilled * @param s the waiting node，等待节点 * @param e the comparison value for checking match，检查匹配的比较元素 * @param timed true if timed wait 是否超时等待 * @param nanos timeout value 超时等待时间 * @return matched item, or s if cancelled 成功返回匹配元素，取消返回等待元素 */ Object awaitFulfill(QNode s, Object e, boolean timed, long nanos) &#123; /* Same idea as TransferStack.awaitFulfill 这里与栈中的实现思路是一样的*/ //获取超时的当前时间，当前线程，自旋数 long lastTime = timed ? System.nanoTime() : 0; Thread w = Thread.currentThread(); int spins = ((head.next == s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); for (;;) &#123; if (w.isInterrupted()) //如果中断，则取消等待 s.tryCancel(e); Object x = s.item; if (x != e) return x;//如果s的节点的元素不相等，则返回x,即s节点指向自身，等待clean if (timed) &#123; long now = System.nanoTime(); nanos -= now - lastTime; lastTime = now; if (nanos &lt;= 0) &#123; //如果超时，则取消等待 s.tryCancel(e); continue; &#125; &#125; if (spins &gt; 0) //自旋数减一 --spins; else if (s.waiter == null) //如果是节点的等待线程为空，则设置为当前线程 s.waiter = w; else if (!timed) //非超时，则park LockSupport.park(this); else if (nanos &gt; spinForTimeoutThreshold) //超时时间大于自旋时间，则超时park LockSupport.parkNanos(this, nanos); &#125; &#125; /** * Gets rid of cancelled node s with original predecessor pred. 移除队列中取消等待的线程节点 */ void clean(QNode pred, QNode s) &#123; s.waiter = null; // forget thread 在任何时候，最后一个节点入队列时，队列中都有可能存在取消等待，但没有删除的节点。 为了将这些节点删除，如果我们不能删除最后入队列的节点，我们可以用cleanMe记录它的前驱， 删除cleanMe后继节点。s节点和cleanMe后继节点至少一个删除，则停止。 while (pred.next == s) &#123; // Return early if already unlinked //如果s为队尾节点，且前驱为旧队尾 QNode h = head; QNode hn = h.next; // Absorb cancelled first node as head if (hn != null &amp;&amp; hn.isCancelled()) &#123; //如果队头不为空，且取消等待，设置后继为新的队头元素 advanceHead(h, hn); continue; &#125; QNode t = tail; // Ensure consistent read for tail if (t == h) //空队列，则返回 return; QNode tn = t.next; if (t != tail) //如果队尾有变化，跳出循环 continue; if (tn != null) &#123; //如果队尾后继不为null，则设置新的队尾 advanceTail(t, tn); continue; &#125; if (s != t) &#123; // If not tail, try to unsplice QNode sn = s.next; if (sn == s || pred.casNext(s, sn)) //s节点指向自己，则返回 return; &#125; QNode dp = cleanMe; if (dp != null) &#123; // Try unlinking previous cancelled node //移除前一个取消等待的节点 QNode d = dp.next; QNode dn; if (d == null || // d is gone or d == dp || // d is off list or !d.isCancelled() || // d not cancelled or (d != t &amp;&amp; // d not tail and (dn = d.next) != null &amp;&amp; // has successor dn != d &amp;&amp; // that is on list dp.casNext(d, dn))) // d unspliced casCleanMe(dp, null); if (dp == pred) return; // s is already saved node &#125; else if (casCleanMe(null, pred)) //先前取消等待的节点为null，则将cleanMe设为刚取消等待节点的前驱 return; // Postpone cleaning s &#125; &#125; private static final sun.misc.Unsafe UNSAFE; private static final long headOffset; private static final long tailOffset; private static final long cleanMeOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class k = TransferQueue.class; headOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;head&quot;)); tailOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;tail&quot;)); cleanMeOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;cleanMe&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; TransferStack这么复杂算法，感觉有些大材小用啊。- - ! TransferStack用于非公平队列的实现，根据栈的特性，应该是先进后出的一种形式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362static final class TransferStack extends Transferer &#123; 本stack实现的是算法是拓展了Scherer-Scott双栈的算法，所不同的时，用covering节点，而不是bit-marked指针：在bit集填充模式下，填充操作将会为匹配一个等待节点保留资源，生产一个标记节点。 */ /* Modes for SNodes, ORed together in node fields */ /** Node represents an unfulfilled consumer REQUEST节点表示一个未填充的消费者*/ static final int REQUEST = 0; /** Node represents an unfulfilled producer DATA节点表示一个未填充的生产者*/ static final int DATA = 1; /** Node is fulfilling another unfulfilled DATA or REQUESTFULFILLING节点表示生产者正在给等待资源的消费者补给资源，或生产者在等待消费者消费资源/ static final int FULFILLING = 2; /** Return true if m has fulfilling bit set如果m是一个填充为单元，则返回true*/ static boolean isFulfilling(int m) &#123; return (m &amp; FULFILLING) != 0; &#125; /** Node class for TransferStacks. 栈节点 */ static final class SNode &#123; volatile SNode next; // next node in stack 节点的后继 volatile SNode match; // the node matched to this 匹配节点 volatile Thread waiter; // to control park/unpark 等待者线程 Object item; // data; or null for REQUESTs 数据，消费者消费的资源 int mode;//节点模式 // Note: item and mode fields don&apos;t need to be volatile // since they are always written before, and read after, // other volatile/atomic operations. //元素item和mode需要要可见，由于他们总是在其他可见/原子操作写之前，读之后 SNode(Object item) &#123; this.item = item; &#125; //设置节点后继 boolean casNext(SNode cmp, SNode val) &#123; return cmp == next &amp;&amp; UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); &#125; /** * Tries to match node s to this node, if so, waking up thread. * Fulfillers call tryMatch to identify their waiters. * Waiters block until they have been matched. * 尝试匹配目标节点与本节点，如果匹配，可以唤醒线程。补给者调用tryMatch方法 确定它们的等待线程。等待线程阻塞到它们自己被匹配。如果匹配返回true。 * @param s the node to match * @return true if successfully matched to s */ boolean tryMatch(SNode s) &#123; if (match == null &amp;&amp; UNSAFE.compareAndSwapObject(this, matchOffset, null, s)) &#123; Thread w = waiter; //如果等待者不为null，则unpark等待线程 if (w != null) &#123; // waiters need at most one unpark waiter = null; LockSupport.unpark(w); &#125; return true; &#125; return match == s; &#125; /** * Tries to cancel a wait by matching node to itself.节点尝试取消等待 */ void tryCancel() &#123; UNSAFE.compareAndSwapObject(this, matchOffset, null, this); &#125; //match指向自己，则取消等待 boolean isCancelled() &#123; return match == this; &#125; // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long matchOffset; private static final long nextOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class k = SNode.class; matchOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;match&quot;)); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;next&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; /** The head (top) of the stack 栈头节点*/ volatile SNode head; //CAS操作nh为当前head，并比较head旧值是否为h boolean casHead(SNode h, SNode nh) &#123; return h == head &amp;&amp; UNSAFE.compareAndSwapObject(this, headOffset, h, nh); &#125; /** * Creates or resets fields of a node. Called only from transfer * where the node to push on stack is lazily created and * reused when possible to help reduce intervals between reads * and CASes of head and to avoid surges of garbage when CASes * to push nodes fail due to contention. 创建或重新设置节点的fields。在节点入栈懒创建，在当可能需要保证减少intervals（间隔） 读和head的CAS操或避免由于竞争CAS操作节点入栈引起的垃圾时，此方法会被transfer调用 */ static SNode snode(SNode s, Object e, SNode next, int mode) &#123; if (s == null) s = new SNode(e); s.mode = mode; s.next = next; return s; &#125; /** * Puts or takes an item. put或take一个元素 */ Object transfer(Object e, boolean timed, long nanos) &#123; /* * Basic algorithm is to loop trying one of three actions: * 算法的基本步骤是，循环尝试一下3步 * 1. If apparently empty or already containing nodes of same * mode, try to push node on stack and wait for a match, * returning it, or null if cancelled. * 1.如果队列为空或已经包含相同模式的节点，则尝试节点入栈，等待匹配， 返回，如果取消返回null。 * 2. If apparently containing node of complementary mode, * try to push a fulfilling node on to stack, match * with corresponding waiting node, pop both from * stack, and return matched item. The matching or * unlinking might not actually be necessary because of * other threads performing action 3: * 2.如果包含一个互补模式的节点（take(REQUEST)-&gt;put(DATA)；put(DATA)-&gt;take(REQUEST)）， 则尝试一个FULFILLING节点入栈，同时匹配等待的协同节点，两个节点同时出栈，返回匹配的元素。 由于其他线程执行步骤3，实际匹配和解除链接指针动作不会发生。 * 3. If top of stack already holds another fulfilling node, * help it out by doing its match and/or pop * operations, and then continue. The code for helping * is essentially the same as for fulfilling, except * that it doesn&apos;t return the item. 3.如果栈顶存在另外一个FULFILLING的节点，则匹配节点，并出栈。这段的代码 与fulfilling相同，除非没有元素返回 */ SNode s = null; // constructed/reused as needed //根据元素判断节点模式，元素不为null，则为DATA，否则为REQUEST int mode = (e == null) ? REQUEST : DATA; for (;;) &#123; SNode h = head; if (h == null || h.mode == mode) &#123; // empty or same-mode //如果是空队列，或栈头节点的模式与要放入的节点模式相同 if (timed &amp;&amp; nanos &lt;= 0) &#123; // can&apos;t wait //如果超时，则取消等待，出栈，设置栈头为其后继 if (h != null &amp;&amp; h.isCancelled()) casHead(h, h.next); // pop cancelled node else //否则返回null return null; &#125; else if (casHead(h, s = snode(s, e, h, mode))) &#123; //如果非超时，则将创建的新节点入栈成功，即放在栈头，自旋等待匹配节点（timed决定超时，不超时） SNode m = awaitFulfill(s, timed, nanos); if (m == s) &#123; // wait was cancelled //如果返回的是自己，节点取消等待，从栈中移除，并遍历栈移除取消等待的节点 clean(s); return null; &#125; if ((h = head) != null &amp;&amp; h.next == s) //s节点匹配成功，则设置栈头为s的后继 casHead(h, s.next); // help s&apos;s fulfiller //匹配成功，REQUEST模式返回，匹配到的节点元素（DATA），DATA模式返回当前节点元素 return (mode == REQUEST) ? m.item : s.item; &#125; &#125; else if (!isFulfilling(h.mode)) &#123; // try to fulfill //如果栈头节点模式不为Fulfilling，判断是否取消等待，是则出栈 if (h.isCancelled()) // already cancelled casHead(h, h.next); // pop and retry //非取消等待，则是节点入栈 else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) &#123; for (;;) &#123; // loop until matched or waiters disappear SNode m = s.next; // m is s&apos;s match //后继节点为null，则出栈 if (m == null) &#123; // all waiters are gone casHead(s, null); // pop fulfill node s = null; // use new node next time break; // restart main loop &#125; SNode mn = m.next; //尝试匹配是s节点 if (m.tryMatch(s)) &#123; //匹配成功两个节点则出栈， casHead(s, mn); // pop both s and m return (mode == REQUEST) ? m.item : s.item; &#125; else // lost match //否则，跳过s的后继节点 s.casNext(m, mn); // help unlink &#125; &#125; &#125; else &#123; // help a fulfiller //如果栈头节点模式为Fulfilling,找出栈头的匹配节点 SNode m = h.next; // m is h&apos;s match if (m == null) // waiter is gone //如果无后继等待节点，则栈头出栈 casHead(h, null); // pop fulfilling node else &#123; //尝试匹配，如果匹配成功，栈头和匹配节点出栈，否则跳过后继节点 SNode mn = m.next; if (m.tryMatch(h)) // help match casHead(h, mn); // pop both h and m else // lost match h.casNext(m, mn); // help unlink &#125; &#125; &#125; &#125; /** * Spins/blocks until node s is matched by a fulfill operation.自旋或阻塞，直到节点被一个fulfill操作匹配 * * @param s the waiting node 等待被匹配的节点 * @param timed true if timed wait 是否超时等待 * @param nanos timeout value 时间值 * @return matched node, or s if cancelled 如果匹配返回节点，否则取消等待 */ SNode awaitFulfill(SNode s, boolean timed, long nanos) &#123; /* * When a node/thread is about to block, it sets its waiter * field and then rechecks state at least one more time * before actually parking, thus covering race vs * fulfiller noticing that waiter is non-null so should be * woken. * 当一个节点线程将要阻塞时，在实际park之前，设置等待线程的field，重新至少检查 自身状态一次，这样可以避免在fulfiller注意到有等待线程非null，可以操作时，掩盖了竞争。 * When invoked by nodes that appear at the point of call * to be at the head of the stack, calls to park are * preceded by spins to avoid blocking when producers and * consumers are arriving very close in time. This can * happen enough to bother only on multiprocessors. * 当awaitFulfill被栈头节点调用时，通过自旋park一段时间，以免在刚要阻塞的时刻， 有生产者或消费者到达。这在多处理机上将会发生。 * The order of checks for returning out of main loop * reflects fact that interrupts have precedence over * normal returns, which have precedence over * timeouts. (So, on timeout, one last check for match is * done before giving up.) Except that calls from untimed * SynchronousQueue.&#123;poll/offer&#125; don&apos;t check interrupts * and don&apos;t wait at all, so are trapped in transfer * method rather than calling awaitFulfill. 主循环检查返回的顺序将会反应，在正常返回时，中断是否处理，还是超时处理。 （在放弃匹配之前，及最后一次检查，正好超时），除非调用SynchronousQueue的 非超时poll/offer操作，不会检查中断，不等待，那么将调用transfer方法中的其他部分逻辑， 而不是调用awaitFulfill。 */ long lastTime = timed ? System.nanoTime() : 0; Thread w = Thread.currentThread(); SNode h = head; //获取自旋的次数 int spins = (shouldSpin(s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); for (;;) &#123; if (w.isInterrupted()) //如果线程被中断，则取消等待 s.tryCancel(); SNode m = s.match; if (m != null) //如果节点的匹配节点不为null，则返回匹配节点 return m; if (timed) &#123; long now = System.nanoTime(); nanos -= now - lastTime; lastTime = now; if (nanos &lt;= 0) &#123; //如果超时，则取消等待 s.tryCancel(); continue; &#125; &#125; if (spins &gt; 0) //如果自旋次数大于零，且可以自旋，则自旋次数减1 spins = shouldSpin(s) ? (spins-1) : 0; else if (s.waiter == null) //如果节点S的等待线程为空，则设置当前节点为S节点的等待线程，以便可以park后继节点。 s.waiter = w; // establish waiter so can park next iter else if (!timed) //非超时等在者，park当前线程 LockSupport.park(this); else if (nanos &gt; spinForTimeoutThreshold) //如果超时时间大于，最大自旋阈值，则超时park当前线程 LockSupport.parkNanos(this, nanos); &#125; &#125; /** * Returns true if node s is at head or there is an active * fulfiller. 如果节点在栈头或栈头为FULFILLING的节点，则返回true */ boolean shouldSpin(SNode s) &#123; SNode h = head; return (h == s || h == null || isFulfilling(h.mode)); &#125; /** * Unlinks s from the stack. */ void clean(SNode s) &#123; s.item = null; // forget item s.waiter = null; // forget thread 最糟糕的情况是我们需要遍历整个栈，unlink节点s。如果有多个线程同时访问 clean方法，由于其他线程可能移除s节点，我们也许看不到s节点。但是我们可以停止 操作，当发现一个节点的后继为s。我们可以用s节点的后继，除非s节点取消，否则， 我们可越过s节点。我们不会进一步地检查，因为我们不想仅仅为了发现s节点，遍历两次。 */ SNode past = s.next; if (past != null &amp;&amp; past.isCancelled()) past = past.next; // Absorb cancelled nodes at head SNode p; while ((p = head) != null &amp;&amp; p != past &amp;&amp; p.isCancelled()) //设置栈头节点的后继为第一个非取消等待的节点 casHead(p, p.next); // Unsplice embedded nodes，遍历栈，移除取消等待的节点 while (p != null &amp;&amp; p != past) &#123; SNode n = p.next; if (n != null &amp;&amp; n.isCancelled()) p.casNext(n, n.next); else p = n; &#125; &#125; // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long headOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class k = TransferStack.class; headOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;head&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; 从TransferStack中Snode节点可以看出：节点关联一个等待线程waiter，后继next，匹配节点match，节点元素item和模式mode；模式由三种，REQUEST节点表示消费者等待消费资源，DATA表示生产者等待生产资源。FULFILLING节点表示生产者正在给等待资源的消费者补给资源，或生产者在等待消费者消费资源。当有线程take/put操作时，查看栈头，如果是空队列，或栈头节点的模式与要放入的节点模式相同；如果是超时等待，判断时间是否小于0，小于0则取消节点等待；如果非超时，则将创建的新节点入栈成功，即放在栈头，自旋等待匹配节点（timed决定超时，不超时）；如果匹配返回的是自己，节点取消等待，从栈中移除，并遍历栈移除取消等待的节点；匹配成功，两个节点同时出栈，REQUEST模式返回，匹配到的节点元素（DATA），DATA模式返回返回当前节点元素）。如果与栈头节点的模式不同且不为FULFILLING，匹配节点，成功者，两个节点同时出栈，REQUEST模式返回，匹配到的节点元素（DATA），DATA（put）模式返回返回当前节点元素。如果栈头为FULFILLING，找出栈头的匹配节点，栈头与匹配到的节点同时出栈。从分析非公平模式下的TransferStack，可以看出一个REQUEST操作必须同时伴随着一个DATA操作，一个DATA操作必须同时伴随着一个REQUEST操作，这也是同步队列的命名中含Synchronous原因。 LinkedBlockingDeque由一个链表结构组成的双向阻塞队列。所谓双向队列指的是你可以从队列的两端插入和移出元素，双端队列因多了一个操作入口，在多线程同时入队时减少了一半的竞争。在初始化LinkedBlockingDeque时，可以设置容量，防止其过渡膨胀，相比其他的阻塞队列，LinkedBlockingDeque多了addFirst，addLast，offerFirst，offerLast，peekFirst，peekLast等方法，以First单词结尾的方法，表示插入，获取（peek）或移除双端队列的第一个元素；以Last单词结尾的方法，表示插入，获取或移除双端队列的最后一个元素；插入方法add等同于addLast，移除方法remove等同于removeFirst。 这个数据结构的方法还是比较简单易懂的。 LinkedTransferQueueLinkedTransferQueue实现了TransferQueue接口的方法。实现了这个接口就意味着它的特性就是消费者与生产者的分离，生产者或消费者都不在乎有没有资源，阻塞都由服务员transfer统一调度。 它的成员变量与之前的SynchronousQueue的结构很相似，并且内部同样使用的是cas算法。 1234final boolean isData; // false if this is a request nodevolatile Object item; // initially non-null if isData; CASed to matchvolatile Node next;volatile Thread waiter; // null until waiting LinkedTransferQueue添加和删除元素都指向了同一个方法xfer()，这之前要了解xfer方法参数how的几个可选值 1234private static final int NOW = 0; // for untimed poll, tryTransferprivate static final int ASYNC = 1; // for offer, put, addprivate static final int SYNC = 2; // for transfer, takeprivate static final int TIMED = 3; // for timed poll, tryTransfer NOW就是立刻返回不追加元素到末尾，ASYNC就是同步需要添加元素到队列尾，TIMED用于有时间限制的操作，SYNC用于无时间限制无限等待的操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445private E xfer(E e, boolean haveData, int how, long nanos) &#123; if (haveData &amp;&amp; (e == null)) throw new NullPointerException(); Node s = null; // the node to append, if needed retry: for (;;) &#123; // restart on append race for (Node h = head, p = h; p != null;) &#123; // find &amp; match first node boolean isData = p.isData; Object item = p.item; if (item != p &amp;&amp; (item != null) == isData) &#123; // unmatched if (isData == haveData) // can&apos;t match break; if (p.casItem(item, e)) &#123; // match for (Node q = p; q != h;) &#123; Node n = q.next; // update by 2 unless singleton if (head == h &amp;&amp; casHead(h, n == null ? q : n)) &#123; h.forgetNext(); break; &#125; // advance and retry if ((h = head) == null || (q = h.next) == null || !q.isMatched()) break; // unless slack &lt; 2 &#125; LockSupport.unpark(p.waiter); return LinkedTransferQueue.&lt;E&gt;cast(item); &#125; &#125; Node n = p.next; p = (p != n) ? n : (h = head); // Use head if p offlist &#125; if (how != NOW) &#123; // No matches available if (s == null) s = new Node(e, haveData); Node pred = tryAppend(s, haveData); if (pred == null) continue retry; // lost race vs opposite mode if (how != ASYNC) return awaitMatch(s, pred, e, (how == TIMED), nanos); &#125; return e; // not waiting &#125; &#125; 不允许放入的数据为空，放入操作的模式是ASYNC。从头指针处开始死循环，当前结点p没有被匹配，数据节点不能匹配直接跳出循环，不进行匹配，后面会进入how!=NOW的判断，创建新节点，尝试追加到队列尾。如果可以匹配就替换P节点的值，失败意味着被其它线程抢先了，继续循环，成功了意味着这两个匹配成功，可能需要更新头结点。q=p且p!=h的循环意味着已经跳过了一个元素，n又取了q.next，p又是当前被匹配了的结点，这就意味着前面有2个match的结点：head和p。达到slack为2的条件，更新头结点，并遗弃之前的head。不需要更新头结点的时候直接跳出循环。匹配完成之后就是唤醒p结点的waiter（如果p是请求节点的话）返回item。 参考链接 http://blog.csdn.net/javazejian/article/details/77410889?locationNum=1&amp;fps=1 http://www.importnew.com/17537.html http://donald-draper.iteye.com/blog/2364842 https://www.cnblogs.com/lighten/p/7505355.html]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-Executor框架(10)]]></title>
    <url>%2F2018%2F02%2F11%2FJUC-Executor%E6%A1%86%E6%9E%B6-10%2F</url>
    <content type="text"><![CDATA[我们日常工作中使用Executor框架最常见的就是创建一个线程池，然后将任务交给线程池去执行，实现提交与执行任务之间解耦 结构这里主要研究一下Executor框架的主干部分，对于ScheduledService工作中应该主要使用的是quartz框架，对于CompletionService，个人觉得java8中的CompletableFuture使用效果更好，所以在这里就不研究了。 从日常使用看起使用1ExecutorService service = Executors.newFixedThreadPool(3); 这个方法应该是使用频率很高的，它创建了一个拥有三个固定线程的线程池。那么点进源码里看看都做了哪些事情。 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 其实是Executor在内部new了一个ThreadPoolExecutor。其实Executors就是一个静态工厂方法，封装了一些常用的线程池类型。 构造ThreadPoolExecutor其实是Executor框架的一个核心类，通过设置不同的参数，可以构造出各种效果的线程池。继续深入到ThreadPoolExecutor类中。 123456789101112131415161718192021222324252627282930313233public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; ThreadPoolExecutor的构造函数如图所示，有七个参数: corePoolSize表示线程池核心线程数量 maximumPoolSize表示线程池最大容量 keepAliveTime表示线程池中大于coresize的空闲线程最大的存活时间。 timeunit 时间单位 blockingQueue:暂存任务的工作队列 ThreadFactory: 用于创建一个新的线程 handler:用于配置线程池饱和后的拒绝策略 流程 当通过主线程提交一个任务后，如果当前任务的数量小于coresize那么直接执行步骤1 如果任务数量大于coresize并且blockingQueue没满，则加入blockingQueue，如步骤3 当blockingQueue已满，线程池扩容到maxpoolsize情况下运行 当线程池处于maxpoolsize数量下满载工作，并且blockingQueue满，则执行步骤4，拒绝任务 这个处理策略可以再execute方法中清楚的看到。 12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 上面再提交任务的时候，会出现开辟新的线程来执行，也就是调用addWorker()方法。 核心方法 addWorker 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125;上面的部分是两层无限循环，尝试增加线程数量到ctl变量。如果超过线程池设定的数量或者线程池状态不符，则返回false，增加worker失败。 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125;上面的部分把firstTask这个Runnable对象传递给worker构造方法，给worker的task属性赋值。worker将自身封装为一个Thread。锁住整个线程池，将worker添加到workers的hashSet中。增加线程后调用start()方法，真正开始执行任务。实际上是运行的worker的run()方法，worker的run()方法调用了ThreadPoolExecutor的runWorker()方法。 Worker内部类 Worker是ThreadPoolExecutor的内部类，它继承了AQS,实现了Runnable接口。封装了三个属性: 123456/** Thread this worker is running in. Null if factory fails. */final Thread thread;/** Initial task to run. Possibly null. */Runnable firstTask;/** Per-thread task counter */volatile long completedTasks; 内部实现了一些资源共享的方法。 runWorker() 123456789101112131415161718192021222324252627282930313233343536373839final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 首先对worker进行加锁，任务开始之前执行beforeExecute，任务执行结束之后执行afterExecute，任务完成后记录当前线程完成的任务数。如果调用了getTask()方法，阻塞方法的退出，继续执行当前方法。 getTask() 12345678910111213141516171819202122232425262728293031323334353637private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125; &#125; 该方法从workQueue中取一个任务。该队列是一个blockingQueue，当没有任务的时候会陷入阻塞。如果获取到的任务是有时间限制的则调用poll方法，设置过期时间。否则调用take方法执行任务。当getWorker()方法返回null的时候，addworker()方法执行processWorkerExit，退出线程。 processWorkerExit 123456789101112131415161718192021222324252627private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) // If abrupt, then workerCount wasn&apos;t adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125; &#125; 主要的逻辑就是从works的HashSet中remove一个线程。如果在方法执行过程中出现了异常completedAbruptly=true，线程直接退出，线程数量减一。正常退出则加锁统计任务总数并remove线程。 tryTerminate()将线程池尝试设置为终止状态 最后比较当前线程数是不是低于coreSize，如果是则添加空的worker到线程池待命。 拒绝策略 ThreadPoolExecutor提供了四个拒绝策略 AbortPolicy: 不处理，直接抛出RejectedExecutionException异常。 CallerRunsPolicy: 任务可以被执行，但是线程池不会开辟新的线程。而是由提交任务的线程来执行。 DiscardOldestPolicy: 丢弃一个最早进入队列的任务 DiscardPolicy: 直接丢弃提交的任务。 到此，一个线程在线程池中的生命周期大概就走完了。 继承关系在上面的介绍中，主要是ThreadPoolExecutor类的方法。ThreadPoolExecutor继承自AbstractExecutorService，AbstractExecutorService实现了ExecutorService接口，ExecutorService接口继承Executor接口。 123public interface Executor &#123; void execute(Runnable command);&#125; Executor接口只有一个execute方法，通过命名可以看出这是一个命令模式的实现。ExecutorService则是提供了线程池生命周期相关的方法与任务提交的方法。 常用线程池newFixedThreadPool 固定容量线程池12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 通过传入一个int值来指定线程池的大小，coreSize=maxSize。也就是说该线程池不具有伸缩性，线程不会有销毁的开销，所以keepAliveTime=0。超过coreSize的数量的任务会直接放入等待队列中。 newCachedThreadPool可缓存的线程池 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; coreSize=0,maxSize=最大整数。创建任务时有空闲线程则使用，没有则创建新的线程，每60s销毁一次空闲线程。SynchronousQueue 它是一个对于元素来说空了才能存入，存在才能取出的队列，只保留一个元素在queue里。由于cachedPool本身容量足够大，所以阻塞队列无需保存很多的任务，而SynchronousQueue足够轻量，所以在这里使用最合适不过。 newSingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 单线程的线程池，coreSize=MaxSize=1，可以保证任务的FIFO执行。 newScheduledThreadPool1234public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125; 定时线程池，用来执行大量的定时任务。可以指定coreSize，最大为Integer.MAX，空闲线程立即销毁。超过数量的任务加入到DelayedWorkQueue，DelayedWorkQueue可以控制任务的延迟执行。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-等等我,一起走(9)]]></title>
    <url>%2F2018%2F02%2F02%2FJUC-%E7%AD%89%E7%AD%89%E6%88%91-%E4%B8%80%E8%B5%B7%E8%B5%B0-9%2F</url>
    <content type="text"><![CDATA[CountDownLatchcoding日常使用的最多的一个工具，初始化时需要指定一个int值，可以理解为要执行任务的线程的数量，每次调用countDown()会使int值减一。当int值&lt;=0时，调用await()方法的地方会放行所有线程。一个简单的demo: 1234567891011121314151617181920212223242526public class CountDownLatchTest &#123; public static CountDownLatch countDownLatch = new CountDownLatch(3); static class MyRun implements Runnable&#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot;working&quot;); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; countDownLatch.countDown(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; new Thread(new MyRun()).start(); new Thread(new MyRun()).start(); new Thread(new MyRun()).start(); countDownLatch.await(); System.out.println(&quot;all finish&quot;); &#125;&#125; 当三个线程都执行过countDown方法之后，计数器减为0。await()方法放行，输出all finish语句。如果有线程出现错误造成计数器无法减到0就会一直阻塞，解决方法有两种。第一种就是给await方法设定等待时间，超过等待时间就放行 1countDownLatch.await(2,TimeUnit.SECONDS); 第二种就是使用try/finally代码块 1234567891011@Overridepublic void run() &#123; try &#123; System.out.println(Thread.currentThread().getName()+&quot;working&quot;); TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; countDownLatch.countDown(); &#125;&#125; 可能平时不注意就会忘了考虑线程出异常而造成的阻塞这种情况，所以还是建议使用try/finally这种处理，因为可以再finally代码块中记录日志，做一些结束操作。 源码可以看出CountDownLatch算是JUC里比较简单的了，可供调用的方法非常简单，从字面意思就可以看懂怎么用。内部的实现是AQS，那么核心就是看一下它是怎样使用AQS了。 初始化时调用了内部AQS的初始化，将计数器赋值给state(同步器状态)。 1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count);&#125; countDown和await方法的内部实现 12345678910111213141516//await时候执行，只查看当前需要countDown数量减为0了，如果为0，说明可以继续执行，否则需要park住，等待countDown次数足够，并且unpark所有等待线程public int tryAcquireShared(int acquires) &#123; return getState() == 0? 1 : -1;&#125;//countDown 时候执行，如果当前countDown数量为0，说明没有线程await，直接返回false而不需要唤醒park住线程，如果不为0，得到剩下需要 countDown的数量并且compareAndSet,最终返回剩下的countDown数量是否为0,供AQS判定是否释放所有await线程。public boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; CylicBarriarcodingCyclicBarrier与CountDownLatch的使用有些相似 1234567891011121314151617181920212223242526public class CyclicBarrierTest &#123; public static CyclicBarrier cyclicBarrier = new CyclicBarrier(4); public static Random random = new Random(); static class MyRun implements Runnable&#123; @Override public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName()+&quot;is working&quot;); TimeUnit.SECONDS.sleep(random.nextInt(5)); cyclicBarrier.await(); System.out.println(Thread.currentThread().getName()+&quot;after wait&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) throws BrokenBarrierException, InterruptedException &#123; new Thread(new MyRun()).start(); new Thread(new MyRun()).start(); new Thread(new MyRun()).start(); cyclicBarrier.await(); TimeUnit.SECONDS.sleep(1); System.out.println(&quot;all finished&quot;); &#125;&#125; 首先对于同样启动3个线程，CountDownLath初始化个数为3，而CyclicBarrier则是4。所以CountDownLath初始化值的意思是要执行任务的线程的个数，而CyclicBarrier初始化值的意思是要等待的线程的个数。因为总要多出一个主线程进入阻塞等待，否则可能导致程序提前退出。 从上面的demo可以看出，只要有线程还没有到达await方法，其他线程都阻塞在cyclicBarrier.await()这个方法之前，当所有的方法执行到这个屏障的时候，屏障才会打开，所有线程继续抢占cpu执行。 对于这个工具，我们只使用了一个方法就完成了目标，看一下它的实现代码。 源码 虽然没有使用AQS，但是代码好像复杂很多，多出了一个Generation(分代)的概念，还使用了自旋锁。 首先CyclicBarrier提供了两个构造函数,第一个构造函数就是传入等待线程的数量，另一个还需要传入一个Runnable。作用就是当所有线程到达同步点时,先执行构造函数中的Runnable,这个Runnable拥有最高的优先级。如下: 123456public static CyclicBarrier cyclicBarrier = new CyclicBarrier(4, new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;所有线程都到达同步点啦，准备冲啊&quot;); &#125;&#125;); 12345678Thread-1is workingThread-2is workingThread-0is working所有线程都到达同步点啦，准备冲啊Thread-1after waitThread-2after waitThread-0after waitall finished 对于await方法，同样提供了带超时和不带超时的功能,核心方法是doawait: 1234567891011121314public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125; &#125;public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; return dowait(true, unit.toNanos(timeout));&#125; doWait方法： 首先每个线程进入方法之后会加一个自旋锁，初始化一个Generation，这个内部类只有一个默认为false的broken属性，然后进行一些异常检测。 index=–count,将等待线程的数量减一，表示已经到了等待处。 如果index!=0,循环等待，并进行超时判断。 如果index==0,判断构造函数有没有传入Runnable，如果有就优先执行。否则执行nextGeneration()，并在最后检查一些异常，解锁退出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; breakBarrier(); throw new InterruptedException(); &#125; int index = --count; if (index == 0) &#123; // tripped boolean ranAction = false; try &#123; final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) breakBarrier(); &#125; &#125; // loop until tripped, broken, interrupted, or timed out for (;;) &#123; try &#123; if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; // We&apos;re about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // &quot;belong&quot; to subsequent execution. Thread.currentThread().interrupt(); &#125; &#125; if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; 那么我们继续来看看nextGeneration这个方法做了什么 1234567private void nextGeneration() &#123; // signal completion of last generation trip.signalAll(); // set up next generation count = parties; generation = new Generation();&#125; 首先将broken设置为了true。我们可以把刚刚执行过的线程想象成第一代线程，当第一代线程没有全部执行完时，broken=false。执行完之后broken为true，根据上面的doawait源码，我们就可以理解为对当前cyclicBarrier进行一次flush操作，踢出所有线程将CyclicBarrier恢复原样，等待下一批线程的使用。同时我们可以发现，如果出现异常，调用的breakBarrier方法也是同样的逻辑，将所有等待线程都踢出去，刷新CyclicBarrier，所以本质上它是可以复用的。 12345private void breakBarrier() &#123; generation.broken = true; count = parties; trip.signalAll();&#125; 所以在执行完之后可以在主函数中打印一下CyclicBarrier的count值,可以发现并没有减为0，而是初始值4. 1System.out.println(cyclicBarrier.getParties()); CountDownLatch vs CyclicBarrier 构造函数赋值的意义不同，一个是执行任务的线程数量，一个是等待线程的数量 CyclicBarrier可以重复使用，CountDownLatch使用后会变为0 Phaser与CountDownLatch和CyclicBarrier功能类似，都可以对任务进行不同粒度的划分，但是Phaser支持动态的增加和减少初始化构造器parties的个数,在功能上完全可以替代前面两个。 coding1234567891011121314151617181920212223242526272829303132333435363738394041424344public class PhaserTest &#123; public static Random random = new Random(System.currentTimeMillis()); public static void main(String[] args) &#123; Phaser phaser = new Phaser(5); for (int i = 1; i &lt; 6; i++) &#123; new Athletes(i,phaser).start(); &#125; &#125; static class Athletes extends Thread&#123; private final int no; private final Phaser phaser; public Athletes(int no, Phaser phaser) &#123; this.no = no; this.phaser = phaser; &#125; @Override public void run() &#123; try &#123; System.out.println(&quot;运动员&quot;+no+&quot;开始跑步了&quot;); TimeUnit.SECONDS.sleep(random.nextInt(5)); System.out.println(&quot;运动员&quot;+no+&quot;跑完了&quot;); phaser.arriveAndAwaitAdvance(); System.out.println(phaser.getPhase()); System.out.println(&quot;运动员&quot;+no+&quot;开始骑车了&quot;); TimeUnit.SECONDS.sleep(random.nextInt(5)); System.out.println(&quot;运动员&quot;+no+&quot;骑完了&quot;); phaser.arriveAndAwaitAdvance(); System.out.println(phaser.getPhase()); System.out.println(&quot;运动员&quot;+no+&quot;开始跳远了&quot;); TimeUnit.SECONDS.sleep(random.nextInt(5)); System.out.println(&quot;运动员&quot;+no+&quot;完成跳远了&quot;); phaser.arriveAndAwaitAdvance(); System.out.println(phaser.getPhase()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 输出结果 123456789101112131415161718192021222324252627282930运动员1开始跑步了运动员3开始跑步了运动员2开始跑步了运动员5开始跑步了运动员4开始跑步了运动员5跑完了运动员3跑完了运动员1跑完了运动员2跑完了运动员4跑完了运动员4开始骑车了运动员5开始骑车了运动员1开始骑车了运动3开始骑车了运动员2开始骑车了运动员2骑完了运动员5骑完了运动员4骑完了运动员1骑完了运动员3骑完了运动员2开始跳远了运动员4开始跳远了运动员5开始跳远了运动员3开始跳远了运动员1开始跳远了运动员5完成跳远了运动员4完成跳远了运动员2完成跳远了运动员3完成跳远了运动员1完成跳远了 可以看到Phaser可以做到CyclicBarrier和CountDownLatch相同的功能，但是考虑这样的场景，加入有一个运动员骑车之后受伤了，不能参加第三阶段的比赛那该怎么办呢,模拟一下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class PhaserTest &#123; public static Random random = new Random(System.currentTimeMillis()); public static void main(String[] args) &#123; Phaser phaser = new Phaser(5); for (int i = 1; i &lt; 5; i++) &#123; new Athletes(i,phaser).start(); &#125; new Injured(6,phaser).start(); &#125; static class Athletes extends Thread&#123; private final int no; private final Phaser phaser; public Athletes(int no, Phaser phaser) &#123; this.no = no; this.phaser = phaser; &#125; @Override public void run() &#123; try &#123; sport(phaser,&quot;运动员&quot;+no+&quot;开始跑步了&quot;,&quot;运动员&quot;+no+&quot;跑完了&quot;); sport(phaser,&quot;运动员&quot;+no+&quot;开始骑车了&quot;,&quot;运动员&quot;+no+&quot;骑完了&quot;); sport(phaser,&quot;运动员&quot;+no+&quot;开始跳远了&quot;,&quot;运动员&quot;+no+&quot;完成跳远了&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; static class Injured extends Thread&#123; private final int no; private final Phaser phaser; public Injured(int no, Phaser phaser) &#123; this.no = no; this.phaser = phaser; &#125; @Override public void run() &#123; try &#123; sport(phaser,&quot;运动员&quot;+no+&quot;开始跑步了&quot;,&quot;运动员&quot;+no+&quot;跑完了&quot;); sport(phaser,&quot;运动员&quot;+no+&quot;开始骑车了&quot;,&quot;运动员&quot;+no+&quot;骑完了&quot;); System.out.println(&quot;我受伤了&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void sport(Phaser phaser,String s1,String s2) throws InterruptedException &#123; System.out.println(s1); TimeUnit.SECONDS.sleep(random.nextInt(5)); System.out.println(s2); phaser.arriveAndAwaitAdvance(); &#125;&#125; 输出结果: 12345678910....运动员4开始跳远了运动员2开始跳远了运动员1开始跳远了运动员3开始跳远了我受伤了运动员3完成跳远了运动员2完成跳远了运动员4完成跳远了运动员1完成跳远了 可以看到结果可以输出，但是程序并不会停止，因为第三阶段的线程没有达到预定的数目，全部都进入无限等待中。那么按照正常的逻辑，一个运动员受伤后应该离开赛场，不应该影响其他运动员的比赛。而我们写的程序确是将运动员留在赛场上，所以为了程序正常退出，应该这样做: 1234sport(phaser,&quot;运动员&quot;+no+&quot;开始跑步了&quot;,&quot;运动员&quot;+no+&quot;跑完了&quot;);sport(phaser,&quot;运动员&quot;+no+&quot;开始骑车了&quot;,&quot;运动员&quot;+no+&quot;骑完了&quot;);System.out.println(&quot;我受伤了&quot;);phaser.arriveAndDeregister(); 通过这个方法，线程与phaser动态解绑，程序正常退出。 考虑4x100接力赛的场景，从相同的起点出发，每个赛道的选手只需要和下一位队友接棒就可以，并不需要等待其他对手到达再跑。那么我们可以使用 1phaser.arrive(); 它的作用就是在每个阶段的终点大喊一声”我到啦”,然后继续执行，并不会等待其他线程到齐。 另一个phaser常用的方法就是awaitAdvace()，这个方法接受一个int值，当且劲当int值==phaser.getPhase()时，程序阻塞，填入其他任意值将不会阻塞。 还有很多方法就不作介绍了，主要是一些中断方法以及观察phaser状态的方法。日常的使用都是灵活组合arriveXXX()方法和awaitXXX()方法。 源码 https://www.cnblogs.com/lytwajue/p/7258278.html 源码自己看了很久都没看懂，尤其是phaser的堆叠部分。看了这篇文章才有点理解，能力有限，这里就不解释了。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq入门-MessageConverter(6)]]></title>
    <url>%2F2018%2F02%2F01%2FRabbitMq%E5%85%A5%E9%97%A8-MessageConverter-6%2F</url>
    <content type="text"><![CDATA[简介AmqpTemplate还定义了几种发送和接收消息的方法，这些方法将委托给一个MessageConverter。 MessageConverter本身非常简单。它为每个方向提供一个方法：一个用于将消息转换为Message实体，另一个用于将Message转换为Object。 12345678public interface MessageConverter &#123; Message toMessage(Object object, MessageProperties messageProperties) throws MessageConversionException; Object fromMessage(Message message) throws MessageConversionException;&#125; 下面列出了AmqpTemplate上的相关消息发送方法。它们比我们先前讨论的方法简单，因为它们不需要Message实例。相反，MessageConverter可以将要发送的消息转换为字节数组。 123456789101112131415void convertAndSend(Object message) throws AmqpException;void convertAndSend(String routingKey, Object message) throws AmqpException;void convertAndSend(String exchange, String routingKey, Object message) throws AmqpException;void convertAndSend(Object message, MessagePostProcessor messagePostProcessor) throws AmqpException;void convertAndSend(String routingKey, Object message, MessagePostProcessor messagePostProcessor) throws AmqpException;void convertAndSend(String exchange, String routingKey, Object message, MessagePostProcessor messagePostProcessor) throws AmqpException; 在接收端只有两个方法 123Object receiveAndConvert() throws AmqpException;Object receiveAndConvert(String queueName) throws AmqpException; SimpleMessageConverterMessageConverter的默认实现为SimpleMessageConverter。如果你没有明确地配置MessageConverter，这个转换器将被RabbitTemplate的使用。它处理基于文本的内容，序列化的Java对象和简单的字节数组。 Message转换为对象如果输入消息的内容类型以“text”开始(例如“text/plain”),MessageConverter还会检查content-encoding属性，用来确定将Message的body转换为java的String类型所需要的字符集。如果没有设置这个属性，默认是UTF-8.如果需要设置，可以配置SimpleMessageConverter，设置defaultCharset属性，然后注入到RabbitTemplate中。 如果content-type设置为application/x-java-serialized-object，SimpleMessageConverter将尝试将字节数组反序列化为java对象。但是并不建议这么做，因为这样做会导致消费者和生产者产生紧耦合。 对于所有其他内容类型，SimpleMessageConverter将直接以字节数组形式返回消息正文内容。 转换为Message当任意的java对象转换为Message时，SimpleMessageConverter会将对象转换为字节数组，并且设置相应的content-type属性。 Jackson2JsonMessageConverter#####转换为Message 通常我们不提倡直接使用序列化或反序列化的消息转换器，所以Json就是一个比较好的替代方案，它在不同平台上更加灵活也有更好的可移植性。Jackson2JsonMessageConverter可以在任何RabbitTemplate实例上配置，以覆盖其对SimpleMessageConverter默认值的使用。 Jackson2JsonMessageConverter使用com.fasterxml.jackson 2.x库。 123456789&lt;bean class=&quot;org.springframework.amqp.rabbit.core.RabbitTemplate&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;rabbitConnectionFactory&quot;/&gt; &lt;property name=&quot;messageConverter&quot;&gt; &lt;bean class=&quot;org.springframework.amqp.support.converter.Jackson2JsonMessageConverter&quot;&gt; &lt;!-- if necessary, override the DefaultClassMapper --&gt; &lt;property name=&quot;classMapper&quot; ref=&quot;customClassMapper&quot;/&gt; &lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt; 可以根据自己的需要，添加MessageConverter的映射 12345678&lt;bean id=&quot;jsonConverterWithDefaultType&quot; class=&quot;o.s.amqp.support.converter.Jackson2JsonMessageConverter&quot;&gt; &lt;property name=&quot;classMapper&quot;&gt; &lt;bean class=&quot;org.springframework.amqp.support.converter.DefaultClassMapper&quot;&gt; &lt;property name=&quot;defaultType&quot; value=&quot;foo.PurchaseOrder&quot;/&gt; &lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt; 对于springboot可以这样配置: 12345678910111213141516@Beanpublic Jackson2JsonMessageConverter jsonMessageConverter() &#123; Jackson2JsonMessageConverter jsonConverter = new Jackson2JsonMessageConverter(); jsonConverter.setClassMapper(classMapper()); return jsonConverter;&#125;@Beanpublic DefaultClassMapper classMapper() &#123; DefaultClassMapper classMapper = new DefaultClassMapper(); Map&lt;String, Class&lt;?&gt;&gt; idClassMapping = new HashMap&lt;&gt;(); idClassMapping.put(&quot;foo&quot;, Foo.class); idClassMapping.put(&quot;bar&quot;, Bar.class); classMapper.setIdClassMapping(idClassMapping); return classMapper;&#125; Message转换为对象根据发送方加在消息头中的类型信息，可以将message转换为对象。在1.6之前的版本中，如果类型信息不存在，转换将失败。从版本1.6开始，如果缺少类型信息，转换器将使用Jackson默认值（通常是map）转换JSON。在1.6之后的版本，如果使用@Rabbitlistener注解，可以配置MessageProperties加入类型信息。 在默认情况下，推断的类型信息会覆盖发送方发送消息的TypeId和头信息。消息的接收方可以自动将其转换为不同的域对象。但这种配置只适用于参数类型是实体类或者来自java.util包下的情况。抽象类和接口则不适用。假设有一个RabbitListener，它接受一个Foo参数，但是这个消息包含一个Bar，它是Foo的子类。这时类型推断将产生错误，无法解析。要处理这种情况，请将Jackson2JsonMessageConverter上的TypePrecedence属性设置为TYPE_ID而不是默认的INFERRED。该属性实际上是在转换器的DefaultJackson2JavaTypeMapper中，但是为了方便，在转换器上提供了一个setter。如果注入自定义类型映射器，则应该在映射器上设置该属性。 1234567891011121314151617@RabbitListenerpublic void foo(Foo foo) &#123;...&#125;@RabbitListenerpublic void foo(@Payload Foo foo, @Header(&quot;amqp_consumerQueue&quot;) String queue) &#123;...&#125;@RabbitListenerpublic void foo(Foo foo, o.s.amqp.core.Message message) &#123;...&#125;@RabbitListenerpublic void foo(Foo foo, o.s.messaging.Message&lt;Foo&gt; message) &#123;...&#125;@RabbitListenerpublic void foo(Foo foo, String bar) &#123;...&#125;@RabbitListenerpublic void foo(Foo foo, o.s.messaging.Message&lt;?&gt; message) &#123;...&#125; 在上面的四个例子中，转换器将尝试转换为Foo类型。第五个例子是无效的，因为我们不能确定哪个参数应该接收消息payload。在第六个示例中，由于泛型类型，所以Jackson会使用默认配置。 然而，可以创建自定义转换器并使用targetMethod消息属性来决定将JSON转换为哪种类型。 只有在方法级别声明RabbitListener注释时才能实现此类型推断。使用类级别RabbitListener时，转换后的类型用于选择要调用哪个RabbitHandler方法。为此，基础结构提供了targetObject消息属性，可以由自定义转换器使用它来确定类型。 RabbitTemplate消息转换正如上面提到的，类型信息在消息头中传送，帮助转换器转换消息。这在大多数条件下有用，但是当使用泛型时，它只能转换简单的对象和部分容器对象(list,array,map)。从2.0版本开始，Jackson2JsonMessageConverter实现了SmartMessageConverter接口，允许rabbitTemplate使用ParameterizedTypeReference，这个对象可以用来包装复杂的参数 12Foo&lt;Bar&lt;Baz, Qux&gt;&gt; foo = rabbitTemplate.receiveAndConvert(new ParameterizedTypeReference&lt;Foo&lt;Bar&lt;Baz, Qux&gt;&gt;&gt;() &#123; &#125;); ContentTypeDelegatingMessageConverter该类在1.4.2版本中引入，并允许根据MessageProperties中的内容类型属性委派特定的MessageConverter。默认情况下，如果没有contentType属性或者不匹配配置转换器的值，它将委托给SimpleMessageConverter。看起来这个MessageConverter是比较好用的。 12345678&lt;bean id=&quot;contentTypeConverter&quot; class=&quot;ContentTypeDelegatingMessageConverter&quot;&gt; &lt;property name=&quot;delegates&quot;&gt; &lt;map&gt; &lt;entry key=&quot;application/json&quot; value-ref=&quot;jsonMessageConverter&quot; /&gt; &lt;entry key=&quot;application/xml&quot; value-ref=&quot;xmlMessageConverter&quot; /&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt;]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq入门-消息发送与接收(5)]]></title>
    <url>%2F2018%2F01%2F31%2FRabbitMq%E5%85%A5%E9%97%A8-%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E4%B8%8E%E6%8E%A5%E6%94%B6-5%2F</url>
    <content type="text"><![CDATA[SpringBoot1.5.9 https://projects.spring.io/spring-amqp/ &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; 发送消息如果你使用AmqpTemplate，发送消息时，可以使用以下方法： 12345void send(Message message) throws AmqpException;void send(String routingKey, Message message) throws AmqpException;void send(String exchange, String routingKey, Message message) throws AmqpException; 如果没有设置exchange的属性，那么它默认会是空。也就会发送到rabbitmq默认的exchange中。因为AMQP规范将“默认Exchange”定义为没有名称。 如果你使用AmqpTemplate的一个实现RabbitTemplate，那么会多一个方法的重载，接受一个额外的correlationData对象，当publisher启用了ack机制，这个对象会在回调中返回。这将允许发送者将ack与发送的消息相关联。 1send(final String exchange, final String routingKey, final Message message, final CorrelationData correlationData) throws AmqpException MessageBuilder API可以通过MessageBuilder构造Message对象 12345Message message = MessageBuilder.withBody(&quot;foo&quot;.getBytes()) .setContentType(MessageProperties.CONTENT_TYPE_TEXT_PLAIN) .setMessageId(&quot;123&quot;) .setHeader(&quot;bar&quot;, &quot;baz&quot;) .build(); 12345678MessageProperties props = MessagePropertiesBuilder.newInstance() .setContentType(MessageProperties.CONTENT_TYPE_TEXT_PLAIN) .setMessageId(&quot;123&quot;) .setHeader(&quot;bar&quot;, &quot;baz&quot;) .build();Message message = MessageBuilder.withBody(&quot;foo&quot;.getBytes()) .andProperties(props) .build(); 批处理从版本1.4.2开始，引入了BatchingRabbitTemplate。这是RabbitTemplate的一个子类，它有一个重写的发送方法，它根据BatchingStrategy对消息进行批处理;只有当批处理完成时才会发送消息给RabbitMQ。BatchingStrategy是一个接口，有一个实现类SimpleBatchingStrategy，它支持将消息发送到单个的交换器或者routingKey。需要注意的是，这个方法需要将correlationData设置为null并且拒绝来自批次的任何消息将导致整个批次被拒绝。 接收消息信息的接收要比发送复杂。有两种方式可以接受信息，一种是轮询单个消息，更复杂更常见的是注册一个异步事件监听器，看一下两种方式的demo 轮询AmqpTemplate本身可用于轮询消息接收。默认情况下，如果没有消息可用，则立即返回null,没有阻塞。从1.5版本开始，你可以设置receiveTimeout，它将阻塞式的等待一个消息直至时间结束，如果设置为负数，则表示永远等待。template提供了大量receive方法 1234567Message receive() throws AmqpException;Message receive(String queueName) throws AmqpException;Message receive(long timeoutMillis) throws AmqpException;Message receive(String queueName, long timeoutMillis) throws AmqpException; 带convert关键字的表示会经过默认的utf-8转码 1234567Object receiveAndConvert() throws AmqpException;Object receiveAndConvert(String queueName) throws AmqpException;Message receiveAndConvert(long timeoutMillis) throws AmqpException;Message receiveAndConvert(String queueName, long timeoutMillis) throws AmqpException; ####异步方式 spring AMQP提供了一种通过注解注册listener的方式，即:@RabbitListener。需要注意，开启这种注解需要在一个@Configuration类上加入@EnableRabbit注解 在方法上添加一个@RabbitHandler注解表示对接收到消息的处理，传入的参数即接收到的消息 123456789@RabbitListener(queues = &#123;&quot;Queue1&quot;,&quot;Queue2&quot;&#125;)@Componentpublic class RabbitTest &#123; @RabbitHandler public void handle(String msg)&#123; System.out.println(&quot;接收到消息&quot;+msg); &#125;&#125; 另一种方法是在方法上添加@RabbitListener注解 123456789101112131415161718192021222324252627@Componentpublic class MyService &#123; @RabbitListener(bindings = @QueueBinding( value = @Queue(value = &quot;myQueue&quot;, durable = &quot;true&quot;), exchange = @Exchange(value = &quot;auto.exch&quot;, ignoreDeclarationExceptions = &quot;true&quot;), key = &quot;orderRoutingKey&quot;) ) public void processOrder(Order order) &#123; ... &#125; @RabbitListener(bindings = @QueueBinding( value = @Queue, exchange = @Exchange(value = &quot;auto.exch&quot;), key = &quot;invoiceRoutingKey&quot;) ) public void processInvoice(Invoice invoice) &#123; ... &#125; @RabbitListener(queuesToDeclare = @Queue(name = &quot;$&#123;my.queue&#125;&quot;, durable = &quot;true&quot;)) public String handleWithSimpleDeclare(String data) &#123; ... &#125;&#125; 如果使用了Header模式，参数的配置需要写在arguments里 1234567891011121314@RabbitListener(bindings = @QueueBinding( value = @Queue(value = &quot;auto.headers&quot;, autoDelete = &quot;true&quot;, arguments = @Argument(name = &quot;x-message-ttl&quot;, value = &quot;10000&quot;, type = &quot;java.lang.Integer&quot;)), exchange = @Exchange(value = &quot;auto.headers&quot;, type = ExchangeTypes.HEADERS, autoDelete = &quot;true&quot;), arguments = &#123; @Argument(name = &quot;x-match&quot;, value = &quot;all&quot;), @Argument(name = &quot;foo&quot;, value = &quot;bar&quot;), @Argument(name = &quot;baz&quot;) &#125;))public String handleWithHeadersExchange(String foo) &#123; ...&#125; 容器容器是一个生命周期的管理组件，它提供了启动和停止的方法。在配置容器时，可以显式的对队列和监听器进行绑定。最常使用的是SimpleMessageListenerContainer,官方给出的配置是这样的: 1234567891011121314151617@Beanpublic SimpleMessageListenerContainer messageListenerContainer() &#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(); container.setConnectionFactory(rabbitConnectionFactory()); container.setQueueName(&quot;some.queue&quot;); container.setMessageListener(exampleListener()); return container;&#125;@Beanpublic MessageListener exampleListener() &#123; return new MessageListener() &#123; public void onMessage(Message message) &#123; System.out.println(&quot;received: &quot; + message); &#125; &#125;;&#125; 可以看到这里绑定的监听器功能比较单一，如果我们希望能够在接收到信息进行处理并手动ack的话可以这样做: 123456789101112131415161718192021222324252627container.setMessageListener(new ChannelAwareMessageListener() &#123; public void onMessage(Message message, com.rabbitmq.client.Channel channel) throws Exception &#123; byte[] body = message.getBody(); logger.info(&quot;消费端接收到消息 : &quot; + new String(body)); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; &#125;);同时在template要加入一项配置 rabbitConfirmCallBack是注入进来的template.setConfirmCallback(rabbitConfirmCallBack);@Componentpublic class RabbitConfirmCallBack implements RabbitTemplate.ConfirmCallback&#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if(ack)&#123; System.out.println(correlationData); &#125;else&#123; System.out.println(cause); &#125; &#125;&#125;在这里就可以把之前的东西串起来了 MessageConverter 消息转换在唤醒一个listener之前，其实有两个步骤。是使用MessageConverter将Spring AMQP Message转换成spring-messaging Message。 第一步默认的MessageConverter是Spring AMQP SimpleMessageConverter，它处理String和java.io.Serializable对象的转换，其他对象则是byte[]的形式。我们称这个处理器为消息转换器。 第二步的默认转换器是GenericMessageConverter，它委托给DefaultFormattingConversionService进行转换，我们称之为方法参数转换器。 如果我们要修改MessageConverter可以这样做: 12345678@Beanpublic SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory() &#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); ... factory.setMessageConverter(new Jackson2JsonMessageConverter()); ... return factory;&#125; 这里使用了一个jackson2的转换器，但是你需要显式的指定头信息才会起作用。 1setContentType(&quot;application/json;utf-8&quot;) 如果你想指定方法参数转换器，可以这么做 12345678910111213141516171819202122232425262728@Configuration@EnableRabbitpublic class AppConfig implements RabbitListenerConfigurer &#123; ... @Bean public DefaultMessageHandlerMethodFactory myHandlerMethodFactory() &#123; DefaultMessageHandlerMethodFactory factory = new DefaultMessageHandlerMethodFactory(); factory.setMessageConverter(new GenericMessageConverter(myConversionService())); return factory; &#125; @Bean public ConversionService myConversionService() &#123; DefaultConversionService conv = new DefaultConversionService(); conv.addConverter(mySpecialConverter()); return conv; &#125; @Override public void configureRabbitListeners(RabbitListenerEndpointRegistrar registrar) &#123; registrar.setMessageHandlerMethodFactory(myHandlerMethodFactory()); &#125; ...&#125; 消息回复MessageListenerAdapter现在已经支持方法具有非void的返回类型。在这种情况下，调用的结果被封装在原始消息的ReplyToAddress头中指定的地址或者在listener上配置的默认地址中发送的消息中。现在可以使用@SendTo注释来设置该默认地址。 假设我们的processOrder方法现在应该返回一个OrderStatus，那么可以把它写成如下来自动发送一个回复： 123456@RabbitListener(destination = &quot;myQueue&quot;)@SendTo(&quot;status&quot;)public OrderStatus processOrder(Order order) &#123; // order processing return status;&#125; 如果你需要配置一些额外的头信息，可以返回一个Message实体 123456789@RabbitListener(destination = &quot;myQueue&quot;)@SendTo(&quot;status&quot;)public Message&lt;OrderStatus&gt; processOrder(Order order) &#123; // order processing return MessageBuilder .withPayload(status) .setHeader(&quot;code&quot;, 1234) .build();&#125; @SendTo的值也可以使用 Exchange/routingKey的组合 foo/bar 返回给foo交换器，routingKey为bar foor/ 返回给交换器，routingKey默认为空 bar 或者 /bar 指定routingKey使用默认交换器 / 默认交换器 默认routingKey 1.5版本之后，@SendTo支持SpEL表达式。表达式必须返回一个String类型 12345678910@RabbitListener(queues = &quot;test.sendTo.spel&quot;)@SendTo(&quot;#&#123;spelReplyTo&#125;&quot;)public String capitalizeWithSendToSpel(String foo) &#123; return foo.toUpperCase();&#125;...@Beanpublic String spelReplyTo() &#123; return &quot;test.sendTo.reply.spel&quot;;&#125; 多方法的listener从1.5版本开始，支持类级别的@RabbitListener注解，通过@RabbitHandler方法级别的注解，允许单个listener根据传入消息的payload调用不同的方法 1234567891011121314151617181920@RabbitListener(id=&quot;multi&quot;, queues = &quot;someQueue&quot;)public class MultiListenerBean &#123; @RabbitHandler @SendTo(&quot;my.reply.queue&quot;) public String bar(Bar bar) &#123; ... &#125; @RabbitHandler public String baz(Baz baz) &#123; ... &#125; @RabbitHandler public String qux(@Header(&quot;amqp_receivedRoutingKey&quot;) String rk, @Payload Qux qux) &#123; ... &#125;&#125; 简单来说，系统会根据Handler所在方法接受的参数选择由哪个Handler来执行。如果方法有多个参数，那么可以通过注解来指定payload 1234@RabbitHandlerpublic String qux(@Header(&quot;amqp_receivedRoutingKey&quot;) String rk, @Payload Qux qux) &#123; ...&#125; 异常处理从版本2.0开始,RabbitListener注释具有两个新属性：errorHandler和returnExceptions。listener可以监听异常，包装在一个ListenerExecutionFailedException中。错误处理程序可以返回一些结果给发送者，也可以直接抛出异常，取决于returnException的设置。 当returnException为true时，会返回消息给发送者。异常被包装在RemoteInvocationResult对象中。在发送方需要配置一个RemoteInvocationAwareMessageConverterAdapter在template中，它将异常包装在AmqpRemoteException中并重新抛出一个服务器的异常，通过异常堆栈就可以定位错误。 但是这种机制只能在SimpleMessageConverter配置下工作，也就是默认的配置。如果你指定了jackson转换器，由于异常消息通常不是json，所以并不支持这种序列化。如果一定要使用jackson converter，那么应该把错误处理转换为可以序列化为json的对象。 ####多线程与异步消费者 异步消费者的使用涉及到一系列不同的线程。 当一个新的消息到达RabbitMq客户端时，会从SimpleMessageListenerContainer中配置的TaskExecutor线程池中获取线程并唤醒MessageListener。如果没有配置，则会使用SimpleAsyncTaskExecutor。如果使用的是DirectMessageListenerContainer，MessageListener则会由RabbitMq客户端来唤醒，这种情况下，TaskExecutor用于监视消费者任务的执行。 使用默认的SimpleAsyncTaskExecutor时，被listener调用的线程，它的threadNamePrefix属性会被设置为listener容器的beanName，这对于日志的分析非常有用。 容器选择在2.0版本中加入了DirectMessageListenerContainer(DMLC),在此之前只有SimpleMessageListenerContainer(SMLC)。SMLC使用了一个内部队列，每个消费者都有一个独有的线程为它服务。如果一个container配置为监听多个队列，则使用相同的consumer线程处理所有的队列。并发由concurrentConsumers和一些其他属性来控制。当消息到达rabbitmq客户端，客户端线程将它们加入队列再传递给消费者。 DMLC直接通过rabbitmq客户端线程唤醒listener，因此它的结构比SMLC更简单。但是它们有各自的优势: SMLC独有特点: txSize 可以通过这个属性控制事务中传递的Message的数量，并且增加或减少ack的数量，但是这样做可能会导致消息发送失败后重复发送的次数增加。 maxConcurrentConsumers DMLC中不支持自动缩放，只能够已编码的方式修改consumersPerQueue的属性 DMLC优势： 相比于SMLC，DMLC更方便的可以再运行时动态的添加或者删除队列 避免了rabbitmq客户端线程和消费者线程之间的上下文切换 消费者之间共享线程，而SMLC则是为每个消费者提供专用线程]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA继承机制与多态]]></title>
    <url>%2F2018%2F01%2F30%2FJAVA%E7%BB%A7%E6%89%BF%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%A4%9A%E6%80%81%2F</url>
    <content type="text"><![CDATA[java的继承机制无论在工作中还是面试中，都是一个让人非常迷惑的地方。今天被一个朋友的问题难住了，所以查阅了一下相关的资料，在此整理一下 结论 java不支持多继承但支持实现多个接口 在多态情况下,重写方法会调用派生类的方法。非多态情况下会调用本类的方法 对于不同的访问修饰符，成员变量的覆盖情况不同 下面举几个例子加深理解，题目来源于网络 对于方法 1 1234567891011121314151617181920212223242526public class Base&#123; private String baseName = &quot;base&quot;; public Base() &#123; callName(); &#125; public void callName() &#123; System. out. println(baseName); &#125; static class Sub extends Base &#123; private String baseName = &quot;sub&quot;; public void callName() &#123; System. out. println (baseName) ; &#125; &#125; public static void main(String[] args) &#123; Base b = new Sub(); &#125;&#125; 答案是null 在创造派生类的过程中首先创建基类对象，然后才能创建派生类。创建基类即默认调用Base()方法，在方法中调用callName()方法，由于派生类中存在此方法，则被调用的callName()方法是派生类中的方法，此时派生类还未构造，所以变量baseName的值为null。 1.首先，需要明白类的加载顺序。 (1) 父类静态代码块(包括静态初始化块，静态属性，但不包括静态方法) (2) 子类静态代码块(包括静态初始化块，静态属性，但不包括静态方法 ) (3) 父类非静态代码块( 包括非静态初始化块，非静态属性 ) (4) 父类构造函数 (5) 子类非静态代码块 ( 包括非静态初始化块，非静态属性 ) (6) 子类构造函数 其中：类中静态块按照声明顺序执行，并且(1)和(2)不需要调用new类实例的时候就执行了(意思就是在类加载到方法区的时候执行的) 2.其次，需要理解子类覆盖父类方法的问题，也就是方法重写实现多态问题。Base b = new Sub();它为多态的一种表现形式，声明是Base,实现是Sub类， 理解为 b 编译时表现为Base类特性，运行时表现为Sub类特性。当子类覆盖了父类的方法后，意思是父类的方法已经被重写，题中 父类初始化调用的方法为子类实现的方法，子类实现的方法中调用的baseName为子类中的私有属性。由1.可知，此时只执行到步骤4.,子类非静态代码块和初始化步骤还没有到，子类中的baseName还没有被初始化。所以此时 baseName为空。 所以为null。 在内存机制中，父类和子类是占用同一块内存的，只不过子类在父类的基础上增加了自己的部分(包括数据成员和属性)。子类是依附于父类的，先有父类再有子类。所以说一个子类对象的产生，必须先调用父类的构造函数产生一个父类实例，然后在这个实例基础上添加自己的部分。而实际的运行机制，也正是这样的。 对于成员变量 观察这样一个demo 123456789101112131415161718192021222324public class Father &#123; int x = 1; static&#123; System.out.println(&quot;father static&quot;); &#125; public Father()&#123; System.out.println(&quot;father&quot;); &#125;&#125;public class Son extends Father&#123; int x = 2; static&#123; System.out.println(&quot;son static&quot;); &#125; public Son()&#123; System.out.println(&quot;son&quot;); &#125;&#125;public static void main(String[] args) &#123; Father father = new Son(); System.out.println(father.x);&#125; 答案是1,派生类并没有覆盖父类的同名属性,为什么重写的方法会覆盖，同名的属性却不会呢,继续做一下扩展在得出结论 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Father &#123; private String privateField = &quot;父类变量--private&quot;; String friendlyField = &quot;父类变量--friendly&quot;; protected String protectedField = &quot;父类变量--protected&quot;; public String publicField = &quot;父类变量--public&quot;; // private的变量无法直接访问，因此我们给他增加了一个访问方法 public String getPrivateFieldValue() &#123; return privateField; &#125;&#125;public class Son extends Father&#123; private String privateField = &quot;子类变量--private&quot;; String friendlyField = &quot;子类变量--friendly&quot;; protected String protectedField = &quot;子类变量--protected&quot;; public String publicField = &quot;子类变量--public&quot;; // private的变量无法直接访问，因此我们给他增加了一个访问方法 public String getPrivateFieldValue() &#123; return privateField; &#125;&#125;public static void main(String[] args) &#123; //非多态 Father father = new Father(); System.out.println(father.friendlyField); System.out.println(father.protectedField); System.out.println(father.publicField); System.out.println(father.getPrivateFieldValue()); System.out.println(&quot;=======================&quot;); //多态 Father father1 = new Son(); System.out.println(father1.friendlyField); System.out.println(father1.protectedField); System.out.println(father1.publicField); System.out.println(father1.getPrivateFieldValue()); System.out.println(&quot;========================&quot;); //非多态 Son son = new Son(); System.out.println(son.friendlyField); System.out.println(son.protectedField); System.out.println(son.publicField); System.out.println(son.getPrivateFieldValue()); &#125; 结果 1234567891011121314父类变量--friendly父类变量--protected父类变量--public父类变量--private=======================父类变量--friendly父类变量--protected父类变量--public子类变量--private========================子类变量--friendly子类变量--protected子类变量--public子类变量--private 对于两种非多态的情况，输出的结果很好理解。对于多态的情况，子类只覆盖了private修饰的属性。 暂时可以得到的结论是属性的覆盖与修饰属性的访问权限有关。那么访问权限之间有没有优先级呢？继续做一些测试 1234567891011121314151617public class Father &#123; String friendlyField = &quot;父类变量--friendly&quot;;&#125;public class Son extends Father&#123; public String friendlyField = &quot;子类变量&quot;;&#125; public static void main(String[] args) &#123; Father father1 = new Son(); System.out.println(father1.friendlyField); &#125;父类变量--friendly.....省略n种排列组合测试，结果都不会覆盖 分析实际上，即使子类声明了与父类完全一样的成员变量，也不会覆盖掉父类的成员变量。而是在子类实例化时，会同时定义两个成员变量，子类也可以同时访问到这两个成员变量，但父类不能访问到子类的成员变量（父类不知道子类的存在）。而具体在方法中使用成员变量时，究竟使用的是父类还是子类的成员变量，则由方法所在的类决定；即，方法在父类中定义和执行，则使用父类的成员变量，方法在子类中定义（包括覆盖父类方法）和执行，则使用子类的成员变量。方法在多态情况下，除了private都会显示为父类的属性。那如果我们就是想要得到子类的属性，该怎么办呢。我们可以利用继承的重写方法的特点，子类、父类声明get/set方法,那么我们调用方法就可以得到子类的属性啦。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-StampedLock(8)]]></title>
    <url>%2F2018%2F01%2F30%2FJUC-StampedLock-8%2F</url>
    <content type="text"><![CDATA[StampedLockStampedLock字面上理解就是带有时间戳的lock，这个锁是在java8中加入的。为什么要加入这样一个锁呢，原因就要从ReentrantLock和ReadWriteLock给我们带来的便利和问题说起。 ReentrantLock vs synchronized lock的api更加灵活，显式的释放获取锁 lock可以进行扩展，synchronized不可以 lock的效率目前略高于synchronized，以为在java每个版本升级中，都会对synchronized关 键字进行优化 ReentrantReadWriteLock vs ReentrantLock 解决在并发读的过程中不需要加锁 StampedLock 使用场景假设现在有100个线程想要请求资源A，其中99个是读请求，1个是写请求。如果是读请求先获取到资源，那么就可能造成写的饥饿，如果写请求先获取到资源，那么久可能造成读请求的长时间等待。StampedLock的作用就是替换ReentrantLock和ReentrantReadWriteLock,因为StampedLock有这两者的API。ReadWriteLock虽然做到了读写分离，但是它实现的读锁是一个悲观锁，而StampedLock实现了一个乐观的读锁。也就是说在读的同时可以做到写，通过代码看看是怎么做到的。 模拟使用StampedLock分别使用悲观读锁和乐观读锁，7个读线程和1个写线程，观察效果 使用悲观读锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class StampedLockTest &#123; private static StampedLock lock = new StampedLock(); private static List&lt;Long&gt; data = new ArrayList&lt;&gt;(); public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(30); Runnable runnable = ()-&gt;&#123; while (true)&#123; read(); &#125; &#125;; Runnable runnable1 = ()-&gt;&#123; while (true)&#123; write(); &#125; &#125;; executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable1); &#125; private static void read()&#123; long stamped = -1; try &#123; stamped = lock.readLock(); //假设任务是读出data中的数据 Optional.of(data.stream().map(String::valueOf) .collect(Collectors.joining(&quot;#&quot;,&quot;R&quot;,&quot;&quot;))) .ifPresent(System.out::println); TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(stamped); &#125; &#125; private static void write()&#123; long stamp = -1; try&#123; stamp=lock.writeLock(); data.add(System.currentTimeMillis()); TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally&#123; lock.unlock(stamp); &#125; &#125;&#125; 使用乐观读锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class StampedLockTest1 &#123; private static StampedLock lock = new StampedLock(); private static List&lt;Long&gt; data = new ArrayList&lt;&gt;(); public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(30); Runnable runnable = ()-&gt;&#123; while (true)&#123; read(); &#125; &#125;; Runnable runnable1 = ()-&gt;&#123; while (true)&#123; write(); &#125; &#125;; executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable); executorService.submit(runnable1); &#125; private static void read()&#123; long stamped =lock.tryOptimisticRead(); //检查乐观锁是否被修改，如果有就拿不到锁 if(!lock.validate(stamped))&#123; try&#123; stamped=lock.readLock(); //假设任务是读出data中的数据 Optional.of(data.stream().map(String::valueOf) .collect(Collectors.joining(&quot;#&quot;,&quot;R&quot;,&quot;&quot;))) .ifPresent(System.out::println); TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(stamped); &#125; &#125; &#125; private static void write()&#123; long stamp = -1; try&#123; stamp=lock.writeLock(); data.add(System.currentTimeMillis()); TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally&#123; lock.unlock(stamp); &#125; &#125;&#125; 结果7个读+1个写 乐观锁明显优于悲观锁。程序开始读线程便可写入数据，而悲观锁则需要等待很久 推荐一篇很好的性能比较的文章 https://blog.takipi.com/java-8-stampedlocks-vs-readwritelocks-and-synchronized/]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq入门-AmqpTemplate(4)]]></title>
    <url>%2F2018%2F01%2F29%2FRabbitMq%E5%85%A5%E9%97%A8-AmqpTemplate-4%2F</url>
    <content type="text"><![CDATA[简介与Spring Framework及其相关项目提供的许多其他高级抽象一样，Spring AMQP提供了一个扮演主角的“template”。定义主要操作的接口称为AmqpTemplate。这些操作涵盖发送和接收消息的一般行为。换句话说，它们不是唯一的实现，因此名称中有“AMQP”。另一方面，这个接口的实现与AMQP协议的实现有关。与JMS（接口级API本身）不同，AMQP是一个有线协议。该协议的实现提供了自己的客户端库，因此AmqpTemplate接口的每个实现都将依赖于特定的客户端库。目前，只有一个实现：RabbitTemplate。 增加重试机制从版本1.3开始，可以将RabbitTemplate配置为使用RetryTemplate来解决borker连接问题。以下仅是一个使用指数退避策略的示例，以及默认的SimpleRetryPolicy，它会在向调用方抛出异常之前进行三次尝试。 XML方式: 1234567891011&lt;rabbit:template id=&quot;template&quot; connection-factory=&quot;connectionFactory&quot; retry-template=&quot;retryTemplate&quot;/&gt;&lt;bean id=&quot;retryTemplate&quot; class=&quot;org.springframework.retry.support.RetryTemplate&quot;&gt; &lt;property name=&quot;backOffPolicy&quot;&gt; &lt;bean class=&quot;org.springframework.retry.backoff.ExponentialBackOffPolicy&quot;&gt; &lt;property name=&quot;initialInterval&quot; value=&quot;500&quot; /&gt; &lt;property name=&quot;multiplier&quot; value=&quot;10.0&quot; /&gt; &lt;property name=&quot;maxInterval&quot; value=&quot;10000&quot; /&gt; &lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt; @Configuration方式: 123456789101112@Beanpublic AmqpTemplate rabbitTemplate(); RabbitTemplate template = new RabbitTemplate(connectionFactory()); RetryTemplate retryTemplate = new RetryTemplate(); ExponentialBackOffPolicy backOffPolicy = new ExponentialBackOffPolicy(); backOffPolicy.setInitialInterval(500); backOffPolicy.setMultiplier(10.0); backOffPolicy.setMaxInterval(10000); retryTemplate.setBackOffPolicy(backOffPolicy); template.setRetryTemplate(retryTemplate); return template;&#125; ###异步发布，如何检测成功还是失败 发布消息在默认情况下是一种异步机制，RabbitMQ简单地丢弃无法路由的消息。如果成功发布，可以收到一个异步确认信息，我们来考虑两个失败情况： 发布到exchange，但是没有相匹配的目的队列 发布到一个不存在exchange 第一种只需要一个发布确认机制即可。对于第二种情况，会直接丢弃信息而不会产生返回值，底层的channel会因为异常而关闭。默认情况下，这个异常会被记录，你也可以注册一个ConnectionListener获取通知。(在这里官方文档有明显的错误,。本人使用的是1.5.9,函数已经被修改，没有提供异常检测的方法) 123456789101112this.connectionFactory.addConnectionListener(new ConnectionListener() &#123; @Override public void onCreate(Connection connection) &#123; &#125; @Override public void onShutDown(ShutdownSignalException signal) &#123; ... &#125;&#125;); 发布确认和返回AmqpTemplate的RabbitTemplate实现支持Publisher确认和返回。 消息返回对于返回的消息，必须将模板的mandatory属性设置为true，或者对于特定的消息，必须将mandatory-expression设置为true。此功能需要将其publisherReturns属性设置为true的CachingConnectionFactory。返回通过调用setReturnCallback（ReturnCallback回调）注册一个RabbitTemplate.ReturnCallback发送到客户端。回调必须实现这个方法： 123456789@Componentpublic class RabbitCallBack implements RabbitTemplate.ReturnCallback &#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; System.out.println(&quot;收到消息&quot;+message.getBody()+&quot;响应码&quot;+replyCode+&quot;响应内容&quot;+replyText+&quot;来自Exchange:&quot;+exchange+&quot;RoutingKey&quot;+routingKey); &#125;&#125; 12将上面的类注入到配置类中template.setReturnCallback(rabbitCallBack); 需要注意的是，每个RabbitTemplate只支持一个ReturnCallback。 ####消息确认 对于发布者确认（也称为发布者确认），该模板需要一个将其publisherConfirms属性设置为true。通过调用setConfirmCallback（ConfirmCallback回调）注册一个RabbitTemplate.ConfirmCallback，确认被发送到客户端。回调必须实现这个方法： 123456789101112@Componentpublic class RabbitConfirmCallBack implements RabbitTemplate.ConfirmCallback&#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if(ack)&#123; System.out.println(correlationData); &#125;else&#123; System.out.println(cause); &#125; &#125;&#125; 12将上面的类注入到配置类中template.setConfirmCallback(rabbitConfirmCallBack); CorrelationData是客户端接收到的原始信息，如果ack为true，表示信息经过确认，如果ack为false，则cause会包含ack为false的原因。 RabbitTemplate只支持一个ConfirmCallback 当rabbitTemplate发送操作完成时，通道关闭;当连接工厂缓存已满时，将阻止接收确认或返回消息。当缓存满时，框架将延迟关闭达5秒钟，以便有时间接收确认/返回。当使用确认时，当收到最后一次确认时，频道将被关闭。仅使用返回时，通道将保持打开5秒。通常建议将连接工厂的channelCacheSize设置为足够大的值，以使发布消息的通道返回缓存而不是关闭。您可以使用RabbitMQ management plugin监控频道使用情况;如果您看到频道正在快速打开/关闭，则应考虑增加缓存大小以减少服务器上的开销。 与spring message整合从版本1.4开始，构建在RabbitTemplate之上的RabbitMessagingTemplate提供了与Spring Framework消息抽象（即org.springframework.messaging.Message）的集成。这允许你使用spring-messaging Message&lt;?&gt; 抽象来发送和接收消息。其他Spring项目（如Spring Integration和Spring的STOMP支持）使用了这种抽象。有两个消息转换器参与:一个用于在Spring消息传递Message&lt;?&gt;和Spring AMQP的Message抽象之间进行转换，另一个用于在Spring AMQP的Message抽象和底层RabbitMQ客户端库所需的格式之间进行转换。默认情况下，消息的payload由的RabbitTemplate的消息转换器负责转换。或者，你可以注入一个自定义MessagingMessageConverter与其他payload转换器： 123MessagingMessageConverter amqpMessageConverter = new MessagingMessageConverter();amqpMessageConverter.setPayloadConverter(myPayloadConverter);rabbitMessagingTempalte.setAmqpMessageConverter(amqpMessageConverter); 总结对RabbitMq进行配置 1234567891011121314151617181920212223242526272829303132333435363738@Autowired private RabbitCallBack rabbitCallBack; @Autowired private RabbitConfirmCallBack rabbitConfirmCallBack; @Bean public ConnectionFactory rabbitMqConnection() &#123; CachingConnectionFactory connectionFactory = new CachingConnectionFactory(); connectionFactory.setHost(&quot;47.95.205.65&quot;); connectionFactory.setPort(5672); connectionFactory.setConnectionNameStrategy(ConnectionFactory -&gt; &quot;MyConnection&quot;); connectionFactory.setVirtualHost(&quot;/&quot;); connectionFactory.setUsername(&quot;admin&quot;); connectionFactory.setPassword(&quot;123&quot;); connectionFactory.setChannelCacheSize(25); //单位是毫秒 connectionFactory.setChannelCheckoutTimeout(2000); connectionFactory.setPublisherConfirms(true); connectionFactory.setPublisherReturns(true); connectionFactory.setCacheMode(CachingConnectionFactory.CacheMode.CHANNEL); return connectionFactory; &#125; @Bean public AmqpTemplate rabbitTemplate() &#123; RabbitTemplate template = new RabbitTemplate(rabbitMqConnection()); RetryTemplate retryTemplate = new RetryTemplate(); ExponentialBackOffPolicy backOffPolicy = new ExponentialBackOffPolicy(); backOffPolicy.setInitialInterval(500); backOffPolicy.setMultiplier(10.0); backOffPolicy.setMaxInterval(10000); retryTemplate.setBackOffPolicy(backOffPolicy); template.setRetryTemplate(retryTemplate); template.setMandatory(true); template.setReturnCallback(rabbitCallBack); template.setConfirmCallback(rabbitConfirmCallBack); return template; &#125;]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq入门-连接和资源管理(3)]]></title>
    <url>%2F2018%2F01%2F29%2FRabbitMq%E5%85%A5%E9%97%A8-%E8%BF%9E%E6%8E%A5%E5%92%8C%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86-3%2F</url>
    <content type="text"><![CDATA[官方文档 https://docs.spring.io/spring-amqp/docs/2.0.1.RELEASE/reference/html/_reference.html#_introduction_4 简介用于管理与RabbitMQ代理的核心组件是ConnectionFactory接口。ConnectionFactory的实现类负责提供一个org.springframework.amqp.rabbit.connection.Connection的实例，它是com.rabbitmq.client.Connection的一个封装。官方提供的唯一的具体实现是CachingConnectionFactory。默认情况下，它建立一个可以被应用程序共享的连接代理(可以理解为一个全局配置)。因为与AMQP进行消息传递的“工作单元”实际上是一个“通道”（在某些方面，这与JMS中的Connection和Session之间的关系类似），所以可以共享连接。如你所想，连接实例提供了一个createChannel方法。 CachingConnectionFactory实现支持这些通道的高速缓存，并根据它们是否是事务处理来维护通道的单独高速缓存。在创建CachingConnectionFactory的实例时，可以通过构造函数提供主机名,用户名和密码。如果你想配置通道缓存的大小（默认是25），你也可以在这里调用setChannelCacheSize()方法. 可以看到一个SingleConnectionFactory实现类，它只在框架的单元测试代码中可用。它比CachingConnectionFactory简单，因为它不会缓存通道，但由于缺乏性能和弹性，它不适用于简单测试之外的实际应用。如果由于某种原因需要实现自己的ConnectionFactory，那么可以通过继承AbstractConnectionFactory来实现。 从版本1.3开始，CachingConnectionFactory可以缓存连接数也可以只缓存通道。在这种情况下，每次调用createConnection()都会创建一个新连接（或从缓存中检索一个空闲连接）。关闭连接会将其返回到缓存（如果尚未达到缓存大小）。在这样的连接上创建的通道也被缓存。 如果缓存大小为10，则可以使用任意数量的通道。如果超过10个通道正在使用，他们都返回到缓存，10将进入缓存;其余的将被关闭。 从版本1.6开始，默认通道高速缓存大小从1增加到25.在大容量，多线程环境中，缓存太小意味着频繁地创建和关闭通道。增加默认缓存大小将避免这种开销。可以通过RabbitMQ管理界面监视正在使用的频道，并且如果您看到许多频道正在创建和关闭，请考虑进一步增加缓存大小。缓存只能按需增长（以适应应用程序的并发需求），所以这种改变不会影响现有的低容量应用程序。 从版本1.4.2开始，CachingConnectionFactory有一个属性channelCheckoutTimeout。当此属性大于零时，channelCacheSize将成为可在连接上创建的通道数的最大值。如果达到限制，调用线程将阻塞，直到有一个通道可用或达到超时，在这种情况下会引发AmqpTimeoutException。 配置标准的连接如果没有使用spring框架创建通道，则需要手动的创建通道 12345CachingConnectionFactory connectionFactory = new CachingConnectionFactory(&quot;somehost&quot;);connectionFactory.setUsername(&quot;guest&quot;);connectionFactory.setPassword(&quot;guest&quot;);Connection connection = connectionFactory.createConnection(); XML配置 123456&lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.amqp.rabbit.connection.CachingConnectionFactory&quot;&gt; &lt;constructor-arg value=&quot;somehost&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;guest&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;guest&quot;/&gt;&lt;/bean&gt; 如果配置了rabbitmq的命名空间，也可以这样做。它会使用默认的配置创建一个CachingConnectionFactory 1&lt;rabbit:connection-factory id=&quot;connectionFactory&quot;/&gt; 从版本2.0开始，为注入到AbstractionConnectionFactory提供了一个ConnectionNameStrategy。生成的名称用于目标RabbitMQ连接的应用程序特定标识。如果RabbitMQ服务器支持，连接名称将显示在管理UI中。该值不必是唯一的，并且不能用作连接标识符，例如在HTTP API请求中。该值应该是可以让人理解的，并且是connection_name键下的ClientProperties的一部分。可以简单的使用lambda表达式设置 1connectionFactory.setConnectionNameStrategy(ConnectionFactory-&gt;&quot;MyConnection&quot;); 当应用程序使用单个CachingConnectionFactory进行配置时，也就是默认情况下使用Spring Boot自动配置。当Broker(rabbitmq实例)阻止连接时，应用程序将停止工作。也就是说当Broker停止工作时，任何client也会无法使用。如果我们在同一个应用程序中有生产者和消费者，那么当生产者阻塞连接时，可能会导致死锁，因为Broker上没有资源，消费者也不能释放它们，因为连接被阻塞。为了缓解这个问题，需要再配置一个CachingConnectionFactory实例，一个用于生产者，一个用于消费者。分离的CachingConnectionFactory不推荐用于事务性生产者，因为事务性的生产者应该与消费者使用相同的通道。 安全的连接(ssl)从版本1.4开始，提供了一个方便的RabbitConnectionFactoryBean，以便使用依赖注入方便地在底层客户端连接工厂中配置SSL属性。 123456789101112&lt;rabbit:connection-factory id=&quot;rabbitConnectionFactory&quot; connection-factory=&quot;clientConnectionFactory&quot; host=&quot;$&#123;host&#125;&quot; port=&quot;$&#123;port&#125;&quot; virtual-host=&quot;$&#123;vhost&#125;&quot; username=&quot;$&#123;username&#125;&quot; password=&quot;$&#123;password&#125;&quot; /&gt;&lt;bean id=&quot;clientConnectionFactory&quot; class=&quot;org.springframework.xd.dirt.integration.rabbit.RabbitConnectionFactoryBean&quot;&gt; &lt;property name=&quot;useSSL&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;sslPropertiesLocation&quot; value=&quot;file:/secrets/rabbitSSL.properties&quot;/&gt;&lt;/bean&gt; Routing Connection Factory从版本1.3开始，已经引入了AbstractRoutingConnectionFactory。这提供了一种机制来配置多个ConnectionFactory的映射，并在运行时通过一些lookupKey来确定目标ConnectionFactory。通常，实现检查线程绑定的上下文。为了方便起见，Spring AMQP提供了SimpleRoutingConnectionFactory，它从SimpleResourceHolder获取当前线程绑定的lookupKey。其核心的数据结构是一个Map，看一个使用demo 1234567891011&lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.amqp.rabbit.connection.SimpleRoutingConnectionFactory&quot;&gt; &lt;property name=&quot;targetConnectionFactories&quot;&gt; &lt;map&gt; &lt;entry key=&quot;#&#123;connectionFactory1.virtualHost&#125;&quot; ref=&quot;connectionFactory1&quot;/&gt; &lt;entry key=&quot;#&#123;connectionFactory2.virtualHost&#125;&quot; ref=&quot;connectionFactory2&quot;/&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt;&lt;rabbit:template id=&quot;template&quot; connection-factory=&quot;connectionFactory&quot; /&gt; 123456789101112public class MyService &#123; @Autowired private RabbitTemplate rabbitTemplate; public void service(String vHost, String payload) &#123; SimpleResourceHolder.bind(rabbitTemplate.getConnectionFactory(), vHost); rabbitTemplate.convertAndSend(payload); SimpleResourceHolder.unbind(rabbitTemplate.getConnectionFactory()); &#125;&#125; 也就是说这种连接工厂支持动态的绑定和解绑你所使用的连接，但是需要注意，在使用完资源之后一定要unbind，就像lock方法一定要进行unlock。 队列亲和性以及LocalizedQueueConnectionFactory在群集中使用高可用队列时，为了获得最佳性能，可能需要连接到主队列所在的物理地址。虽然CachingConnectionFactory可以配置多个地址，但这只是用于故障转移，客户端将尝试按顺序重新连接。 LocalizedQueueConnectionFactory使用admin plugin提供的REST API来确定哪个节点的队列被选为主队列。然后它创建（或从缓存中检索）一个将连接到该节点的CachingConnectionFactory。如果连接失败，则确定新的主节点，并且让客户连接到它。 LocalizedQueueConnectionFactory配置了一个默认的连接工厂，以防队列的物理位置无法确定，在这种情况下，它将正常连接到集群。 出于这个原因（使用队列名称进行查找），LocalizedQueueConnectionFactory只能在容器配置为侦听单个队列时使用。 给出一个springboot的配置 1234567891011121314151617181920212223242526@Autowiredprivate RabbitProperties props;private final String[] adminUris = &#123; &quot;http://host1:15672&quot;, &quot;http://host2:15672&quot; &#125;;private final String[] nodes = &#123; &quot;rabbit@host1&quot;, &quot;rabbit@host2&quot; &#125;;@Beanpublic ConnectionFactory defaultConnectionFactory() &#123; CachingConnectionFactory cf = new CachingConnectionFactory(); cf.setAddresses(this.props.getAddresses()); cf.setUsername(this.props.getUsername()); cf.setPassword(this.props.getPassword()); cf.setVirtualHost(this.props.getVirtualHost()); return cf;&#125;@Beanpublic ConnectionFactory queueAffinityCF( @Qualifier(&quot;defaultConnectionFactory&quot;) ConnectionFactory defaultCF) &#123; return new LocalizedQueueConnectionFactory(defaultCF, StringUtils.commaDelimitedListToStringArray(this.props.getAddresses()), this.adminUris, this.nodes, this.props.getVirtualHost(), this.props.getUsername(), this.props.getPassword(), false, null);&#125; 消息发布确认与返回通过将CachingConnectionFactory的publisherConfirms和publisherReturns属性分别设置为“true”来支持已确认和返回的消息。 当这些选项被设置时，由工厂创建的Channel被封装在一个PublisherCallbackChannel中，用于简化回调。当获得这样的channel时，客户端可以在channel上注册一个PublisherCallbackChannel.Listener。 PublisherCallbackChannel实现包含将确认/返回路由到合适的侦听器的逻辑。 connectionListener和channelListener连接工厂支持注册ConnectionListener和ChannelListener实现。这使您可以接收有关connection和channel相关事件的通知。 12connectionFactory.setConnectionListeners();connectionFactory.setChannelListeners(); 通道关闭事件日志在1.5版本中引入了一个使用户能够控制日志级别的机制。 CachingConnectionFactory使用默认策略来记录通道关闭，如下所示： 正常通道关闭（200 OK）不记录。如果通道由于被动队列声明失败而关闭，则会在调试级别进行记录。如果由于独占消费者条件而导致basic.consume被拒绝，因此频道被关闭，则它将以INFO级别记录。所有其他错误都记录在ERROR级别。 要修改此行为，请在其closeExceptionLogger属性中将自定义的ConditionalExceptionLogger注入到CachingConnectionFactory中。 总结这一节主要是讲了RabbitMq的核心ConnectionFactory的一些配置和要点，根据上面的讲述，自己配置一个ConnectionFactory 1234567891011121314151617@Beanpublic ConnectionFactory rabbitMqConnection()&#123; CachingConnectionFactory connectionFactory = new CachingConnectionFactory(); connectionFactory.setHost(&quot;47.95.205.65&quot;); connectionFactory.setPort(5672); connectionFactory.setConnectionNameStrategy(ConnectionFactory-&gt;&quot;MyConnection&quot;); connectionFactory.setVirtualHost(&quot;/&quot;); connectionFactory.setUsername(&quot;admin&quot;); connectionFactory.setPassword(&quot;123&quot;); connectionFactory.setChannelCacheSize(25); //单位是毫秒 connectionFactory.setChannelCheckoutTimeout(2000); connectionFactory.setPublisherConfirms(true); connectionFactory.setPublisherReturns(true); connectionFactory.setCacheMode(CachingConnectionFactory.CacheMode.CHANNEL); return connectionFactory;&#125;]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-Unsafe(7)]]></title>
    <url>%2F2018%2F01%2F22%2FJUC-Unsafe%2F</url>
    <content type="text"><![CDATA[什么是Unsafe如果你使用jdk8进行多线程的编程，在很多框架或者lock中随处可以看到compareAndSet方法和weakCompareAndSet这种方法，它实际上是加在CPU级别上的锁，所以相比于synchronized和volatile,CAS更加轻量，开始扮演着越来越重要的作用。找到它们的调用类就可以定位到Unsafe.class，这个类中绝大部分方法都是native方法，也就是使用c++编写的一些方法，jvm帮我们屏蔽掉了具体的细节。那么Unsafe的作用是什么呢?一句话可以概括。 Java is a safe programming language and prevents programmer from doing a lot of stupid mistakes,most of which based on memory management.But, there is a way to do such mistakes intentionaly,using Unsafe.class. 意思就是java是一个安全的编程语言，让程序员不会犯一些内存管理上的错误。但如果你执意要操作内存，那么使用Unsafe.class。但是作者并不推荐我们直接使用Unsafe，这就是Unsafe的由来，而不是说这个类的方法是非安全的。 如果获取Unsafe通过这个方法我们可以得到一些信息，get unsafe实例的方法会判断当前调用它的类加载器是谁，如果不是系统级的类加载器就会抛出安全异常，我们都知道parent delegete model。所以正常的调用方法是取不到Unsafe实例的，那么利用反射就可以啦，反射就是外挂。 123456789@CallerSensitivepublic static Unsafe getUnsafe() &#123; Class var0 = Reflection.getCallerClass(); if (!VM.isSystemDomainLoader(var0.getClassLoader())) &#123; throw new SecurityException(&quot;Unsafe&quot;); &#125; else &#123; return theUnsafe; &#125;&#125; 通过反射获取Unsafe 1234Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);field.setAccessible(true);Unsafe unsafe = (Unsafe) field.get(null);System.out.println(unsafe); show me the code1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class UnsafeTest &#123; public static void main(String[] args) throws InterruptedException &#123; ExecutorService executorService = Executors.newFixedThreadPool(1000); Counter counter=new SimpleCounter(); long start= System.currentTimeMillis(); for (int i = 0; i &lt; 1000; i++) &#123; executorService.submit(new CounterRunnable(counter,10000)); &#125; executorService.shutdown(); executorService.awaitTermination(1, TimeUnit.HOURS); long end = System.currentTimeMillis()-start; System.out.println(&quot;result=&quot;+counter.getCount()+&quot;---耗时=&quot;+end); &#125; public static Unsafe getUnsafe()&#123; Field field = null; try &#123; field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); field.setAccessible(true); Unsafe unsafe = (Unsafe) field.get(null); return unsafe; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; interface Counter&#123; void increment(); long getCount(); &#125; static class CounterRunnable implements Runnable&#123; private final Counter counter; private final int num; public CounterRunnable(Counter counter, int num) &#123; this.counter = counter; this.num = num; &#125; @Override public void run() &#123; for(int i=0;i&lt;num;i++)&#123; counter.increment(); &#125; &#125; &#125; static class SimpleCounter implements Counter&#123; private long i=0; @Override public void increment() &#123; i++; &#125; @Override public long getCount() &#123; return i; &#125; &#125;&#125; 这个测试方法的主要意图是开启1000个线程，每个线程对一个long变量自增10000次。 result=9745967—耗时=128 这是不加锁的情况下，可以看出答案时错的 没有意义 在increament方法上加synchronized关键字result=10000000—耗时=461 答案正确，速度也可以接受，可见jdk对synchronized不断的优化还是有效果的 加锁 result=10000000—耗时=343 答案也是对的效率也高于synchronized.因为自旋锁的内部也是CAS实现的，所以也算是使用了CAS方式 1234567Lock lock = new ReentrantLock();@Overridepublic void increment() &#123; lock.lock(); i++; lock.unlock();&#125; 使用AtomicLong result=0—耗时=293性能介于lock和synchronized之间。 直接使用CAS方式:result=10000000—耗时=1129 性能真实出乎意料的差呀，调试了半天也没觉得代码有问题，可能和系统情况有关系。所以以后还是老老实实使用lock吧 123456789101112131415161718192021static class SimpleCounter implements Counter&#123; private volatile long i=0; private Unsafe unsafe; private long offset; SimpleCounter() throws NoSuchFieldException &#123; unsafe = getUnsafe(); offset = unsafe.objectFieldOffset(SimpleCounter.class.getDeclaredField(&quot;i&quot;)); &#125; @Override public void increment() &#123; long current = i; while (!unsafe.compareAndSwapLong(this,offset,current,current+1))&#123; current = i; &#125; &#125; @Override public long getCount() &#123; return i; &#125; &#125; ###利用Unsafe.class进行Unsafe操作 青铜级来看这样一个Demo 123456789101112131415161718public class UnsafeFoo &#123; static class Simple&#123; private long l = 0; public Simple()&#123; this.l=1; System.out.println(&quot;init&quot;); &#125; public long getL() &#123; return l; &#125; &#125; public static void main(String[] args) throws InstantiationException &#123; Simple s = new Simple(); System.out.println(s.getL()); &#125;&#125; 代码很简单，最后控制台上会输出init 1.表示类通过构造函数进行了初始化。但是依靠unsafe的allocateInstance方法，我们可以直接给一个实例分配内存，并且可以绕过它的构造函数,不仅如此，还可以得到类的信息以及类加载器的信息。下面这段代码的输出结果l=0;没有init字符打印在控制台上。 1234567891011121314151617181920212223242526272829303132333435public class UnsafeFoo &#123; static class Simple&#123; private long l = 0; public Simple()&#123; this.l=1; System.out.println(&quot;init&quot;); &#125; public long getL() &#123; return l; &#125; &#125; public static void main(String[] args) throws InstantiationException &#123; Unsafe unsafe = getUnsafe(); Simple simple = (Simple) unsafe.allocateInstance(Simple.class); System.out.println(simple.getL()); System.out.println(simple.getClass()); System.out.println(simple.getClass().getClassLoader()); &#125; public static Unsafe getUnsafe()&#123; Field field = null; try &#123; field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); field.setAccessible(true); Unsafe unsafe = (Unsafe) field.get(null); return unsafe; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 黄金级在之前的代码中加入一个work方法 12345678910111213141516static class Simple&#123; private long l = 0; public Simple()&#123; this.l=1; System.out.println(&quot;init&quot;); &#125; public long getL() &#123; return l; &#125; public void work()&#123; if(l==2)&#123; System.out.println(&quot;i am working&quot;); &#125; &#125; 在主方法中调用,可以确定不会打印出 i am working 这句话。 12345public static void main(String[] args) throws InstantiationException, NoSuchFieldException &#123; Unsafe unsafe = getUnsafe(); Simple simple = new Simple(); simple.work();&#125; 那么如何利用unsafe方法强制修改内存中这个字段的值呢 123Field field = simple.getClass().getDeclaredField(&quot;l&quot;);unsafe.putInt(simple,unsafe.objectFieldOffset(field),2);simple.work(); 这样就可以看到i am working 打印在控制台上了，果然，如果别有用心的人使用了unsafe方法，会对程序的逻辑造成损坏。 白金级unsafe当然不止于操作类和方法，它还可以操作字节码文件，通过字节码文件调用函数。假设有一个简单的类A，把它编译成class文件。 123456789class A&#123; private int i=0; public A()&#123; this.i=1; &#125; public int get()&#123; return i; &#125;&#125; 在自己类中添加一个读取字节码文件的方法。 12345678public static byte[] readContent() throws IOException &#123; File file = new File(&quot;/User/sc/Desktop/A.class&quot;); FileInputStream fileInputStream = new FileInputStream(file); byte[] bytes = new byte[(int) file.length()]; fileInputStream.read(bytes); fileInputStream.close(); return bytes;&#125; 主方法中读取 1234byte[] bytes = readContent();Class aClass = unsafe.defineClass(null, bytes, 0, bytes.length,UnsafeFoo.class.getClass().getClassLoader(),null);int i = (int) aClass.getMethod(&quot;get&quot;).invoke(aClass.newInstance(), null);System.out.println(i); 通过这样的方式，可以看到打印出1.也就是说unsafe解析class文件是经过了构造函数的。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot-Security认证流程]]></title>
    <url>%2F2018%2F01%2F16%2FSpringBoot-Security%E8%AE%A4%E8%AF%81%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[基本结构spring security的核心结构如图所示，实际上就是一套过滤器组成，每个过滤器都实现一种功能，用户也可以自定义过滤器加入到过滤器链中。 认证处理流程 整个登录的流程大概可以分为这几个部分，当我们在页面上输入用户名密码点击登录后，Debug一下看看具体的流程是怎样的: UsernamePasswordAuthenticationFilter.class 这个类中关键的方法如下，其它都是一些简单的get、set方法。在这个方法中，首先获取到了请求的用户名和密码。 使用获取到的用户名密码构建了一个UsernamePasswordAuthenticationToken对象，这个对象其实是Authentication接口的一个实现，而Authentication实际上是封装的用户信息 setDetails方法设置了一些本机的登录信息 最后返回了getAuthenticationManager对象，也就到了上图的第二步。这个对象本身并不包含验证的逻辑，他的作用是管理第三步中的AuthenticationProvider，它是真正实现校验逻辑的一个类 1234567891011121314151617181920public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; if (this.postOnly &amp;&amp; !request.getMethod().equals(&quot;POST&quot;)) &#123; throw new AuthenticationServiceException(&quot;Authentication method not supported: &quot; + request.getMethod()); &#125; else &#123; String username = this.obtainUsername(request); String password = this.obtainPassword(request); if (username == null) &#123; username = &quot;&quot;; &#125; if (password == null) &#123; password = &quot;&quot;; &#125; username = username.trim(); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password); this.setDetails(request, authRequest); return this.getAuthenticationManager().authenticate(authRequest); &#125; &#125; ProviderManager.class 这里就是流程图的第三步，也就是一个Authentication Provider的实现类，这里继续看这个关键方法 代码中首先对provider进行了遍历，因为不同的场景可能需要不同的认证方式，例如常见的用户名密码认证，手机验证码认证，图片认证，第三方登录等等manager收到请求时会依次询问provider能不能处理这种认证，也就是provider.supports方法，manager会挑出一个provider对请求进行处理 如果支持校验，就执行校验逻辑provider.authenticate，如果不支持就跳出本次循环 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Class&lt;? extends Authentication&gt; toTest = authentication.getClass(); AuthenticationException lastException = null; Authentication result = null; boolean debug = logger.isDebugEnabled(); Iterator var6 = this.getProviders().iterator(); while(var6.hasNext()) &#123; AuthenticationProvider provider = (AuthenticationProvider)var6.next(); if (provider.supports(toTest)) &#123; if (debug) &#123; logger.debug(&quot;Authentication attempt using &quot; + provider.getClass().getName()); &#125; try &#123; result = provider.authenticate(authentication); if (result != null) &#123; this.copyDetails(authentication, result); break; &#125; &#125; catch (AccountStatusException var11) &#123; this.prepareException(var11, authentication); throw var11; &#125; catch (InternalAuthenticationServiceException var12) &#123; this.prepareException(var12, authentication); throw var12; &#125; catch (AuthenticationException var13) &#123; lastException = var13; &#125; &#125; &#125; if (result == null &amp;&amp; this.parent != null) &#123; try &#123; result = this.parent.authenticate(authentication); &#125; catch (ProviderNotFoundException var9) &#123; ; &#125; catch (AuthenticationException var10) &#123; lastException = var10; &#125; &#125; if (result != null) &#123; if (this.eraseCredentialsAfterAuthentication &amp;&amp; result instanceof CredentialsContainer) &#123; ((CredentialsContainer)result).eraseCredentials(); &#125; this.eventPublisher.publishAuthenticationSuccess(result); return result; &#125; else &#123; if (lastException == null) &#123; lastException = new ProviderNotFoundException(this.messages.getMessage(&quot;ProviderManager.providerNotFound&quot;, new Object[]&#123;toTest.getName()&#125;, &quot;No AuthenticationProvider found for &#123;0&#125;&quot;)); &#125; this.prepareException((AuthenticationException)lastException, authentication); throw lastException; &#125; &#125; AbstractUserDetailsAuthenticationProvider.class 方法的主要内容就是先从缓存中尝试获取user信息，并构建一个UserDetails实例，如果缓存中没有，就调用this.retrieveUser方法，也是这个方法的核心。在这里我们就可以用自己的方法控制权限的验证。可以自己新建一个类实现UserDetailsService接口，实现其中的验证逻辑。 经过验证逻辑之后会调用this.preAuthenticationChecks.check方法，也就是检查用户是否锁定，可用，过期，如果有则抛出异常 预检查之后执行this.additionalAuthenticationChecks方法，一个附加的检查，作用是检查密码是否匹配 this.postAuthenticationChecks.check后检查方法，再次检验上面的验证是否通过 所有的检查都通过之后，就认为用户的认真是成功的，这时拿用户的认证信息创建一个createSuccessAuthentication。创建一个新的Authentication对象并将信息补充完全再返回，也就是一个通过认证的Authentication。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Assert.isInstanceOf(UsernamePasswordAuthenticationToken.class, authentication, this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.onlySupports&quot;, &quot;Only UsernamePasswordAuthenticationToken is supported&quot;)); String username = authentication.getPrincipal() == null ? &quot;NONE_PROVIDED&quot; : authentication.getName(); boolean cacheWasUsed = true; UserDetails user = this.userCache.getUserFromCache(username); if (user == null) &#123; cacheWasUsed = false; try &#123; user = this.retrieveUser(username, (UsernamePasswordAuthenticationToken)authentication); &#125; catch (UsernameNotFoundException var6) &#123; this.logger.debug(&quot;User &apos;&quot; + username + &quot;&apos; not found&quot;); if (this.hideUserNotFoundExceptions) &#123; throw new BadCredentialsException(this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.badCredentials&quot;, &quot;Bad credentials&quot;)); &#125; throw var6; &#125; Assert.notNull(user, &quot;retrieveUser returned null - a violation of the interface contract&quot;); &#125; try &#123; this.preAuthenticationChecks.check(user); this.additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken)authentication); &#125; catch (AuthenticationException var7) &#123; if (!cacheWasUsed) &#123; throw var7; &#125; cacheWasUsed = false; user = this.retrieveUser(username, (UsernamePasswordAuthenticationToken)authentication); this.preAuthenticationChecks.check(user); this.additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken)authentication); &#125; this.postAuthenticationChecks.check(user); if (!cacheWasUsed) &#123; this.userCache.putUserInCache(user); &#125; Object principalToReturn = user; if (this.forcePrincipalAsString) &#123; principalToReturn = user.getUsername(); &#125; return this.createSuccessAuthentication(principalToReturn, authentication, user); &#125; 认证结果如何在多个请求中间共享数据的共享当然是放到了session中，那么它是什么时间将什么东西放进了session中呢 AbstractAuthenticationProcessingFilter.class 在成功进行了登录流程之后会执行successfulAuthentication方法，在这个方法中可以很明显的看到SecurityContextHolder.getContext().setAuthentication(authResult)，就是把认证成功的信息放入到一个contextHolder中。SecurityContextHolder很简单，封装了Authentication对象，并重写了equals和hashcode方法保证唯一性 12345678910111213protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authResult) throws IOException, ServletException &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Authentication success. Updating SecurityContextHolder to contain: &quot; + authResult); &#125; SecurityContextHolder.getContext().setAuthentication(authResult); this.rememberMeServices.loginSuccess(request, response, authResult); if (this.eventPublisher != null) &#123; this.eventPublisher.publishEvent(new InteractiveAuthenticationSuccessEvent(authResult, this.getClass())); &#125; this.successHandler.onAuthenticationSuccess(request, response, authResult); &#125; SecurityContextHolder.class 这个类写的不太好理解，通过init方法才发现它其实是封装了一个ThreadLocal，一个请求和响应大部分都是一个线程来做，所以当请求来的时候SecurityContext PersistenceFilter会尝试取出session，当认证完成，返回响应的时候会将认证信息写入session。 1234567891011121314151617181920212223private static void initialize() &#123; if (!StringUtils.hasText(strategyName)) &#123; strategyName = &quot;MODE_THREADLOCAL&quot;; &#125; if (strategyName.equals(&quot;MODE_THREADLOCAL&quot;)) &#123; strategy = new ThreadLocalSecurityContextHolderStrategy(); &#125; else if (strategyName.equals(&quot;MODE_INHERITABLETHREADLOCAL&quot;)) &#123; strategy = new InheritableThreadLocalSecurityContextHolderStrategy(); &#125; else if (strategyName.equals(&quot;MODE_GLOBAL&quot;)) &#123; strategy = new GlobalSecurityContextHolderStrategy(); &#125; else &#123; try &#123; Class&lt;?&gt; clazz = Class.forName(strategyName); Constructor&lt;?&gt; customStrategy = clazz.getConstructor(); strategy = (SecurityContextHolderStrategy)customStrategy.newInstance(); &#125; catch (Exception var2) &#123; ReflectionUtils.handleReflectionException(var2); &#125; &#125; ++initializeCount;&#125; 获取认证过的用户信息 方法一这种方式会返回认证的全部信息，如果只需要和用户相关的信息，可以使用方法三 1234@GetMapping(&quot;/me&quot;)public Object getCurrentUser()&#123; return SecurityContextHolder.getContext().getAuthentication();&#125; 方法二这种方式会返回认证的全部信息，如果只需要和用户相关的信息，可以使用方法三 1234@GetMapping(&quot;/me&quot;)public Object getCurrentUser(Authentication authentication)&#123; return authentication;&#125; 方法三返回用户相关信息 1234@GetMapping(&quot;/me&quot;)public Object getCurrentUser(@AuthenticationPrincipal UserDetails userDetails)&#123; return userDetails;&#125;]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot-异步REST服务]]></title>
    <url>%2F2018%2F01%2F15%2FSpringBoot-%E5%BC%82%E6%AD%A5REST%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[在spring中调用请求时，经常会遇到某些业务需要长时间的计算，如果单线程来做费时费力，很快就会耗尽tomcat的连接数。所以一种思路是当http请求进来，可以另起一个线程处理业务，释放连接，当业务处理完成再将它返回，这样在处理业务的时间中，tomcat可以处理多个低时延的任务。 Callable第一种方法就是使用Callable，模型如图: 123456789101112@GetMapping(&quot;/order&quot;)public DeferredResult&lt;String&gt; order()&#123; log.info(&quot;开始&quot;); Callable&lt;String&gt; result = ()-&gt;&#123; log.info(&quot;副线程开始&quot;); Thread.sleep(10000 ); log.info(&quot;副线程结束&quot;); return &quot;success&quot;; &#125;; log.info(&quot;结束&quot;); return result;&#125; DeferredResult模型如图: 其核心也是模拟了一个消息队列,应用2监听到消息队列的值发生变化，取出数据进行处理并将处理后的结果放回队列，应用1监听到事件完成，将信息取出返回 Controller层 1234567891011121314151617@RestController@Slf4jpublic class AsyncController &#123; @Autowired private MockQueue mockQueue; @Autowired private DeferredResultHolder deferredResultHolder; String orderNum = RandomStringUtils.randomNumeric(8); mockQueue.setPlaceOrder(orderNum); DeferredResult deferredResult =new DeferredResult(); deferredResultHolder.getMap().put(orderNum,deferredResult); log.info(&quot;结束&quot;); return deferredResult; &#125;&#125; 模拟队列 1234567891011121314151617181920212223242526272829303132@Component@Slf4jpublic class MockQueue &#123; private String placeOrder; private String completeOrder; public String getCompleteOrder() &#123; return completeOrder; &#125; public String getPlaceOrder() &#123; return placeOrder; &#125; public void setCompleteOrder(String completeOrder) &#123; this.completeOrder = completeOrder; &#125; public void setPlaceOrder(String placeOrder) &#123; new Thread(()-&gt;&#123; log.info(&quot;接到下单请求&quot;+placeOrder); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; this.completeOrder = placeOrder; log.info(&quot;处理完成&quot;+placeOrder); &#125;).start(); &#125;&#125; 123456789101112@Componentpublic class DeferredResultHolder &#123; private Map&lt;String,DeferredResult&gt; map = new HashMap&lt;&gt;(); public Map&lt;String, DeferredResult&gt; getMap() &#123; return map; &#125; public void setMap(Map&lt;String, DeferredResult&gt; map) &#123; this.map = map; &#125;&#125; 监听队列 1234567891011121314151617181920212223242526272829@Component@Slf4jpublic class QueueListener implements ApplicationListener&lt;ContextRefreshedEvent&gt;&#123; @Autowired private MockQueue mockQueue; @Autowired private DeferredResultHolder resultHolder; @Override public void onApplicationEvent(ContextRefreshedEvent contextRefreshedEvent) &#123; new Thread(()-&gt;&#123; while (true)&#123; if(StringUtils.isNotBlank(mockQueue.getCompleteOrder()))&#123; String orderNo = mockQueue.getCompleteOrder(); log.info(&quot;返回订单处理结果&quot;+orderNo); resultHolder.getMap().get(orderNo).setResult(&quot;order success&quot;); mockQueue.setCompleteOrder(null); &#125;else &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125;&#125; 消息队列同样是订单处理的场景，可以使用的消息队列有很多种，比如rabbitmq或者阿里的rocketmq。rabbitmq的应用非常广泛，rocketmq是阿里开源的专门用来处理电商场景的消息队列。学会了把这两种场景再补上。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web容器对比]]></title>
    <url>%2F2018%2F01%2F08%2Fweb%E5%AE%B9%E5%99%A8%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[公司里统一使用的是jetty，自己平时写项目都习惯性用tomcat。大概比较一下两个容器。 Tomcat结构 接受请求 BIO: blocking IO NIO: non blocking IO APR: 操作系统级别解决异步IO，如果应用需要处理高并发的请求，可以配置为apr模式 优化 tomcat默认使用BIO的connector协议,并发达到几百会有瓶颈。可以通过修改protocol设置为org.apache.coyote.http11.Http11NioProtocol启动NIO。 useURIValidation=false关闭URL检查 enableLookUps=false消除DNS查询影响 compression=on采取资源压缩 因为tomcat运行在jvm上，所以可以通过优化jvm提高性能。tomcat默认内存128MB。可以修改Catalina.sh JAVA_OPTS参数，指定-Xms -Xmx，设置初始化大小和最大内存，减少频繁伸缩带来的消耗 Jetty结构 可以看出jetty结构相比于tomcat要简单了很多，它只有一个数据模型，那就是handler。可以根据规则添加hanlder作为jetty的启动组件。与tomcat相同，每个组件都有一个观察者(LifyCycle接口)，当start、fail、stop事件被触发，listener将会被调用。 接受请求 HTTP协议 BIO NIO AJP协议:假设在jboss服务器前加入了nginx服务器，那么nginx会解析http请求，jboss只需要处理nginx处理过的数据包，也就是ajp工作。所以处理ajp请求要快于http请求 tomcat与jetty比较jetty在架构上，核心就是handler。Handler的设计实际上是一个责任链的模式，对于组件生命周期的监控使用了观察者模式。tomcat的结构从server-&gt;service—&gt;container-&gt;engine-&gt;host-&gt;context-&gt;wrapper，是一种分层的设计，非常复杂但是也更加稳重。 对于J2ee规范，tomcat支持的更广泛，jetty更加轻量响应更快。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot-Data-Jpa之高级话题(3)]]></title>
    <url>%2F2018%2F01%2F01%2FSpringBoot-Data-Jpa%E4%B9%8B%E9%AB%98%E7%BA%A7%E8%AF%9D%E9%A2%98%2F</url>
    <content type="text"><![CDATA[JPA的一些坑如果我们的Repository继承自JpaRepository，那么我们如果执行插入或保存代码的时候会出现异常,比如下面一个方法是会执行失败的: 12345678@Testpublic void test8()&#123; Book book = new Book(); book.setName(&quot;heng&quot;); book.setUpdateDate(new Date()); book.setCreateDate(new Date()); bookRepository.save(book);&#125; Connection is read-only. Queries leading to data modification are not allowed 错误提示是ReadOnly，也就是说我们不能修改数据，那么如何解决这个问题呢，很简单。只需要在测试类或者方法上加@Transactional注解就可以。那么这个问题ReadOnly是从哪里来的呢，我们继承的JpaRepository只是一个接口，那么找问题就要去找它的实现类，可以找到SimpleJpaRepository。在类注解上我们就找到了问题所在 123@Transactional( readOnly = true) 这里事务标注为只读，所以我们执行修改操作的时候要加事务注解对它进行覆盖。如果你对Repository层写的测试代码，那么你会发现，虽然Junit测试显示成功，sql也打印在了控制台，但是数据库并没有插入或修改这条数据。因为springboot对repository层默认进行了回滚，如果你使用Service层包装了Repository层，对Service写Junit测试，就不会出现事务回滚的情况，要解决这种回滚的情况，需要再添加一个注解: 12345678910@Test@Transactional@Rollback(false)public void test8()&#123; Book book = new Book(); book.setName(&quot;heng&quot;); book.setUpdateDate(new Date()); book.setCreateDate(new Date()); bookRepository.save(book);&#125; 现在测试代码就不会有什么问题了，如果你只想观察测试用例的sql语句，那么就不需要加RollBack这个注解了。 自定义Repository如果我们想对Repository的方法做一些定制，Jpa当然也是支持的。这里简单演示一下在save方法前打印一句话。 第一步就是集成SimpleJpaRepository这个类，这个类是JpaRepository的实现类。实现一个构造方法，这里我们重写一个save方法，save之前打印这个保存实体的名称。 1234567891011public class MyRepository&lt;T&gt; extends SimpleJpaRepository&lt;T,Long&gt;&#123; public MyRepository(JpaEntityInformation&lt;T, ?&gt; entityInformation, EntityManager entityManager) &#123; super(entityInformation, entityManager); &#125; @Override public &lt;S extends T&gt; S save(S entity) &#123; System.out.println(&quot;保存了:&quot;+entity.getClass().getSimpleName()); return super.save(entity); &#125;&#125; 第二步:在启动类上指定要使用的Jpa实现类 1234567@SpringBootApplication@EnableJpaRepositories(repositoryBaseClass = MyRepository.class)public class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 这时当我们再调用测试方法: 123456789@Test@Transactionalpublic void test8()&#123; Book book = new Book(); book.setName(&quot;heng&quot;); book.setUpdateDate(new Date()); book.setCreateDate(new Date()); bookRepository.save(book);&#125; 就可以看到输出结果: 12345678保存了:BookHibernate: insert into sc_book (sc_create_date, sc_update_date, sc_category_sc_id, sc_name) values (?, ?, ?, ?) 持久化上下文先来看这么一个场景 1234567@Test@Transactionalpublic void test9()&#123; Book one = bookRepository.findOne(2L); one.setName(&quot;python&quot;); bookRepository.save(one);&#125; 输出结果 123456789101112131415161718192021222324252627Hibernate: select book0_.sc_id as sc_id1_2_0_, book0_.sc_create_date as sc_creat2_2_0_, book0_.sc_update_date as sc_updat3_2_0_, book0_.sc_category_sc_id as sc_categ5_2_0_, book0_.sc_name as sc_name4_2_0_, category1_.sc_id as sc_id1_4_1_, category1_.sc_create_date as sc_creat2_4_1_, category1_.sc_update_date as sc_updat3_4_1_, category1_.sc_address as sc_addre4_4_1_, category1_.sc_area as sc_area5_4_1_, category1_.sc_city as sc_city6_4_1_, category1_.sc_province as sc_provi7_4_1_, category1_.sc_zip_code as sc_zip_c8_4_1_, category1_.sc_age as sc_age9_4_1_, category1_.sc_birth_day as sc_birt10_4_1_, category1_.sc_gender as sc_gend11_4_1_, category1_.sc_name as sc_name12_4_1_ from sc_book book0_ left outer join sc_category category1_ on book0_.sc_category_sc_id=category1_.sc_id where book0_.sc_id=?保存了:Book 结果很奇怪，只有select的sql语句执行了，然后显示save方法也执行了，但是没有执行update的sql语句。这就是持久化上下文在起作用。先给出持久化上下文的特点再进行验证。 持久化上下文的生命周期与事务一致 持久化上下文提供自动脏检查 持久化下上文是一级缓存 解释一下持久化上下文对于编程人员来说其实是不可见的，我们可以把它想象成一个map。对于第一条，当事务开始的时候会创建一个map，在事务中的所有操作都会写入这个map中，事务结束map就会销毁。自动脏检查是说如果持久化上下文发现了自己map中的数据有修改，就会修改这些数据，在事务完成后提交，如果没有修改，就不会提交。对于缓存机制，我们可以通过代码来进行验证。 其实前两点就可以解释刚才代码中出现的现象，由于我们的Transactional注解会回滚掉，所以持久化上下文就不会执行update语句。如果想让它执行update那么我们只需要让jpa提交这个事务，而不是回滚这个事务就可以了。最简单的做法就是在方法上添加@Rollback(false)这个注解就可以了。当然要修改一下你要保存的数据，不要和查出来的数据一样，否则脏检查发现没有修改，也就不会执行update操作了。接着我们验证缓存机制。 1234567891011121314151617181920212223242526272829303132333435 @Test @Transactional @Rollback(false) public void test9()&#123; Book one = bookRepository.findOne(2L); Book one1 = bookRepository.findOne(2L); &#125;输出sql: select book0_.sc_id as sc_id1_2_0_, book0_.sc_create_date as sc_creat2_2_0_, book0_.sc_update_date as sc_updat3_2_0_, book0_.sc_category_sc_id as sc_categ5_2_0_, book0_.sc_name as sc_name4_2_0_, category1_.sc_id as sc_id1_4_1_, category1_.sc_create_date as sc_creat2_4_1_, category1_.sc_update_date as sc_updat3_4_1_, category1_.sc_address as sc_addre4_4_1_, category1_.sc_area as sc_area5_4_1_, category1_.sc_city as sc_city6_4_1_, category1_.sc_province as sc_provi7_4_1_, category1_.sc_zip_code as sc_zip_c8_4_1_, category1_.sc_age as sc_age9_4_1_, category1_.sc_birth_day as sc_birt10_4_1_, category1_.sc_gender as sc_gend11_4_1_, category1_.sc_name as sc_name12_4_1_ from sc_book book0_ left outer join sc_category category1_ on book0_.sc_category_sc_id=category1_.sc_id where book0_.sc_id=? 可以看到我们执行了两次查询，同一个数据的操作，结果只执行了一次查询sql。 123456789101112131415161718192021222324252627 @Test @Transactional @Rollback(false) public void test9()&#123; bookRepository.findAll(); bookRepository.findAll(); &#125;输出sql:Hibernate: select book0_.sc_id as sc_id1_2_, book0_.sc_create_date as sc_creat2_2_, book0_.sc_update_date as sc_updat3_2_, book0_.sc_category_sc_id as sc_categ5_2_, book0_.sc_name as sc_name4_2_ from sc_book book0_Hibernate: select book0_.sc_id as sc_id1_2_, book0_.sc_create_date as sc_creat2_2_, book0_.sc_update_date as sc_updat3_2_, book0_.sc_category_sc_id as sc_categ5_2_, book0_.sc_name as sc_name4_2_ from sc_book book0_ 对于findall查询，执行了两次sql 可以得到的结论是，持久化上下文对于条件查询语句会做缓存，相同的查询会走缓存，而不是去连接数据库。对于findAll这种无限制条件的查询则不会缓存。 我们在说JpaRepository的时候发现它有flush和saveAndFlush这两个方法，其实这两个方法的作用就是立刻将持久化上下文与数据库进行同步，而不等待事务的提交。验证方法如下: 123456789@Test@Transactionalpublic void test9()&#123; Book one = bookRepository.findOne(2L); one.setName(&quot;python123&quot;); bookRepository.saveAndFlush(one); Book one1 = bookRepository.findOne(2L); System.out.println(one1.getName());&#125; 通过saveAndflush方法，数据库的数据立即就发生了改变，由于上下文中记录了数据的改变，所以第二次查询不需要经过数据库，直接可以从上下文中获取。因此第二次查询没有打印出sql语句，结果输出python123 1234567891011121314151617181920212223242526272829303132333435363738Hibernate: select book0_.sc_id as sc_id1_2_0_, book0_.sc_create_date as sc_creat2_2_0_, book0_.sc_update_date as sc_updat3_2_0_, book0_.sc_category_sc_id as sc_categ5_2_0_, book0_.sc_name as sc_name4_2_0_, category1_.sc_id as sc_id1_4_1_, category1_.sc_create_date as sc_creat2_4_1_, category1_.sc_update_date as sc_updat3_4_1_, category1_.sc_address as sc_addre4_4_1_, category1_.sc_area as sc_area5_4_1_, category1_.sc_city as sc_city6_4_1_, category1_.sc_province as sc_provi7_4_1_, category1_.sc_zip_code as sc_zip_c8_4_1_, category1_.sc_age as sc_age9_4_1_, category1_.sc_birth_day as sc_birt10_4_1_, category1_.sc_gender as sc_gend11_4_1_, category1_.sc_name as sc_name12_4_1_ from sc_book book0_ left outer join sc_category category1_ on book0_.sc_category_sc_id=category1_.sc_id where book0_.sc_id=?保存了:BookHibernate: update sc_book set sc_create_date=?, sc_update_date=?, sc_category_sc_id=?, sc_name=? where sc_id=?python123 抓取策略在上面的select语句中我们可以发现一个问题，jpa会默认为我们抓取所有相关的表的数据，比如这里外联了category这张表，可以想象一下如果我们这张表关联了多张表的情况下再去默认外联很可能影响我们的查询效率，而大多数情况下我们可能不需要外联，那么这里就涉及到抓取策略。 抓取策略的配置在Book类上，@ManyToOne注解上进行配置，默认为EAGER类型，也就是不管需要不需要，我都查出来。 12345678910111213@Entity@Datapublic class Book extends CommonProperty &#123; private String name; @ManyToOne(fetch = FetchType.LAZY) private Category category; @OneToMany(mappedBy = &quot;book&quot;) private List&lt;BookAuthor&gt; authors;&#125; 改为lazy模式后查看sql: 12345678910select book0_.sc_id as sc_id1_2_0_, book0_.sc_create_date as sc_creat2_2_0_, book0_.sc_update_date as sc_updat3_2_0_, book0_.sc_category_sc_id as sc_categ5_2_0_, book0_.sc_name as sc_name4_2_0_from sc_book book0_where book0_.sc_id=? 可以看到当我们不需要类别信息的时候不会去外联这张category表。 当我们调用jpa默认提供的方法时会是这样一种效果，那么我们自定义的接口方法时什么样的呢： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Componentpublic interface BookRepository extends JpaRepository&lt;Book,Long&gt; &#123; Book findByName(String name);&#125; @Test public void test10()&#123; Book python123 = bookRepository.findByName(&quot;python1&quot;); System.out.println(python123.getCategory().getName()); &#125;输出结果:Hibernate: select book0_.sc_id as sc_id1_2_, book0_.sc_create_date as sc_creat2_2_, book0_.sc_update_date as sc_updat3_2_, book0_.sc_category_sc_id as sc_categ5_2_, book0_.sc_name as sc_name4_2_ from sc_book book0_ where book0_.sc_name=?Hibernate: select category0_.sc_id as sc_id1_4_0_, category0_.sc_create_date as sc_creat2_4_0_, category0_.sc_update_date as sc_updat3_4_0_, category0_.sc_address as sc_addre4_4_0_, category0_.sc_area as sc_area5_4_0_, category0_.sc_city as sc_city6_4_0_, category0_.sc_province as sc_provi7_4_0_, category0_.sc_zip_code as sc_zip_c8_4_0_, category0_.sc_age as sc_age9_4_0_, category0_.sc_birth_day as sc_birt10_4_0_, category0_.sc_gender as sc_gend11_4_0_, category0_.sc_name as sc_name12_4_0_ from sc_category category0_ where category0_.sc_id=?技术 可以看到在默认的Eager模式下，jpa对于我们自定义的方法并没有做外联操作，而是执行了两次select操作。如果选择Lazy模式则会直接抛出异常no session。所以说在这里控制抓取策略是没有用的。这才是查询一条category的情况，实际环境中我们可能查询100条，就会有101句select语句，那么对性能就是一种极大的影响。那么就要想办法解决这种情况。 方法一:12@Query(&quot;from Book b left join b.category where b.name = ?1&quot;)Book findByName(String name); 在自定义的方法上，明确指定查询要外联category表 方法二:12@EntityGraph(attributePaths = &#123;&quot;category&quot;&#125; )Book findByName(String name); 在这个注解中，我们可以传入一个String 数组，也就是说，如果这个Book表关联了多个表，那么这里就可以填入想要外联的表在Book类中的属性名称,就会在查询的时候执行外联操作，而不是多个select,如图 1234567891011121314151617181920212223242526Hibernate: select book0_.sc_id as sc_id1_2_0_, category1_.sc_id as sc_id1_4_1_, book0_.sc_create_date as sc_creat2_2_0_, book0_.sc_update_date as sc_updat3_2_0_, book0_.sc_category_sc_id as sc_categ5_2_0_, book0_.sc_name as sc_name4_2_0_, category1_.sc_create_date as sc_creat2_4_1_, category1_.sc_update_date as sc_updat3_4_1_, category1_.sc_address as sc_addre4_4_1_, category1_.sc_area as sc_area5_4_1_, category1_.sc_city as sc_city6_4_1_, category1_.sc_province as sc_provi7_4_1_, category1_.sc_zip_code as sc_zip_c8_4_1_, category1_.sc_age as sc_age9_4_1_, category1_.sc_birth_day as sc_birt10_4_1_, category1_.sc_gender as sc_gend11_4_1_, category1_.sc_name as sc_name12_4_1_ from sc_book book0_ left outer join sc_category category1_ on book0_.sc_category_sc_id=category1_.sc_id where book0_.sc_name=? 这个注解似乎已经完美解决了我们的问题，但是在真实场景中，我们可能要写10个查询方法根据不同的条件，那么我们每个方法都要加上这个注解，其实是很麻烦的事情，那么有没有方法，让我们只需要修改一处就行了呢，当然可以。 方法三:12345678910111213141516171819202122@Entity@Data@NamedEntityGraph(name = &quot;Book.fetch.category_author&quot;,attributeNodes = &#123; @NamedAttributeNode(&quot;category&quot;), @NamedAttributeNode(&quot;authors&quot;)&#125;)public class Book extends CommonProperty &#123; private String name; @ManyToOne private Category category; @OneToMany(mappedBy = &quot;book&quot;) private List&lt;BookAuthor&gt; authors;&#125; @EntityGraph(&quot;Book.fetch.category_author&quot;) Book findByName(String name); 我们只需要在Book实体类中添加一个NamedEntityGraph注解，并指定一个名字，名字可以任意取，并声明要抓取的策略。然后在方法上只需要声明这个Graph的名称即可。如果你有多个要抓取的策略，那么可以使用@NamedEntityGraphs注解，嵌套@NamedEntityGraph就可以了。 继承策略single table在之前的实体类中，我们提取了Id、createTime、updateTime这些公共属性，并让实体表继承了这些属性，那么每个表就会增加响应的列。现在考虑如果我们新增了电子书和实体书两个类，两种书同属于Book，所以我们可以考虑让这两种书继承Book类，并且我们需要存储两种书的数据，那么这时候我们就需要在两种书的实体类上添加@Entity注解，我们观察一下数据库会有什么变化。 1234567891011@Data@Entitypublic class PrintBook extends Book &#123; private String press;&#125;@Entity@Datapublic class EBook extends Book &#123; private String webSite;&#125; 新建两个实体类，并运行项目 可以发现数据库中并没有新增两个表，而是增加了三个字段，两个字段是我们自己定义的，并且默认都是allow null的属性。dtype则是自动生成的,不可为null。也就是说现在我们数据库中的book必须制定是Ebook还是PrintBook，如果数据库之前存了数据，现在执行查询是会报错的。要么对该列进行填充，要么删除所有数据。我们先清空数据库。 123456789101112131415161718192021222324252627282930313233343536 @Test @Transactional public void test11()&#123; EBook eBook = new EBook(); eBook.setWebSite(&quot;123&quot;); eBook.setName(&quot;西游记&quot;); bookRepository.saveAndFlush(eBook); &#125;输出结果:保存了:EBookHibernate: insert into sc_book (sc_create_date, sc_update_date, sc_category_sc_id, sc_name, sc_web_site, dtype) values (?, ?, ?, ?, ?, &apos;EBook&apos;) @Test @Transactional public void test12()&#123; PrintBook printBook = new PrintBook(); printBook.setName(&quot;水浒传&quot;); printBook.setPress(&quot;北京出版社&quot;); bookRepository.saveAndFlush(printBook); &#125;输出结果:保存了:PrintBookHibernate: insert into sc_book (sc_create_date, sc_update_date, sc_category_sc_id, sc_name, sc_press, dtype) values (?, ?, ?, ?, ?, &apos;PrintBook&apos;) 可以看出jpa根据我们声明的类型，会自动添加dtype属性到数据库。那么查询操作也是类似的道理，如果findAll则会查出来两种类型，如果声明了一种返回类型，则会自动添加dtype条件进行查询。 有一点要注意的是，子类中的属性不能设置为not null，因为其他子类在进行插入操作的时候不会插入这个子类的属性，设置为not null就会影响其他子类的插入操作。 ####joined上面通过dtype的表形式只是jpa种默认的一种继承策略，我们可以修改继承策略来建立不同的表结构。需要在父类上添加注解 @Inheritance(strategy = InheritanceType.JOINED) 共有三种继承策略, SINGLE_TABLE为默认策略，那么我们尝试一下其他两种策略，首先要清空数据库。 123SINGLE_TABLE,TABLE_PER_CLASS,JOINED; 使用这种继承策略，会建立两个额外的表，也就是Ebook表和PrintBook表，每次插入数据的时候都会向两个表中执行两个insert语句，select语句会使用join外联，这也符合我们对Joined策略的理解。Ebook和PrintBook的表结构也是类似的，除了自身特有的属性，还有一个外键和Book表相关联。 TABLE_PER_CLASS从字面上很难理解是什么意思，清空数据库后启动项目，发现报错了。错误的内容是说当我们使用这种策略的时候主键不允许使用自增的形式。为什么呢，因为对于前两种方式，主键都是存储在Book表中，也就是说只有一个主键。而使用这种方式建立的表，每个表都有一个主键，它会把数据聚合在一起，如果使用自增的策略，可能导致多个表有相同的主键，所以会报错。那么这时候，我们要使用其他生成策略: 12345678910@Id@GeneratedValue(generator = &quot;sequenceGenerator&quot;)@GenericGenerator(name=&quot;sequenceGenerator&quot;,strategy = &quot;org.hibernate.id.enhanced.SequenceStyleGenerator&quot;,parameters = &#123; @Parameter(name = SequenceStyleGenerator.SEQUENCE_PARAM,value = &quot;ID_SEQUENCE&quot;), @Parameter(name = SequenceStyleGenerator.INITIAL_PARAM,value = &quot;1000&quot;), @Parameter(name = SequenceStyleGenerator.INCREMENT_PARAM,value = &quot;1&quot;), @Parameter(name = SequenceStyleGenerator.OPT_PARAM,value = &quot;pooled&quot;)&#125;)private Long id; 这里我们选择一种Hibernate的序列化生成Id的策略，并进行了一些配置,同时这里也显示出了我们抽取公共属性的好处，只需要修改一处代码。 观察生成的表结构: 同样是生成了三张表，但是Ebook和PrintBook表和JOINED策略生成的表结构有所差别 这张表包含了Book表中的所有属性，而不是通过外键关联主表，执行测试用例: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 @Test @Transactional @Rollback(false) public void test13()&#123; EBook eBook = new EBook(); eBook.setWebSite(&quot;www.baidu.com&quot;); eBook.setName(&quot;python&quot;); bookRepository.save(eBook); PrintBook printBook =new PrintBook(); printBook.setPress(&quot;工业出版社&quot;); printBook.setName(&quot;java&quot;); bookRepository.save(printBook); &#125;输出:保存了:EBookHibernate: select next_val as id_val from id_sequence for updateHibernate: update id_sequence set next_val= ? where next_val=?Hibernate: select next_val as id_val from id_sequence for updateHibernate: update id_sequence set next_val= ? where next_val=?保存了:PrintBookHibernate: insert into sc_ebook (sc_create_date, sc_update_date, sc_category_sc_id, sc_name, sc_web_site, sc_id) values (?, ?, ?, ?, ?, ?)Hibernate: insert into sc_print_book (sc_create_date, sc_update_date, sc_category_sc_id, sc_name, sc_press, sc_id) values (?, ?, ?, ?, ?, ?) 可以看到除了id的操作之外，jpa向两种表分别插入了数据，Book表不会插入任何数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 @Test public void test14()&#123; bookRepository.findAll(); &#125;输出结果:Hibernate: select book0_.sc_id as sc_id1_2_, book0_.sc_create_date as sc_creat2_2_, book0_.sc_update_date as sc_updat3_2_, book0_.sc_category_sc_id as sc_categ5_2_, book0_.sc_name as sc_name4_2_, book0_.sc_web_site as sc_web_s1_6_, book0_.sc_press as sc_press1_7_, book0_.clazz_ as clazz_ from ( select sc_id, sc_create_date, sc_update_date, sc_name, sc_category_sc_id, null as sc_web_site, null as sc_press, 0 as clazz_ from sc_book union select sc_id, sc_create_date, sc_update_date, sc_name, sc_category_sc_id, sc_web_site, null as sc_press, 1 as clazz_ from sc_ebook union select sc_id, sc_create_date, sc_update_date, sc_name, sc_category_sc_id, null as sc_web_site, sc_press, 2 as clazz_ from sc_print_book ) book0_ 可以看到，对于findAll查询，执行了union查询方式。对于声明类型的查询，则会直接去查询对应类型的表。这种继承策略实际上和不使用继承策略效果是相同的，适用于子类与父类差异比较大的场合，因为使用这种策略查询的效率非常差。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>JPA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot-Data JPA之Repository(2)]]></title>
    <url>%2F2017%2F12%2F31%2FSpringBoot-Data-JPA%E4%B9%8BRepository-2%2F</url>
    <content type="text"><![CDATA[Repository首先进行一下配置，让我们更方便的观察sql语句 123spring.jpa.properties.hibernate.format_sql = true //格式化sqlspring.jpa.show-sql=true //显示sql 我们先实现一个简单的查找，通过继承Repository接口 1234567@Componentpublic interface BookRepository extends Repository&lt;Book,Long&gt;&#123; /** * 根据名字查找 */ List&lt;Book&gt; findByName(String name);&#125; 测试代码: 12345678910111213@RunWith(SpringRunner.class)@SpringBootTestpublic class BookRepositoryTest &#123; @Autowired private BookRepository bookRepository; @Test public void test1()&#123; System.out.println(bookRepository.getClass().getName()); bookRepository.findByName(&quot;sc&quot;); &#125;&#125; 可以发现我们并没有写任何sql语句就实现了查询操作,为了研究到底是怎么做到的，所以打印了一下bookRepository的类型 com.sun.proxy.$Proxy77 可以看出它并不是我们声明的接口类型了，所以在实际执行过程中，是接口的代理在为我们执行sql操作。 CrudRepositoy进入Repository接口的源代码，发现它并没有任何方法。我们依次看一下继承了Repository接口的子接口。 首先看看CrudRepository接口，顾名思义，这个接口是一些简单的Crud操作，可以通过继承这个接口实现crud操作。在类名上有一个@NoRepositoryBean注解，表示这个接口不会生成代理，只是提供一些通用的方法。因为它继承自Repository接口，Repository接口会生成代理。首先修改一下BookRepository，继承CrudRepository接口 1234567891011121314151617@Testpublic void test2()&#123; Book book = new Book(); book.setName(&quot;java入门&quot;); book.setUpdateDate(new Date()); book.setCreateDate(new Date()); bookRepository.save(book);&#125;@Testpublic void test3()&#123; Iterable&lt;Book&gt; all = bookRepository.findAll(); Book one = bookRepository.findOne(1L); bookRepository.deleteAll();&#125; 一个sql语句都没写，便可以执行crud操作，对于小型的项目，真的很方便。在test2中，如果主键没有设置会执行insert语句，如果主键设置了，则会执行update语句，前提是主键对应的行项目是存在的。CrudRepository接口的方法都是比较简单的。 PagingAndSortingRepository一个提供了分页和排序的Repository，同样先修改我们的代码继承自PagingAndSortingRepository。编写测试代码: 1234@Testpublic void test4()&#123; bookRepository.findAll(new Sort(Sort.Direction.DESC,&quot;name&quot;,&quot;id&quot;));&#125; 表示根据name和id降序排列 1234@Testpublic void test5()&#123; bookRepository.findAll(new Sort(new Sort.Order(Sort.Direction.DESC,&quot;name&quot;),new Sort.Order(Sort.Direction.ASC,&quot;id&quot;)));&#125; 根据name的降序和id的升序 12345public void test6()&#123; Pageable pageable = new PageRequest(0,2,new Sort(Sort.Direction.DESC,&quot;name&quot;)); Page&lt;Book&gt; result = bookRepository.findAll(pageable); System.out.println(&quot;共&quot;+result.getTotalPages()+&quot;页,共&quot;+result.getTotalElements()+&quot;条数据&quot;);&#125; 分页加排序,jpa会根据底层不同的数据库，生成不同的分页查询语句。 JpaRepository这是我们最常继承的一个Repository，JpaRepository继承自PagingAndSortingRepository和QueryByExampleExecutor。 在这个接口中，JpaRepository覆盖了返回Iterator类型的一些方法，返回List类型更方便使用。 提供了flush方法和saveAndFlush方法，这些方法与持久化上下文有关。 通过传入Example对象执行带有条件的findAll方法。 123456789@Testpublic void test7()&#123; Book book =new Book(); book.setName(&quot;java&quot;); ExampleMatcher exampleMatcher = ExampleMatcher.matching().withStringMatcher(ExampleMatcher.StringMatcher.CONTAINING); //这里我们还可以指定一个匹配器，这里使用的是包含关系，也可以指定以xxx开头，以xxx结尾 Example&lt;Book&gt; example = Example.of(book,exampleMatcher); bookRepository.findAll(example);&#125; 静态查询jpa为我们提供了一种机制，让我可以把一些常见的查询语句转换为接口名称，只要接口名称符合规范就可以得到正确的结果。我们在最开始写的findByName方法实际上就是一个静态查询的例子。对应的查询转换可以见下面的表格,支持还是非常全面的 当然如果查询语句非常复杂，想要用sql语句直接操作也是可以的。jpa有专门的语法让我们使用查询语句，叫做JPQL语句。可以屏蔽底层数据库的差异来写sql，并不针对表名来查询，而是针对类和类的属性来查询。 12@Query(&quot;from Book b where b.name like ?1 and b.id = ?2 order by b.name desc&quot;)List&lt;Book&gt; findBooks(String name,Long id); 这个方法的意思就是根据name和id查找book。 12@Query(&quot;select count(1) from Book b where b.name like ?1 and b.id = ?2 order by b.name desc&quot;)List&lt;Book&gt; findBooks(String name,Long id); 也可以直接写出select内容，不管方法的名称限定。 123@Query(&quot;update Book b set b.name = ?1 where b.id = ?2&quot;)@Modifyingint modifyBook(String name,Long id); 在我们执行udpate或者delete这种操作的时候，接口方法必须要加@Modifying注解，否则无法生效。同时可能springboot-data-jpa的版本不同，有可能需要在业务代码或者测试代码上增加事务注解,如下，否则会抛异常 12345@Test@Transactionalpublic void test1()&#123; bookRepository.modifyBook(&quot;java11111&quot;,2L);&#125; 在@Query注解中，我们可以声明nativeQuery这个属性为true。表示使用原生的sql，这时你写的sql语句就要符合你的底层数据库，而不能使用JPQL语句来写了。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>JPA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot-Data JPA之对象映射(1)]]></title>
    <url>%2F2017%2F12%2F31%2Fspringboot-Data-JPA%E4%B9%8B%E5%AF%B9%E8%B1%A1%E6%98%A0%E5%B0%84%2F</url>
    <content type="text"><![CDATA[由于公司使用的是mybatis框架，所以自己学了学Hibernate。用的最多的应该就是SpringBoot-Data-Jpa，记录一下学习笔记。 基本属性12345678@Entity@Data@Table(name=&quot;sc_category&quot;)public class Category &#123; @Id @GeneratedValue private int id;&#125; @Table 指定表的名称 @Entity注解表示该对象可以映射成数据库的一张表 @Id表示该字段为主键 @GeneratedValue表示主键策略,它包含两个属性，strategy和generator。其中strategy默认为AUTO，generator默认为“”。generator用于自定义主键生成策略，需要额外添加一个@GenericGenerator注解。strategy四个属性为： TABLE:根据特定表格生成主键 SEQUENCE:按照序列生成主键，需要数据库支持 IDENTITY:主键列自增长 AUTO: 根据数据库自动选择策略。mysql会选择IDENTITY 123456789101112131415@Basic@Column(name = &quot;sc_name&quot;,length = 10,nullable = false,unique = true)private String name;@Transientprivate String xxxx;@Column(columnDefinition = &quot;INT(3)&quot;)private int age;@Temporal(TemporalType.DATE)private Date birthDay;@Enumerated(EnumType.STRING)private GenderEnum gender; 我们继续添加上面的属性，要注意的是每次修改属性代码，都要讲之前的数据库表删除，因为已经存在的列，hibernate是不会修改的。 @Basic每个属性都会默认加上这个注解，可以不写。 @Transizent表示这个属性不必写入数据库中。 @Colomn,这个注解包括了很多列的属性，常用的nullable可空的，unique唯一的，不可重复。要注意的是String类型的列可以用length来控制长度，而数字类型，例如int，就要用columnDefinition这个属性来控制长度。 @Temporal主要是控制时间的格式，有三种：DATE精确到日/DATETIME精确到时分秒/DATETIMESTAMP时间戳 @Enumerated注解的使用场景，比如性别我们只允许填入男或女，那么我们就可以建立一个枚举类，用这个注解指定保存到数据库的字段类型，可选String或Ordinary。枚举类代码很简单: 1234public enum GenderEnum &#123; MAN, WOMEN;&#125; 内嵌对象比如说我们对于地址字段，总是由省、市、区、邮编、地址等信息组成，如果每个表都写一遍就很累赘，有下面一种解决方法。 12345678910111213新建一个地址类@Embeddablepublic class Address &#123; private String province; private String city; private String area; private String address; private String zipCode;&#125;并在之前的类中继续添加一个属性,注意这里两个注解是不一样的，很容易弄混。 @Enumerated private Address address; 内嵌集合12@ElementCollectionprivate List&lt;String&gt; hobbies; 例如我们添加了这样的一个属性，那么jpa会自动生成一张关联表 hobbies属性与category表的主键相关联，如果在集合中插入了3条数据，那么就会在hobbies表中增加三条对应category ID的记录。集合中的对象不仅可以是像String这种基本属性，也可以是自定义的复杂属性，比如我们刚刚建立的地址类:List,hibernate也会生成一张表，机制与hobbies类似。 自定义表名列名有时候为了防止表名重复或者出发到数据库的关键字，我们会在表名前加一个前缀，如果每个表都去指定就太麻烦了，我们可以通过自己实现一个命名策略简化这些步骤。首先新建一个配置类: 12345678public class MyNameStrategy extends ImplicitNamingStrategyJpaCompliantImpl&#123; @Override protected Identifier toIdentifier(String stringForm, MetadataBuildingContext buildingContext) &#123; return super.toIdentifier(&quot;sc_&quot;+stringForm, buildingContext); //在这里加一个前缀 &#125;&#125;spring.jpa.hibernate.naming.implicit-strategy=com.example.demo.config.MyNameStrategy 在配置文件中加入配置 这样，在每个表和列之前都加入了一个前缀sc_,如果有的表或者列不需要前缀，可以再列或者表上指定名称，因为直接指定的优先级更高。 多对一关系的映射123456789101112@Entitypublic class Book &#123; @Id @GeneratedValue private Long id; private String name; @ManyToOne private Category category;&#125; category类我们不做改变，新增一个book类。因为多本书可以属于同一个分类，所以书对于类别的关系是多对一的，我们添加一个@ManyToOne注解 我们可以看到hibernate做的就是添加了一个列，这个列其实是一个外键，对应的就是category表的id属性。这里我们就做了一个单向的从book到category的多对一关系。 一对多关系映射由于一个分类可以对应多个book，所以category对于book就是一对多的映射关系，我们可以通过集合来表示这种关系。 12@OneToManyprivate List&lt;Book&gt; books; 这个注解产生的效果与内嵌集合的效果相同，都是新增了一张中间表来映射关系。通过这种注解，category和book建立了一种双向的关联。在book这一方添加了一个外键，在category这一方建立了一张中间表。那么如果我们希望book这一方来维护这种关系，而category这一方只需要声明这种一对多关系，因为我希望通过category来查找相应的book。那么我们可以这样来做： 12@OneToMany(mappedBy = &quot;category&quot;)private List&lt;Book&gt; books; 我们添加一个mappdby属性，意思是说，category这一方放弃维护关系，而是交给book表中category这一列来维护，我们看一下生成的表就很容易明白了。 可以看出，book表依旧生成了一个外键，而category则没有生成之前那张中间表。我们也可以使用同样的注解使book放弃维护，让category维护一对多关系。 多对多关系映射我们继续建立一张BookAuthor表和Author表。一本书可以有多个作者，一个作者也可以有多本书。我们尝试建立一种多对多的关系。 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Entitypublic class Author &#123; @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = &quot;author&quot;) private List&lt;BookAuthor&gt; books;&#125;@Entity@Datapublic class Book &#123; @Id @GeneratedValue private Long id; private String name; @ManyToOne private Category category; @OneToMany(mappedBy = &quot;book&quot;) private List&lt;BookAuthor&gt; authors;&#125;@Entity@Datapublic class BookAuthor &#123; @Id @GeneratedValue private Long id; @ManyToOne private Book book; @ManyToOne private Author author;&#125; 这种实现多对多的方式是通过一张中间表来完成的，执行项目之后会在数据库中生成一张中间表，通过外键关联两张表。那么很多人就会产生疑惑，为什么我们不直接使用@ManyToMany注解表示多对多的关系呢？因为这个注解很难用- -!在Hibernate最佳实践中明确告诉我们尽量不要用ManyToMany这种形式。永远把多对多关系拆分成两个多对一关系。通过这种方式，当我们获取对应关系的时候，默认是按照主键Id的顺序排序的，如果我们想指定排序规则，可以使用这种方式: 123@OneToMany(mappedBy = &quot;author&quot;)@OrderBy(&quot;book.name ASC&quot;)private List&lt;BookAuthor&gt; books; 这样表示通过BookAuthor类的book属性，根据book的name属性升序排序。 一对一关系映射一对一的的映射其实是这样一种场景，比如一个Author表和一个AuthorInfo表，我们大部分查询只需要Author表里面的信息，少数时间需要查询info里面的信息，那么我们就可以吧不常用的信息放到info表里，这样Author和AuthorInfo就形成了一种一对一的关系映射。为了演示，增加一个AuthorInfo类： 123456789101112131415161718192021222324252627282930@Entity@Datapublic class AuthorInfo &#123; @Id @GeneratedValue private Long id; private String school; @OneToOne(mappedBy = &quot;info&quot;) //将关系的管理权交给autho对象的info属性 private Author author;&#125;@Data@Entitypublic class Author &#123; @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = &quot;author&quot;) private List&lt;BookAuthor&gt; books; @OneToOne private AuthorInfo info;&#125; 这样在author表中就多出了一个infoId的字段，通过外键来管理author info，而author_info表不会出现author表的外键。 继承的映射在java中我们可以通过继承来解决属性的重用，而在关系型数据中是不存在继承这种关系的。那么我们来看一下Hibernate是如何解决这种问题的。我们新建一个CommonProperty类，抽出每个实体类都有的Id属性，并增加一个创建时间和修改时间: 1234567891011121314@MappedSuperclass@Datapublic class CommonProperty &#123; @Id @GeneratedValue private Long id; @Temporal(TemporalType.DATE) private Date createDate; @Temporal(TemporalType.DATE) private Date updateDate;&#125; 之后我们让每个实体类都去继承这个类就可以了。执行之后查看数据库发现每个实体表都会增加上述三个属性。实现的关键就在于这个@MappedSuperclass注解。@MappedSuperclass标识的类表示其不能映射到数据库表，因为其不是一个完整的实体类，但是它所拥有的属性能够映射在其子类对用的数据库表中。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>JPA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis分布式原理及操作]]></title>
    <url>%2F2017%2F12%2F30%2Fredis%E5%88%86%E5%B8%83%E5%BC%8F%E5%8E%9F%E7%90%86%E5%8F%8A%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[传统分布式算法举个栗子假设我们有20个数据需要缓存，并且有4个分布式redis节点。数据直接通过编号对4进行取余，得到他们Hash到的位置，并放置在对应的redis节点上。效果如图 但是随着我们业务的变化，Redis节点的数量可能会增加或者减少。假设我们增加一个redis节点 重新进行hash之后，对应关系如图所示，绿色的部分就是我们两次hash，数据还映射到同一个redis的数据，总共有4个，也就是说，在传统的分布式算法下，增加一个节点，数据的命中率下降到了4/20=20%。我们演示只用了20个数据，在实际生产环境中，很可能是成千上万的数据，那么这些miss的数据就会直接去访问数据库，对数据库造成巨大的压力。那么如何解决或者降低这种缓存miss的概率呢，一个解决方案就是redis采用的一致性hash算法。 Consistent hashing一致性算法原理环形hash空间通常hash算法都是将value映射到一个32位的key值当中，我们假设将这个数轴首尾相接形成一个环 现在映射空间已经形成，我们要考虑如何将数据映射到空间上。 假设有4个对象O1~O4,可以通过hash函数计算出hash值的key，映射到如下的位置 接着我们使用相同的hash算法把缓存实例(redis)映射到环形空间，一般是通过hash IP地址或者机器名等等 通过hash算法我们现在已经把reids和数据都进行了hash，那么怎么确定哪个数据映射到哪个redis上呢 映射方法如图，我们顺时针看这个圈，每个数据O按顺时针方向找到第一个R，那么这个O就存储在这个R节点上。现在并没有看出这个算法的优势，现在我们假设移除一个Redis节点R2，那么O4数据就会miss，那么这个算法会按原来的方案，将数据映射到R3上。如果我们移除R3节点，受影响的就是O2和O3，其实我们发现，移除或者增加节点，只会影响到新增R与逆时针的第一个R节点之间的数据，其他数据不会受到影响。而使用传统的Hash算法，基本上每个节点都会受到影响，这就体现了一致性Hash的一个优势，那就是缩小了影响范围。 Hash算法的倾斜性在实际的Hash计算中，很可能会出现上图中描述的现象。从这个图中我们可以看出来，大量的数据映射到R1节点上，R2,R3都非常空闲。这样会造成R1节点的负载很高，这就是Hash算法的倾斜性。那么如何解决这种Hash倾斜性带来的问题呢 虚拟节点假设我们增加3个虚拟节点，将其均匀的分布在环上。 可以看出这时的环比刚才而言均匀了许多，我们可以让映射到V1的节点实际上存储到R1,V2存储到R2，V3存储到R3。这样R1 R2 R3之间的负载就均衡了。实际在Redis中，虚拟节点可能会建立成百上千个。Redis通过建立虚拟节点，并将虚拟节点Hash到实际的Redis节点上，通过这种方法将真实节点进行放大，就解决了这种Hash倾斜性造成的问题。在Jedis的源码中，我们可以再Sharded这个类的init方法中看到，每个实例的虚拟节点默认是160个。 结论一致性Hash算法最大限度上抑制了key的重新分布，并且随着缓存实例数量的增加，对key命中的影响会越来越小，而传统的Hash算法，影响只会越来越大。 Jedis配置首先在服务器启动两个Redis节点并在本地项目中配置相应的端口和IP ShardedPool配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class RedisShardedPool &#123; private static ShardedJedisPool pool; private static Integer maxTotal = Integer.parseInt(PropertiesUtil.getProperty(&quot;redis.max.total&quot;,&quot;20&quot;)); private static Integer maxIdle = Integer.parseInt(PropertiesUtil.getProperty(&quot;redis.max.idle&quot;,&quot;20&quot;)); private static Integer minIdle = Integer.parseInt(PropertiesUtil.getProperty(&quot;redis.min.idle&quot;,&quot;20&quot;)); private static Boolean testOnBorrow = Boolean.parseBoolean(PropertiesUtil.getProperty(&quot;redis.test.borrow&quot;,&quot;true&quot;)); private static Boolean testOnReturn = Boolean.parseBoolean(PropertiesUtil.getProperty(&quot;redis.test.return&quot;,&quot;true&quot;)); private static String redisIp = PropertiesUtil.getProperty(&quot;redis.ip&quot;); private static Integer redisPort = Integer.parseInt(PropertiesUtil.getProperty(&quot;redis.port&quot;)); private static String redis2Ip = PropertiesUtil.getProperty(&quot;redis2.ip&quot;); private static Integer redis2Port = Integer.parseInt(PropertiesUtil.getProperty(&quot;redis2.port&quot;)); private static void initPool()&#123; JedisPoolConfig conf = new JedisPoolConfig(); conf.setMaxTotal(maxTotal); conf.setMaxIdle(maxIdle); conf.setMinIdle(minIdle); conf.setTestOnBorrow(testOnBorrow); conf.setTestOnReturn(testOnReturn); conf.setBlockWhenExhausted(true); JedisShardInfo info1 = new JedisShardInfo(redisIp,redisPort); JedisShardInfo info2 = new JedisShardInfo(redis2Ip,redis2Port); List&lt;JedisShardInfo&gt; list = Arrays.asList(info1,info2); //MURMUR Hash就是一致性算法 pool = new ShardedJedisPool(conf,list, Hashing.MURMUR_HASH, Sharded.DEFAULT_KEY_TAG_PATTERN); &#125; static &#123; initPool(); &#125; public static ShardedJedis getJedis()&#123; return pool.getResource(); &#125; public static void returnBrokenResource(ShardedJedis jedis)&#123; pool.returnBrokenResource(jedis); &#125; public static void returnResource(ShardedJedis jedis)&#123; pool.returnResource(jedis); &#125; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; ShardedJedis jedis = pool.getResource(); jedis.set(i+&quot;&quot;,i+&quot;&quot;); returnResource(jedis); &#125; pool.destroy(); System.out.println(&quot;end&quot;); &#125;&#125; 操作方法类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@Slf4jpublic class RedisShardedPoolUtil &#123; public static String set(String key,String value)&#123; ShardedJedis jedis = null; String result= null; try &#123; jedis = RedisShardedPool.getJedis(); result = jedis.set(key, value); &#125; catch (Exception e) &#123; log.error(&quot;set key:&#123;&#125; value:&#123;&#125; error&quot;,key,value); RedisShardedPool.returnBrokenResource(jedis); return result; &#125; RedisShardedPool.returnResource(jedis); return result; &#125; public static String get(String key)&#123; ShardedJedis jedis = null; String reslut= null; try &#123; jedis = RedisShardedPool.getJedis(); reslut = jedis.get(key); &#125; catch (Exception e) &#123; log.error(&quot;get key:&#123;&#125; error&quot;,key); RedisShardedPool.returnBrokenResource(jedis); return reslut; &#125; RedisShardedPool.returnResource(jedis); return reslut; &#125; /** * 时间单位是秒 */ public static String setEx(String key,String value,int exTime)&#123; ShardedJedis jedis = null; String result= null; try &#123; jedis = RedisShardedPool.getJedis(); result = jedis.setex(key,exTime,value); &#125; catch (Exception e) &#123; log.error(&quot;setex key:&#123;&#125; value:&#123;&#125; error&quot;,key,value); RedisShardedPool.returnBrokenResource(jedis); return result; &#125; RedisShardedPool.returnResource(jedis); return result; &#125; public static Long expire(String key,int exTime)&#123; ShardedJedis jedis = null; Long result= null; try &#123; jedis = RedisShardedPool.getJedis(); result = jedis.expire(key,exTime); &#125; catch (Exception e) &#123; log.error(&quot;expire key:&#123;&#125; error&quot;,key); RedisShardedPool.returnBrokenResource(jedis); return result; &#125; RedisShardedPool.returnResource(jedis); return result; &#125; public static Long del(String key)&#123; ShardedJedis jedis = null; Long result= null; try &#123; jedis = RedisShardedPool.getJedis(); result = jedis.del(key); &#125; catch (Exception e) &#123; log.error(&quot;del key:&#123;&#125; error&quot;,key); RedisShardedPool.returnBrokenResource(jedis); return result; &#125; RedisShardedPool.returnResource(jedis); return result; &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq入门-实现微博关注demo(2)]]></title>
    <url>%2F2017%2F12%2F23%2FRabbitMq%E5%85%A5%E9%97%A8-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E5%8D%9A%E5%85%B3%E6%B3%A8demo-2%2F</url>
    <content type="text"><![CDATA[在网上看了很多RabbitMq的demo，发现都是Exchange三种路由模式的demo，很少有真实案例的demo，在这里分享一个自己写的模拟微博关注的demo,方便理解和学习。 工具SpringBoot RabbitMq 构思 美女发布消息，关注她的人可以接收到消息 关注和取关都记录到日志中 美女和关注者都可以动态添加,添加一个美女就是添加一个Fanout模式的Exchange，一个关注者就是一个队列绑定到对应美女的Exchange 测试类列出想要实现的接口 12345678910111213141516171819202122232425262728293031323334353637383940@RestControllerpublic class Controller &#123; @Autowired private LikeService likeService; /** * 美女注册 */ @GetMapping(&quot;/addBeauty&quot;) public void addBeauty(String name)&#123; likeService.addBeauty(name); &#125; /** * 关注她 */ @GetMapping(&quot;/like&quot;) public void like(String boyName,String girlName) &#123; likeService.like(boyName,girlName); &#125; /** * 取关 */ @GetMapping(&quot;/unlike&quot;) public void unlike(String boyName,String girlName)&#123; likeService.unlike(boyName,girlName); &#125; /** * 美女发朋友圈了 */ @GetMapping(&quot;/post&quot;) public void postMessage(String girlName,String message)&#123; likeService.postMessage(girlName,message); &#125;&#125; 配置类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Configurationpublic class BaseRabbitConfig &#123; @Bean public ConnectionFactory connectionFactory()&#123; CachingConnectionFactory factory = new CachingConnectionFactory(); factory.setVirtualHost(&quot;/&quot;); factory.setUsername(&quot;用户名&quot;); factory.setPassword(&quot;密码&quot;); factory.setAddresses(&quot;IP+PORT&quot;); return factory; &#125; @Bean public RabbitManagementTemplate rabbitManagementTemplate()&#123; return new RabbitManagementTemplate(&quot;http://用户名:密码@IP+PORT/api/&quot;); &#125; @Bean public AmqpAdmin amqpAdmin()&#123; return new RabbitAdmin(connectionFactory()); &#125; @Bean public RabbitTemplate rabbitTemplate()&#123; return new RabbitTemplate(connectionFactory()); &#125;&#125;@Configurationpublic class LogRabbitConfig extends BaseRabbitConfig &#123; public static final String LOG_QUEUE = &quot;LOG_QUEUE&quot;; public static final String LOG_EXCHANGE = &quot;LOG_EXCHANGE&quot;; public final static String ROUTING_KEY=&quot;log&quot;; @Bean public Queue logQueue()&#123; return new Queue(LOG_QUEUE); &#125; /** * 监听容器 */ @Bean public SimpleMessageListenerContainer container(ConnectionFactory connectionFactory, LogListener logListener)&#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(); container.setConnectionFactory(connectionFactory); container.setQueueNames(new String[]&#123;LOG_QUEUE&#125;); container.setMessageListener(logListener); return container; &#125; @Bean LogListener logListener()&#123; return new LogListener(); &#125; @Bean public DirectExchange directExchange()&#123; return new DirectExchange(LOG_EXCHANGE); &#125; @Bean Binding binding(Queue logQueue,DirectExchange directExchange)&#123; return BindingBuilder.bind(logQueue).to(directExchange).with(ROUTING_KEY); &#125;&#125; 这里我注册了一个RabbitManagementTemplate，作用是调用HttpApi。因为我的构想是希望能够实现队列和交换器的热插拔，这时要解决的问题就是实时获取Exchange的列表和一些绑定的信息，但在网上并没有找到相关的资料。这里一个技巧就是查找函数了，在IDEA中可以双击shift搜索函数。比如我想要的功能是getExchanges(),因为我猜这个功能的调用函数就叫这个名字，果然在这里发现了: 可以看到还可以取到队列，绑定的信息，这就是我们实现热插拔的必要条件了，接着看到它的构造函数： 123public RabbitManagementTemplate() &#123; this(&quot;http://guest:guest@localhost:15672/api/&quot;); &#125; 所以只要我们把地址填成我们自己的rabbitmq配置就可以，这个对象其实就是调用了RabbitMq的HttpApi。我们可以打开RabbitMq的webUI，拉到最下面 点击这个Http API就可以通过Restful的方式调用这些API 业务实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Servicepublic class LikeService &#123; @Autowired private RabbitTemplate rabbitTemplate; @Autowired private AmqpAdmin amqpAdmin; @Autowired private RabbitManagementTemplate rabbitManagementTemplate; public void addBeauty(String name) &#123; try &#123; FanoutExchange fanoutExchange = new FanoutExchange(name); amqpAdmin.declareExchange(fanoutExchange); System.out.println(&quot;初始化交换器成功 :&quot;+name); rabbitTemplate.convertAndSend(LogRabbitConfig.LOG_EXCHANGE,LogRabbitConfig.ROUTING_KEY,&quot;初始化交换器&quot;+name); &#125;catch (Exception e)&#123; System.out.println(&quot;初始化交换器失败 :&quot;+name); &#125; &#125; public void like(String boyName, String girlName) &#123; Queue queue = new Queue(boyName); FanoutExchange fanoutExchange = (FanoutExchange) rabbitManagementTemplate.getExchange(girlName); amqpAdmin.declareQueue(queue); amqpAdmin.declareBinding(BindingBuilder.bind(queue).to(fanoutExchange)); SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(); container.setQueueNames(boyName); container.setConnectionFactory(rabbitTemplate.getConnectionFactory()); container.setMessageListener(new BoyListener()); container.start(); System.out.println(boyName+&quot;关注了&quot;+girlName); &#125; public void postMessage(String girlName, String message) &#123; System.out.println(girlName+&quot;发了一条微博&quot;+message); rabbitTemplate.convertAndSend(girlName,&quot;&quot;,message); &#125; public void unlike(String boyName, String girlName) &#123; Queue queue = rabbitManagementTemplate.getQueue(boyName); rabbitManagementTemplate.deleteQueue(queue); rabbitTemplate.convertAndSend(LogRabbitConfig.LOG_EXCHANGE,LogRabbitConfig.ROUTING_KEY,boyName+&quot;取关了&quot;+girlName); &#125;&#125;@RabbitListenerpublic class BoyListener implements MessageListener&#123; @Override public void onMessage(org.springframework.amqp.core.Message message) &#123; System.out.println(message.getMessageProperties().getConsumerQueue()+&quot;看到&quot;+message.getMessageProperties().getReceivedExchange()+&quot;发朋友圈&quot;+new String(message.getBody())); &#125;&#125;@Servicepublic class LogListener implements MessageListener&#123; @Override public void onMessage(Message message) &#123; System.out.println(&quot;LOG QUEUE ============&quot;); System.out.println(new String(message.getBody())); //写入文件 System.out.println(&quot;======================&quot;); &#125;&#125; 效果 这里中文出现了乱码，目前已经解决问题,代码在这里 https://gitee.com/swiftsc/RabbitMq-mockweipo]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq入门-基本概念(1)]]></title>
    <url>%2F2017%2F12%2F22%2FRabbitMq%E5%85%A5%E9%97%A8-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[JMSJava Message Service，是java平台面向消息中间件的API，提供了与消息中间件厂商无关的访问方法，作用相当于JDBC，在多个应用程序之间，提供异步的通信服务。由于JMS只是一套API，具体的实现还是依靠Mq来做，目前使用最多的就是AcitveMq，因此在springboot中，jms默认使用的就是activemq。目前springboot集成了两种jms的实现:AcitveMq和Artemis(没听说过),实现了AMQP协议的rabbitMq以及一种发布订阅系统kafka。 AMQPAdvanced Message Queuing Protocol,是一个应用层的消息队列协议，基于此协议开发消息队列产品，可以不受编程语言的限制。 为什么选择RabbitMq一张图就能说明 RabbitMq相关概念 Virtual host: rabbitmq server实际上是由多个vutrual rabbitmq server组成的,即Vhost，默认是 “/”,每个用户所能使用的Exchange和queue也都是一个vhost的，而不能跨vhost调用。这样做的优点是可以为不同app提供边界隔离，使得应用安全的运行在不同的vhost实例上，相互之间不会干扰。 Queue: 消息队列，FIFO，支持缓存、持久化、自动删除 Exchange: 交换机，用来管理队列。在实际操作中，消息并不直接发布给队列，而是发布给Exchange，Exchange根据不同的路由策略选择转发到哪条队列中。Exchange有4种类型：direct(默认)，fanout, topic, 和headers。 Binding: 指定Exchange与Queue建立关系，支持多对多，一对多，多对一。 Connection: 与rabbitmq server建立的一种TCP连接。客户端可以断开连接，server不会主动断开。 Channel: 一个Connection支持多个Channel，以减少建立Connection所需要的消耗。应用可以通过多线程的方式建立多个Channel，共用一个Connection，减少消耗 Exchange交换机制 Direct: 直接交换器，Exchange会将消息发送完全匹配ROUTING_KEY的Queue Fanout: 广播方式，Exchange都会将消息转发给所有绑定的Queue Topic: Exchange会将消息转发和ROUTING_KEY匹配模式相同的所有队列，工作方式类似于sql中的like模糊匹配。 Headers: 与ROUTING_KEY无关，根据消息中的键值对进行匹配，headers属性是一个键值对，可以是Hashtable，键值对的值可以是任何类型。 x-match = all ：表示所有的键值对都匹配才能接受到消息 x-match = any ：表示只要有键值对匹配就能接受到消息 12345678910例如 初始化Exchange:HashMap message = new HashMap(3); message.put(&quot;x-match&quot;,&quot;any&quot;); message.put(&quot;name&quot;,&quot;sc&quot;); message.put(&quot;age&quot;,10); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;&quot;, message); 生产者发布消息:HashMap message = new HashMap(3); message.put(&quot;name&quot;,&quot;sc&quot;); message.put(&quot;age&quot;,20); 由于配置的x-match属性为any，所以Exchange会转发这条信息，如果改为all，则会拒绝这条信息。 RabbitMq在阿里云上的配置由于自己有一个阿里云服务器，所以想把Rabbit放在云上使用，结果碰到了一些坑。由于rabbitmq默认是不支持外网访问的，初始化时的guest用户只能在localhost访问，那么我们就需要配置一个远程访问权限的用户。 我使用的是rabbitmq3.6.3,centos7 进入安装目录/sbin ./rabbitmqctl add_user 用户名 密码 给默认vhost / 设置权限 ./rabbitmqctl set_permissions -p “/“ 用户名 “.“ “.“ “.*” 赋予管理员权限 ./rabbitmqctl set_user_tags 用户名 administrator 配置文件 由于安装方式不同，配置文件的位置可能也不同，如果存在/etc/rabbitmq/目录，就编辑这个目录下rabbitmq.config(没有就创建),加入以下代码[{rabbit, [{tcp_listeners, [5672]}, {loopback_users, [“用户名”]}]}].注意最后有个点号。如果你是直接解压缩使用的，那么就在解压缩目录下的rabbit-xxxx/etc/rabbit，创建文件添加代码就可以了。 通过公网网址：15672访问。 通过这里就可以查看你的配置文件有没有找到，通过web管理也可以很方便的管理rabbit,可以自己摸索一下。 基础DemoRabbitMq配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110@Configurationpublic class MyRabbitConfig &#123; @Value(&quot;$&#123;rabbit.host&#125;&quot;) private String host; @Value(&quot;$&#123;rabbit.port&#125;&quot;) private int port; @Value(&quot;$&#123;rabbit.username&#125;&quot;) private String username; @Value(&quot;$&#123;rabbit.password&#125;&quot;) private String password; @Value(&quot;$&#123;rabbit.vhost&#125;&quot;) private String vhost; @Bean public ConnectionFactory connectionFactory()&#123; CachingConnectionFactory factory = new CachingConnectionFactory(); factory.setHost(host); factory.setPort(port); factory.setUsername(username); factory.setPassword(password); factory.setVirtualHost(vhost); factory.setPublisherConfirms(true); return factory; &#125; @Bean @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) public RabbitTemplate rabbitTemplate()&#123; RabbitTemplate template = new RabbitTemplate(connectionFactory()); return template; &#125; &#125; @Bean public Queue helloQueue()&#123; return new Queue(&quot;hello&quot;); &#125; @Bean public Queue userQueue()&#123; return new Queue(&quot;user&quot;); &#125; /** * 验证topic */ @Bean public Queue queueMessage()&#123; return new Queue(&quot;topic.message&quot;); &#125; @Bean public Queue queueMessages()&#123; return new Queue(&quot;topic.messages&quot;); &#125; /** * fanout */ @Bean public Queue AMessage()&#123; return new Queue(&quot;fanout.A&quot;); &#125; @Bean public Queue BMessage()&#123; return new Queue(&quot;fanout.B&quot;); &#125; @Bean public Queue CMessage()&#123; return new Queue(&quot;fanout.C&quot;); &#125; /** * topic exchange */ @Bean TopicExchange exchange()&#123; return new TopicExchange(&quot;topicExchange&quot;); &#125; /** * fanout exchange */ @Bean FanoutExchange fanoutExchange()&#123; return new FanoutExchange(&quot;fanoutExchange&quot;); &#125; /** * 完全匹配 */ @Bean Binding bindingTopic(Queue queueMessage,TopicExchange exchange)&#123; return BindingBuilder.bind(queueMessage).to(exchange).with(&quot;topic.message&quot;); &#125; /** * 模糊匹配 */ @Bean Binding bindingTopics(Queue queueMessages,TopicExchange exchange)&#123; return BindingBuilder.bind(queueMessages).to(exchange).with(&quot;topic.#&quot;); &#125; /** * fanout 绑定 */ @Bean Binding bindingA(Queue AMessage,FanoutExchange exchange)&#123; return BindingBuilder.bind(AMessage).to(exchange); &#125; @Bean Binding bindingB(Queue BMessage,FanoutExchange exchange)&#123; return BindingBuilder.bind(BMessage).to(exchange); &#125; @Bean Binding bindingC(Queue CMessage,FanoutExchange exchange)&#123; return BindingBuilder.bind(CMessage).to(exchange); &#125; GetMapping测试 123456789101112131415@Autowiredprivate TopicSender topicSender;@Autowiredprivate FanoutSender fanoutSender;@GetMapping(&quot;/topic&quot;)public void topic()&#123; topicSender.send();&#125;@GetMapping(&quot;/fanout&quot;)public void fan()&#123; fanoutSender.send();&#125; Fanout测试代码 12345678910111213141516171819202122232425262728293031323334353637@Componentpublic class FanoutSender &#123; @Autowired private AmqpTemplate template; public void send()&#123; String message = &quot;fanout send&quot;; template.convertAndSend(&quot;fanoutExchange&quot;,&quot;haha&quot;,message); &#125;&#125;@Component@RabbitListener(queues = &quot;fanout.C&quot;)public class FanoutRC &#123; @RabbitHandler public void process(String message)&#123; System.out.println(&quot;fanout C :&quot;+ message); &#125;&#125;@Component@RabbitListener(queues = &quot;fanout.B&quot;)public class FanoutRB &#123; @RabbitHandler public void process(String message)&#123; System.out.println(&quot;fanout B :&quot;+ message); &#125;&#125;@Component@RabbitListener(queues = &quot;fanout.A&quot;)public class FanoutRA &#123; @RabbitHandler public void process(String message)&#123; System.out.println(&quot;fanout A :&quot;+ message); &#125;&#125; Topic测试代码,这里同时测试了反馈机制，需要继承ConfirmCallBack接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Componentpublic class TopicSender implements RabbitTemplate.ConfirmCallback&#123;// @Autowired// private AmqpTemplate template; @Autowired private RabbitTemplate template; public void send()&#123; template.setConfirmCallback(this); CorrelationData data = new CorrelationData(UUID.randomUUID().toString()); String message1 = &quot;I am topic.message =====&quot;; template.convertAndSend(&quot;topicExchange&quot;,&quot;topic.message&quot;,message1,data); CorrelationData data1 = new CorrelationData(UUID.randomUUID().toString()); String message2 = &quot;I am topic.apple.12312&quot;; template.convertAndSend(&quot;topicExchange&quot;,&quot;topic.messages&quot;,message2,data1); &#125; @Override public void confirm(CorrelationData correlationData, boolean b, String s) &#123; System.out.println(&quot;sender confirm callback: &quot;+correlationData.toString()); &#125;&#125;@Component@RabbitListener(queues = &quot;topic.messages&quot;)public class TopicReceiver2 &#123; @RabbitHandler public void say(String mes)&#123; System.out.println(&quot;topic.# receive: &quot;+mes); &#125;&#125;@Component@RabbitListener(queues = &quot;topic.message&quot;)public class TopicReceiver1 &#123; @RabbitHandler public void say(String mess)&#123; System.out.println(&quot;topic.message receive: &quot;+mess); &#125;&#125;]]></content>
      <categories>
        <category>RabbitMq</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring4.3.x源码阅读笔记-AOP(3)]]></title>
    <url>%2F2017%2F12%2F19%2Fspring4-3-x%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-AOP-3%2F</url>
    <content type="text"><![CDATA[Spring AOP部分源码比较复杂，看了书上的内容还是觉得云里雾里，好在这部分的参考资料比较多，感谢原博主。在这里自己整理一下思路。 http://blog.csdn.net/luanlouis/article/details/51155821 《Spring源码深度解析》 AOP的基本概念切面（Aspect）：类似于OOP中的Class，一个Aspect存放一个系统功能的所有逻辑； 连接点（Joinpoint）：程序执行过程中的某一事件，如方法被调用时、抛出异常时； 切入点（Pointcut）：它是一个表达式，用于确定哪些类的哪些函数需要插入横切逻辑；它只精确到函数，究竟要在函数执行的哪个阶段插入横切逻辑，这就由通知的类型决定； 通知（Advice）：具体的横切逻辑； Spring中有四种Advice： 前置通知（Before Advice） 后置通知（After Advice） 返回通知（After Return Advice） 环绕通知（Around Advice） 抛出异常后通知（After Throwing Advice） 自己动手写一个AOP过程上面图中使用AOP的方式是我们在写代码时最常见的一种，只需要添加相应的jar包，并在配置文件中声明扫描位置和启动自动注解即可 12&lt;context:component-scan base-package=&quot;com.sc.aop.impl&quot;/&gt;&lt;aop:aspectj-autoproxy/&gt; 但是这种写法不利于我们的源码阅读，我们通过代码手动装配一个AOP来打断点看源码 http://blog.csdn.net/luanlouis/article/details/51155821 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public interface TicketService &#123; void sellTicket(); void inquire(); void withdraw();&#125;public class RailWayStation implements TicketService &#123; @Override public void sellTicket() &#123; System.out.println(&quot;卖票&quot;); &#125; @Override public void inquire() &#123; System.out.println(&quot;咨询&quot;); &#125; @Override public void withdraw() &#123; System.out.println(&quot;回执&quot;); &#125;&#125;以上是业务逻辑,下面是三个切面类public class MyAfter implements AfterReturningAdvice &#123; @Override public void afterReturning(Object o, Method method, Object[] objects, Object o1) throws Throwable &#123; System.out.println(&quot;给你开发票&quot;); &#125;&#125;public class MyBefore implements MethodBeforeAdvice &#123; @Override public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;询问票价&quot;); &#125;&#125;public class MyAround implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation methodInvocation) throws Throwable &#123; System.out.println(&quot;摄像头在360°监控&quot;); Object returnValue = methodInvocation.proceed(); System.out.println(&quot;摄像头在360°监控&quot;); return returnValue; &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; RailWayStation service = new RailWayStation(); //实例化通知 Advice before = new MyBefore(); Advice after = new MyAfter(); Advice around = new MyAround(); //装配代理bean ProxyFactoryBean proxyFactoryBean = new ProxyFactoryBean(); proxyFactoryBean.setInterfaces(TicketService.class); proxyFactoryBean.setTarget(service); proxyFactoryBean.setProxyTargetClass(true); proxyFactoryBean.addAdvice(before); proxyFactoryBean.addAdvice(after); proxyFactoryBean.addAdvice(around); proxyFactoryBean.setProxyTargetClass(false); TicketService ticketService = (TicketService) proxyFactoryBean.getObject(); ticketService.sellTicket(); &#125;&#125;打印结果:询问票价摄像头在360°监控卖票摄像头在360°监控给你开发票 就这样，我们通过创建ProxyFactoryBean，并手动组装了一个Aop过程。可见AOP实现的关键是这个ProxyFactoryBean，那么就从这里入手看源码。 AOP核心ProxyFactoryBean通过这幅图我们就可以理解刚刚main函数中所做的一些配置,我们可以从getObject这一句来进入源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public Object getObject() throws BeansException &#123;//初始化一个通知链 this.initializeAdvisorChain(); if (this.isSingleton()) &#123;//生成singlton类型bean的代理 return this.getSingletonInstance(); &#125; else &#123; if (this.targetName == null) &#123; this.logger.warn(&quot;Using non-singleton proxies with singleton targets is often undesirable. Enable prototype proxies by setting the &apos;targetName&apos; property.&quot;); &#125; return this.newPrototypeInstance(); &#125; &#125; private synchronized Object getSingletonInstance() &#123; if (this.singletonInstance == null) &#123; this.targetSource = this.freshTargetSource(); if (this.autodetectInterfaces &amp;&amp; this.getProxiedInterfaces().length == 0 &amp;&amp; !this.isProxyTargetClass()) &#123;//获取要代理的类 Class&lt;?&gt; targetClass = this.getTargetClass(); if (targetClass == null) &#123; throw new FactoryBeanNotInitializedException(&quot;Cannot determine target class for proxy&quot;); &#125;//设置代理类的接口，所以在main函数中，可以不显式的指定接口，但必须要有接口才行 this.setInterfaces(ClassUtils.getAllInterfacesForClass(targetClass, this.proxyClassLoader)); &#125; super.setFrozen(this.freezeProxy);//关键方法:创建AOP代理//有两种方式：JDK动态代理和CGLIB this.singletonInstance = this.getProxy(this.createAopProxy()); &#125; return this.singletonInstance; &#125; public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; //在这里，spring通过判断这三个条件来决定使用JDK动态代理还是CGLIB //1.optimize属性控制cglib是否使用激进的优化策略，使用cglib才有效 //2.proxyTargetClss属性默认是false，如果指定为true则使用cglib进行代理 //3.hasNoUserSuppliedProxyInterfaces是否存在接口 if (!config.isOptimize() &amp;&amp; !config.isProxyTargetClass() &amp;&amp; !this.hasNoUserSuppliedProxyInterfaces(config)) &#123; return new JdkDynamicAopProxy(config); &#125; else &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(&quot;TargetSource cannot determine target class: Either an interface or a target is required for proxy creation.&quot;); &#125; else &#123; return (AopProxy)(!targetClass.isInterface() &amp;&amp; !Proxy.isProxyClass(targetClass) ? new ObjenesisCglibAopProxy(config) : new JdkDynamicAopProxy(config)); &#125; &#125; &#125; JDK动态代理实现AOP1final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable&#123;&#125; 可以看到该类实现了InvocationHandler这个接口，当我自己实现一个动态代理的时候就会实现这个接口，那么该类最重要的就是invoke方法的内容了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Class&lt;?&gt; targetClass = null; Object target = null; Object retVal; try &#123;//实现代理对象的equals方法 if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; Boolean var20 = this.equals(args[0]); return var20; &#125;//实现代理对象的hashCode方法 if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; Integer var18 = this.hashCode(); return var18; &#125; if (method.getDeclaringClass() == DecoratingProxy.class) &#123; Class var17 = AopProxyUtils.ultimateTargetClass(this.advised); return var17; &#125; if (this.advised.opaque || !method.getDeclaringClass().isInterface() || !method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; if (this.advised.exposeProxy) &#123; oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; target = targetSource.getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125;//获取当前方法的拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) &#123;//没有拦截器链直接调用切点方法 Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123;//将拦截器链封装到ReflectiveMethodInvocation中 MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);//先执行拦截器链的方法 retVal = invocation.proceed(); &#125; Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException(&quot;Null return value from advice does not match primitive return type for: &quot; + method); &#125; Object var13 = retVal; return var13; &#125; retVal = AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; return retVal; &#125; ==== public Object proceed() throws Throwable &#123;//判断通知方法是否执行完了 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return this.invokeJoinpoint(); &#125; else &#123;//获取下一个要执行的拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex);//执行拦截器方法 if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher)interceptorOrInterceptionAdvice; return dm.methodMatcher.matches(this.method, this.targetClass, this.arguments) ? dm.interceptor.invoke(this) : this.proceed(); &#125; else &#123; return ((MethodInterceptor)interceptorOrInterceptionAdvice).invoke(this); &#125; &#125; &#125; 通过上面的方式，就实现了JDK动态代理的AOP，主要工作就是创建拦截器链，并使用ReflectiveMethodInvocation对象的proceed方法实现拦截器的调用，对目标方法进行前置/后置的增强. CGLIB实现AOP12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 public Object getProxy(ClassLoader classLoader) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Creating CGLIB proxy: target source is &quot; + this.advised.getTargetSource()); &#125; try &#123;//获取需要代理的目标类 Class&lt;?&gt; rootClass = this.advised.getTargetClass(); Assert.state(rootClass != null, &quot;Target class must be available for creating a CGLIB proxy&quot;); Class&lt;?&gt; proxySuperClass = rootClass; int x; if (ClassUtils.isCglibProxyClass(rootClass)) &#123; proxySuperClass = rootClass.getSuperclass(); Class&lt;?&gt;[] additionalInterfaces = rootClass.getInterfaces(); Class[] var5 = additionalInterfaces; int var6 = additionalInterfaces.length; for(x = 0; x &lt; var6; ++x) &#123; Class&lt;?&gt; additionalInterface = var5[x]; this.advised.addInterface(additionalInterface); &#125; &#125;//验证代理类 this.validateClassIfNecessary(proxySuperClass, classLoader);//配置Enhancer对代理类进行增强 Enhancer enhancer = this.createEnhancer(); if (classLoader != null) &#123; enhancer.setClassLoader(classLoader); if (classLoader instanceof SmartClassLoader &amp;&amp; ((SmartClassLoader)classLoader).isClassReloadable(proxySuperClass)) &#123; enhancer.setUseCache(false); &#125; &#125; enhancer.setSuperclass(proxySuperClass); enhancer.setInterfaces(AopProxyUtils.completeProxiedInterfaces(this.advised)); enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE); enhancer.setStrategy(new CglibAopProxy.ClassLoaderAwareUndeclaredThrowableStrategy(classLoader));//设置拦截器 Callback[] callbacks = this.getCallbacks(rootClass); Class&lt;?&gt;[] types = new Class[callbacks.length]; for(x = 0; x &lt; types.length; ++x) &#123; types[x] = callbacks[x].getClass(); &#125; enhancer.setCallbackFilter(new CglibAopProxy.ProxyCallbackFilter(this.advised.getConfigurationOnlyCopy(), this.fixedInterceptorMap, this.fixedInterceptorOffset)); enhancer.setCallbackTypes(types);//生成代理并返回 return this.createProxyClassAndInstance(enhancer, callbacks); &#125; catch (CodeGenerationException var9) &#123; throw new AopConfigException(&quot;Could not generate CGLIB subclass of class [&quot; + this.advised.getTargetClass() + &quot;]: Common causes of this problem include using a final class or a non-visible class&quot;, var9); &#125; catch (IllegalArgumentException var10) &#123; throw new AopConfigException(&quot;Could not generate CGLIB subclass of class [&quot; + this.advised.getTargetClass() + &quot;]: Common causes of this problem include using a final class or a non-visible class&quot;, var10); &#125; catch (Throwable var11) &#123; throw new AopConfigException(&quot;Unexpected AOP exception&quot;, var11); &#125; &#125; CGLIB中的callback拦截器作用相当于JDK动态代理中的ReflectiveMethodInvocation，我们看一下两者的区别 1234567891011121314151617181920212223242526272829303132333435363738 private Callback[] getCallbacks(Class&lt;?&gt; rootClass) throws Exception &#123; boolean exposeProxy = this.advised.isExposeProxy(); boolean isFrozen = this.advised.isFrozen(); boolean isStatic = this.advised.getTargetSource().isStatic();//从名字就可以看出来，将拦截器封装在DynamicAdvisedInterceptor中 Callback aopInterceptor = new CglibAopProxy.DynamicAdvisedInterceptor(this.advised); Object targetInterceptor; if (exposeProxy) &#123; targetInterceptor = isStatic ? new CglibAopProxy.StaticUnadvisedExposedInterceptor(this.advised.getTargetSource().getTarget()) : new CglibAopProxy.DynamicUnadvisedExposedInterceptor(this.advised.getTargetSource()); &#125; else &#123; targetInterceptor = isStatic ? new CglibAopProxy.StaticUnadvisedInterceptor(this.advised.getTargetSource().getTarget()) : new CglibAopProxy.DynamicUnadvisedInterceptor(this.advised.getTargetSource()); &#125; Callback targetDispatcher = (Callback)(isStatic ? new CglibAopProxy.StaticDispatcher(this.advised.getTargetSource().getTarget()) : new CglibAopProxy.SerializableNoOp()); //将拦截器链加入callback Callback[] mainCallbacks = new Callback[]&#123;aopInterceptor, (Callback)targetInterceptor, new CglibAopProxy.SerializableNoOp(), targetDispatcher, this.advisedDispatcher, new CglibAopProxy.EqualsInterceptor(this.advised), new CglibAopProxy.HashCodeInterceptor(this.advised)&#125;; Callback[] callbacks; if (isStatic &amp;&amp; isFrozen) &#123; Method[] methods = rootClass.getMethods(); Callback[] fixedCallbacks = new Callback[methods.length]; this.fixedInterceptorMap = new HashMap(methods.length); for(int x = 0; x &lt; methods.length; ++x) &#123; List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(methods[x], rootClass); fixedCallbacks[x] = new CglibAopProxy.FixedChainStaticTargetInterceptor(chain, this.advised.getTargetSource().getTarget(), this.advised.getTargetClass()); this.fixedInterceptorMap.put(methods[x].toString(), x); &#125; callbacks = new Callback[mainCallbacks.length + fixedCallbacks.length]; System.arraycopy(mainCallbacks, 0, callbacks, 0, mainCallbacks.length); System.arraycopy(fixedCallbacks, 0, callbacks, mainCallbacks.length, fixedCallbacks.length); this.fixedInterceptorOffset = mainCallbacks.length; &#125; else &#123; callbacks = mainCallbacks; &#125; return callbacks; &#125; CGLIB中的DynamicAdvisedInterceptor拦截器，通过实现MethodInterceptor接口的intercept方法来完成 1234567891011121314151617181920212223242526272829303132333435363738394041424344public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; Class&lt;?&gt; targetClass = null; Object target = null; Object var15; try &#123; if (this.advised.exposeProxy) &#123; oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; target = this.getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125;//获取拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);//拦截器链为空，执行原方法 retVal = methodProxy.invoke(target, argsToUse); &#125; else &#123;//否则执行代理方法 retVal = (new CglibAopProxy.CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy)).proceed(); &#125; retVal = CglibAopProxy.processReturnType(proxy, target, method, retVal); var15 = retVal; &#125; finally &#123; if (target != null) &#123; this.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; return var15; &#125; JDK动态代理与CGLIB的实现方式虽然不同，但是思想确实相通的。都是通过封装拦截器链，对原有方法进行拦截调用。 拦截器链我们回过头来看main函数 123proxyFactoryBean.addAdvice(before);proxyFactoryBean.addAdvice(after);proxyFactoryBean.addAdvice(around); 各种Advice本质上来说都是一个拦截器,在Spring的底层，会把我们定义的各个Adivce分别包裹成一个MethodInterceptor,这些Advice按照加入Advised顺序，构成一个AdvisorChain,也就是拦截器链。 方法请求会依次穿过这些拦截器，调用拦截器中的方法后就会放行(proceed)。]]></content>
      <categories>
        <category>spring4</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring4.3.x源码阅读笔记-XML配置文件解析(2)]]></title>
    <url>%2F2017%2F12%2F18%2Fspring4-3-x%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-XML%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90-2%2F</url>
    <content type="text"><![CDATA[验证XML12345678910&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd&quot;&gt; 我们在编写spring.xml文件时都会在头部加入这样一段代码，这段代码就是通过xsd模式验证XML文件结构的正确性。另一种验证方法就是DTD模式验证，不过现在很少使用了。读取XML之前，spring会验证XML文件内的标签是否符合要求，符合要求才会进行下一步。XML的错误验证，一般在编译器就可以发现。 获取Document对象XML通过验证后，spring会读取配置文件，读取的过程XML会转化为InputSream对象，并最终转换为一个Document对象 解析BeanDefinations将配置文件转换为Document对象后，主要的工作就是提取并注册Document对象中的Bean。可以通过一段代码看看Document提取Bean的过程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107 public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; //初始化一个Reader BeanDefinitionDocumentReader documentReader = this.createBeanDefinitionDocumentReader(); //统计已经注册的bean的个数 int countBefore = this.getRegistry().getBeanDefinitionCount(); //加载及注册bean documentReader.registerBeanDefinitions(doc, this.createReaderContext(resource)); //记录本次加载bean的个数 return this.getRegistry().getBeanDefinitionCount() - countBefore; &#125; public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; this.logger.debug(&quot;Loading bean definitions&quot;); Element root = doc.getDocumentElement(); this.doRegisterBeanDefinitions(root); &#125; protected void doRegisterBeanDefinitions(Element root) &#123; BeanDefinitionParserDelegate parent = this.delegate; this.delegate = this.createDelegate(this.getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) &#123; //profile属性可以在web.xml中配置，用于切换开发环境或者生产环境 String profileSpec = root.getAttribute(&quot;profile&quot;); if (StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, &quot;,; &quot;); if (!this.getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (this.logger.isInfoEnabled()) &#123; this.logger.info(&quot;Skipped XML bean definition file due to specified profiles [&quot; + profileSpec + &quot;] not matching: &quot; + this.getReaderContext().getResource()); &#125; return; &#125; &#125; &#125;//预处理，方法为空，为扩展而设计 this.preProcessXml(root); //解析bean this.parseBeanDefinitions(root, this.delegate); //后处理，方法为空，为扩展而设计 this.postProcessXml(root); this.delegate = parent; &#125; protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for(int i = 0; i &lt; nl.getLength(); ++i) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element)node; //将要解析的bean分为两类，一类是默认标签的解析 if (delegate.isDefaultNamespace(ele)) &#123; this.parseDefaultElement(ele, delegate); &#125; else &#123; //自定义标签的解析 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125; &#125; //默认标签解析 //功能很清楚，可以对四种默认标签进行解析:import，alias，bean，beans //import 功能是可以将一个spring配置文件拆分成多个，同个import合并在一起，有利于功能的划分。 //alias可以指定一个bean的别名 //beans 嵌套进行解析就可以了 //bean 解析的主角，最为复杂 private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; if (delegate.nodeNameEquals(ele, &quot;import&quot;)) &#123; this.importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, &quot;alias&quot;)) &#123; this.processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, &quot;bean&quot;)) &#123; this.processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, &quot;beans&quot;)) &#123; this.doRegisterBeanDefinitions(ele); &#125; &#125; protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; //这个方法让bdHolder包含配置文件的各种属性 BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; //如果有自定义的属性，对其进行解析 bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; //对bdHolder进行注册 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, this.getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException var5) &#123; this.getReaderContext().error(&quot;Failed to register bean definition with name &apos;&quot; + bdHolder.getBeanName() + &quot;&apos;&quot;, ele, var5); &#125;//发出响应事件，通知相关监听器，bean加载完成 this.getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125; &#125; 可以发现spring的源码每个方法的分工都非常明确，层层嵌套非常深入。首先要明确BeanDefination的继承关系，BeanDefination只是一个接口，抽象类AbstractBeanDefination实现了这个接口，并且有三个具体的实现类继承自这个抽象类。继续来看最后这个方法的内部实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean) &#123;//获取ID属性 String id = ele.getAttribute(&quot;id&quot;);//解析name属性 String nameAttr = ele.getAttribute(&quot;name&quot;);//解析alias属性 List&lt;String&gt; aliases = new ArrayList(); if (StringUtils.hasLength(nameAttr)) &#123; String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, &quot;,; &quot;); aliases.addAll(Arrays.asList(nameArr)); &#125; String beanName = id; if (!StringUtils.hasText(id) &amp;&amp; !aliases.isEmpty()) &#123; beanName = (String)aliases.remove(0); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;No XML &apos;id&apos; specified - using &apos;&quot; + beanName + &quot;&apos; as bean name and &quot; + aliases + &quot; as aliases&quot;); &#125; &#125; if (containingBean == null) &#123; this.checkNameUniqueness(beanName, aliases, ele); &#125;//关键方法 其他标签的信息的封装 AbstractBeanDefinition beanDefinition = this.parseBeanDefinitionElement(ele, beanName, containingBean); if (beanDefinition != null) &#123; if (!StringUtils.hasText(beanName)) &#123; try &#123; if (containingBean != null) &#123;//如果bean解析成功，但没有name属性，则生成一个name beanName = BeanDefinitionReaderUtils.generateBeanName(beanDefinition, this.readerContext.getRegistry(), true); &#125; else &#123; beanName = this.readerContext.generateBeanName(beanDefinition); String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp; beanName.startsWith(beanClassName) &amp;&amp; beanName.length() &gt; beanClassName.length() &amp;&amp; !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) &#123; aliases.add(beanClassName); &#125; &#125; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Neither XML &apos;id&apos; nor &apos;name&apos; specified - using generated bean name [&quot; + beanName + &quot;]&quot;); &#125; &#125; catch (Exception var9) &#123; this.error(var9.getMessage(), ele); return null; &#125; &#125; String[] aliasesArray = StringUtils.toStringArray(aliases); return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); &#125; else &#123; return null; &#125; &#125; //其他标签信息的封装方法 public AbstractBeanDefinition parseBeanDefinitionElement(Element ele, String beanName, BeanDefinition containingBean) &#123; this.parseState.push(new BeanEntry(beanName)); String className = null; if (ele.hasAttribute(&quot;class&quot;)) &#123; className = ele.getAttribute(&quot;class&quot;).trim(); &#125; try &#123; String parent = null;//解析parent属性 if (ele.hasAttribute(&quot;parent&quot;)) &#123; parent = ele.getAttribute(&quot;parent&quot;); &#125; AbstractBeanDefinition bd = this.createBeanDefinition(className, parent);//解析默认bean的各种属性 this.parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); bd.setDescription(DomUtils.getChildElementValueByTagName(ele, &quot;description&quot;));//解析meta标签 this.parseMetaElements(ele, bd);//解析lookup-method标签 this.parseLookupOverrideSubElements(ele, bd.getMethodOverrides());//解析replace-method标签 this.parseReplacedMethodSubElements(ele, bd.getMethodOverrides());//解析构造函数标签 this.parseConstructorArgElements(ele, bd);//解析property标签 this.parsePropertyElements(ele, bd);//解析Qualifier标签 this.parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(this.extractSource(ele)); AbstractBeanDefinition var7 = bd; return var7; &#125; catch (ClassNotFoundException var13) &#123; this.error(&quot;Bean class [&quot; + className + &quot;] not found&quot;, ele, var13); &#125; catch (NoClassDefFoundError var14) &#123; this.error(&quot;Class that bean class [&quot; + className + &quot;] depends on not found&quot;, ele, var14); &#125; catch (Throwable var15) &#123; this.error(&quot;Unexpected failure during bean definition parsing&quot;, ele, var15); &#125; finally &#123; this.parseState.pop(); &#125; return null; &#125; //解析默认bean的属性，通过字符串就可以看出在解析哪些属性，不做注释 public AbstractBeanDefinition parseBeanDefinitionAttributes(Element ele, String beanName, BeanDefinition containingBean, AbstractBeanDefinition bd) &#123; if (ele.hasAttribute(&quot;singleton&quot;)) &#123; this.error(&quot;Old 1.x &apos;singleton&apos; attribute in use - upgrade to &apos;scope&apos; declaration&quot;, ele); &#125; else if (ele.hasAttribute(&quot;scope&quot;)) &#123; bd.setScope(ele.getAttribute(&quot;scope&quot;)); &#125; else if (containingBean != null) &#123; bd.setScope(containingBean.getScope()); &#125; if (ele.hasAttribute(&quot;abstract&quot;)) &#123; bd.setAbstract(&quot;true&quot;.equals(ele.getAttribute(&quot;abstract&quot;))); &#125; String lazyInit = ele.getAttribute(&quot;lazy-init&quot;); if (&quot;default&quot;.equals(lazyInit)) &#123; lazyInit = this.defaults.getLazyInit(); &#125; bd.setLazyInit(&quot;true&quot;.equals(lazyInit)); String autowire = ele.getAttribute(&quot;autowire&quot;); bd.setAutowireMode(this.getAutowireMode(autowire)); String dependencyCheck = ele.getAttribute(&quot;dependency-check&quot;); bd.setDependencyCheck(this.getDependencyCheck(dependencyCheck)); String autowireCandidate; if (ele.hasAttribute(&quot;depends-on&quot;)) &#123; autowireCandidate = ele.getAttribute(&quot;depends-on&quot;); bd.setDependsOn(StringUtils.tokenizeToStringArray(autowireCandidate, &quot;,; &quot;)); &#125; autowireCandidate = ele.getAttribute(&quot;autowire-candidate&quot;); String destroyMethodName; if (!&quot;&quot;.equals(autowireCandidate) &amp;&amp; !&quot;default&quot;.equals(autowireCandidate)) &#123; bd.setAutowireCandidate(&quot;true&quot;.equals(autowireCandidate)); &#125; else &#123; destroyMethodName = this.defaults.getAutowireCandidates(); if (destroyMethodName != null) &#123; String[] patterns = StringUtils.commaDelimitedListToStringArray(destroyMethodName); bd.setAutowireCandidate(PatternMatchUtils.simpleMatch(patterns, beanName)); &#125; &#125; if (ele.hasAttribute(&quot;primary&quot;)) &#123; bd.setPrimary(&quot;true&quot;.equals(ele.getAttribute(&quot;primary&quot;))); &#125; if (ele.hasAttribute(&quot;init-method&quot;)) &#123; destroyMethodName = ele.getAttribute(&quot;init-method&quot;); if (!&quot;&quot;.equals(destroyMethodName)) &#123; bd.setInitMethodName(destroyMethodName); &#125; &#125; else if (this.defaults.getInitMethod() != null) &#123; bd.setInitMethodName(this.defaults.getInitMethod()); bd.setEnforceInitMethod(false); &#125; if (ele.hasAttribute(&quot;destroy-method&quot;)) &#123; destroyMethodName = ele.getAttribute(&quot;destroy-method&quot;); bd.setDestroyMethodName(destroyMethodName); &#125; else if (this.defaults.getDestroyMethod() != null) &#123; bd.setDestroyMethodName(this.defaults.getDestroyMethod()); bd.setEnforceDestroyMethod(false); &#125; if (ele.hasAttribute(&quot;factory-method&quot;)) &#123; bd.setFactoryMethodName(ele.getAttribute(&quot;factory-method&quot;)); &#125; if (ele.hasAttribute(&quot;factory-bean&quot;)) &#123; bd.setFactoryBeanName(ele.getAttribute(&quot;factory-bean&quot;)); &#125; return bd; &#125; 至此，我们就解析了Bean标签所有的属性。再让我们回顾一下那个最初的入口方法： 123456789101112131415161718 protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; //这个方法让bdHolder包含配置文件的各种属性 BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; //如果有自定义的属性，对其进行解析 bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; //对bdHolder进行注册 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, this.getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException var5) &#123; this.getReaderContext().error(&quot;Failed to register bean definition with name &apos;&quot; + bdHolder.getBeanName() + &quot;&apos;&quot;, ele, var5); &#125;//发出响应事件，通知相关监听器，bean加载完成 this.getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125; &#125; 此时完成了第一行代码的工作，如果有需要会进入装饰bean方法，由于工作中没有使用过自定义的bean属性需要装饰，所以到下一行代码，对hdHolder进行注册。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384 public static void registerBeanDefinition(BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; String beanName = definitionHolder.getBeanName(); //根据bean name属性进行注册 registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; String[] var4 = aliases; int var5 = aliases.length; for(int var6 = 0; var6 &lt; var5; ++var6) &#123; String alias = var4[var6]; //注册所有别名 registry.registerAlias(beanName, alias); &#125; &#125; &#125; public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; Assert.hasText(beanName, &quot;Bean name must not be empty&quot;); Assert.notNull(beanDefinition, &quot;BeanDefinition must not be null&quot;); if (beanDefinition instanceof AbstractBeanDefinition) &#123; try &#123;//对BeanDefination的一些属性进行校验 ((AbstractBeanDefinition)beanDefinition).validate(); &#125; catch (BeanDefinitionValidationException var9) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, &quot;Validation of bean definition failed&quot;, var9); &#125; &#125;//检查这个bean是否已经被注册 BeanDefinition oldBeanDefinition = (BeanDefinition)this.beanDefinitionMap.get(beanName); if (oldBeanDefinition != null) &#123; if (!this.isAllowBeanDefinitionOverriding()) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, &quot;Cannot register bean definition [&quot; + beanDefinition + &quot;] for bean &apos;&quot; + beanName + &quot;&apos;: There is already [&quot; + oldBeanDefinition + &quot;] bound.&quot;); &#125; if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) &#123; if (this.logger.isWarnEnabled()) &#123; this.logger.warn(&quot;Overriding user-defined bean definition for bean &apos;&quot; + beanName + &quot;&apos; with a framework-generated bean definition: replacing [&quot; + oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;); &#125; &#125; else if (!beanDefinition.equals(oldBeanDefinition)) &#123; if (this.logger.isInfoEnabled()) &#123; this.logger.info(&quot;Overriding bean definition for bean &apos;&quot; + beanName + &quot;&apos; with a different definition: replacing [&quot; + oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;); &#125; &#125; else if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Overriding bean definition for bean &apos;&quot; + beanName + &quot;&apos; with an equivalent definition: replacing [&quot; + oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;); &#125;//这里因为是存在相同beanName的情况//将bean覆盖到beanDefinitionMap，这是一个ConcurrentHashMap，Key是beanName，value就是beanDefination this.beanDefinitionMap.put(beanName, beanDefinition); &#125; else &#123; if (this.hasBeanCreationStarted()) &#123; Map var4 = this.beanDefinitionMap;//这里是bean不存在的情况，控制并发访问，将bean放入Map中 synchronized(this.beanDefinitionMap) &#123; this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String&gt; updatedDefinitions = new ArrayList(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) &#123; Set&lt;String&gt; updatedSingletons = new LinkedHashSet(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; &#125; &#125; &#125; else &#123; this.beanDefinitionMap.put(beanName, beanDefinition); this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName); &#125; this.frozenBeanDefinitionNames = null; &#125; if (oldBeanDefinition != null || this.containsSingleton(beanName)) &#123; //重置所以beanName的缓存 this.resetBeanDefinition(beanName); &#125; &#125; 到此就完成了bean的注册。这部分只是对spring默认标签的解析过程，自定义解析的过程的方法并不相同，但思想都大同小异。通过这部分代码，就可以对spring中xml文件解析出bean到内存中这个过程做到心中有数，后面要做的就是bean的加载。 总结 参考《Spring源码深度解析》]]></content>
      <categories>
        <category>spring4</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring4.3.x源码阅读笔记-从hello world开始(1)]]></title>
    <url>%2F2017%2F12%2F18%2Fspring4-3-x%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[环境:Spring4.3.5、IDEA 网络上很多对spring源码讲解的博客基本上使用的都是spring3的版本，跟着做了一下发现最开始的XMLBeanFactory类已经废弃了，spring4中使用最频繁的是ClassPathXmlApplicationContext,所以自己也打打断点看代码，看看有什么变化。 准备基于maven的spring4.3项目，创建一个User类，给一个简单的构造函数。在classpath下新建一个spring的xml文件，配置User Bean。最后创建一个类，在主方法中获取类的信息，观察调用栈。 1234567891011121314151617181920212223242526272829303132333435361.public class User &#123; private int id; private String email; private String password; private String username; private String role; private int status; private Date regTime; public User()&#123; &#125; public User(String username)&#123; this.username = username; &#125; //get/set省略&#125;2. &lt;bean class=&quot;com.sc.model.User&quot; id=&quot;user&quot;&gt; &lt;constructor-arg value=&quot;hello world&quot;/&gt; &lt;/bean&gt;3. public class Start &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;spring-mybatis.xml&quot;); User user = (User) applicationContext.getBean(&quot;user&quot;); System.out.println(user.getUsername()); &#125;&#125; 这段代码正确的结果会打印出:hello world ###ApplicationContext 123456789public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; refresh(); &#125;&#125; 这个方法就是我们测试代码的第一行的源码，和spring3的内容一样，首先支持以数组的方式设置spring配置文件，也就是支持读取多个spirng的配置文件。重要的还是refresh方法: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // 准备上下文的刷新，实际上只记录了启动时间， //方法initPropertySources和validateRequiredProperties方法都是空的，可以留给用户自己扩展 prepareRefresh(); //初始化BeanFactory,并进行xml文件的读取，完成了配置文件的解析,这里就是spring3中的XmlBeanFactory方法， //也就是说ApplicationContext 是对XmlBeanFactory的一种增强，所以在spring4中废弃了XmlBeanFactory //这里实际上进行了很多的操作，再后面细说 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); //对BeanFactory功能进行填充: //1.增加对SPEL的支持:如#&#123;&#125; //2.增加对属性编辑的支持:对日期属性注入的支持 //3.设置了可忽略的接口 //4.注册一些固定的依赖 //5.增加对AspectJ支持 //6.将相关环境变量以及属性注册以单例模式支持 prepareBeanFactory(beanFactory); try &#123; //下面三步都是对beanFacotry进行加载后处理 //可以通过编写类实现BeanFactoryPostProcessor对配置文件中的bean进行拦截修改 postProcessBeanFactory(beanFactory); invokeBeanFactoryPostProcessors(beanFactory); registerBeanPostProcessors(beanFactory); // i18n处理 initMessageSource(); //初始化事件广播 //1.如果用户自己定义，就用用户的 //2.否则就使用默认的事件广播 //用于存放监听器并在合适的时候调用监听器 initApplicationEventMulticaster(); // 空方法，留给子类扩展 onRefresh(); // 注册监听器到广播器 registerListeners(); //完成beanFactory的初始化，主要是非lazy-init属性的bean进行提前实例化 finishBeanFactoryInitialization(beanFactory); //完成刷新,初始化lifeCycleProcessor管理bean的生命周期 //激活监听器 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &apos;active&apos; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&apos;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125; &#125; 通过一个refresh方法，完成了BeanFactory的实例化，剩下的就是通过get方法获取到bean就可以得到bean的属性信息。但是这个方法只能让我们大概了解BeanFactory的过程，其中还有很多具体的细节要分析。 容器基础：BeanFacoty通过测试类方法的第一行代码，返回一个ApplicationContext对象。我们在refresh方法中，大部分操作都是围绕BeanFactory这个对象来进行的，下面的图给出了ApplicationContext和BeanFactory的关系。 接着看测试类的第二行代码，是一个getBean方法，其实现方法如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130 protected &lt;T&gt; T doGetBean(String name, Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = this.transformedBeanName(name); Object sharedInstance = this.getSingleton(beanName); Object bean; //检查是否已经创建了bean if (sharedInstance != null &amp;&amp; args == null) &#123; if (this.logger.isDebugEnabled()) &#123; if (this.isSingletonCurrentlyInCreation(beanName)) &#123; this.logger.debug(&quot;Returning eagerly cached instance of singleton bean &apos;&quot; + beanName + &quot;&apos; that is not fully initialized yet - a consequence of a circular reference&quot;); &#125; else &#123; this.logger.debug(&quot;Returning cached instance of singleton bean &apos;&quot; + beanName + &quot;&apos;&quot;); &#125; &#125; bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, (RootBeanDefinition)null); &#125; else &#123; if (this.isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; //若当前BeanFactory没有此bean，到父容器中查找 BeanFactory parentBeanFactory = this.getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !this.containsBeanDefinition(beanName)) &#123; String nameToLookup = this.originalBeanName(name); if (args != null) &#123; return parentBeanFactory.getBean(nameToLookup, args); &#125; return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; if (!typeCheckOnly) &#123; this.markBeanAsCreated(beanName); &#125; try &#123; //获取BeanDefination final RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); this.checkMergedBeanDefinition(mbd, beanName, args); //查看初始化依赖的bean String[] dependsOn = mbd.getDependsOn(); String[] var11; if (dependsOn != null) &#123; var11 = dependsOn; int var12 = dependsOn.length; for(int var13 = 0; var13 &lt; var12; ++var13) &#123; String dep = var11[var13]; if (this.isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Circular depends-on relationship between &apos;&quot; + beanName + &quot;&apos; and &apos;&quot; + dep + &quot;&apos;&quot;); &#125; this.registerDependentBean(dep, beanName); this.getBean(dep); &#125; &#125; //创建单例模式bean if (mbd.isSingleton()) &#123; sharedInstance = this.getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; public Object getObject() throws BeansException &#123; try &#123; return AbstractBeanFactory.this.createBean(beanName, mbd, args); &#125; catch (BeansException var2) &#123; AbstractBeanFactory.this.destroySingleton(beanName); throw var2; &#125; &#125; &#125;); bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, mbd); //创建原型bean &#125; else if (mbd.isPrototype()) &#123; var11 = null; Object prototypeInstance; try &#123; this.beforePrototypeCreation(beanName); prototypeInstance = this.createBean(beanName, mbd, args); &#125; finally &#123; this.afterPrototypeCreation(beanName); &#125; bean = this.getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); //否则创建其他scope类型的bean,如request session gloable-session &#125; else &#123; String scopeName = mbd.getScope(); Scope scope = (Scope)this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(&quot;No Scope registered for scope name &apos;&quot; + scopeName + &quot;&apos;&quot;); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; public Object getObject() throws BeansException &#123; AbstractBeanFactory.this.beforePrototypeCreation(beanName); Object var1; try &#123; var1 = AbstractBeanFactory.this.createBean(beanName, mbd, args); &#125; finally &#123; AbstractBeanFactory.this.afterPrototypeCreation(beanName); &#125; return var1; &#125; &#125;); bean = this.getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException var21) &#123; throw new BeanCreationException(beanName, &quot;Scope &apos;&quot; + scopeName + &quot;&apos; is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;, var21); &#125; &#125; &#125; catch (BeansException var23) &#123; this.cleanupAfterBeanCreationFailure(beanName); throw var23; &#125; &#125;//创建之后，如果有需要就进行类型转换 if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isAssignableFrom(bean.getClass())) &#123; try &#123; return this.getTypeConverter().convertIfNecessary(bean, requiredType); &#125; catch (TypeMismatchException var22) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Failed to convert bean &apos;&quot; + name + &quot;&apos; to required type &apos;&quot; + ClassUtils.getQualifiedName(requiredType) + &quot;&apos;&quot;, var22); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; else &#123; //否则，直接返回bean return bean; &#125; &#125; 这段代码虽然很长，但是条例非常清楚，非常佩服代码的作者，在变量命名、方法的封装上都值得学习。经过此方法，就获得了指定的bean，然后可以再测试类中强转为pojo，然后调用pojo的get方法就可以获得属性信息了。 参考《Spring源码深度解析》]]></content>
      <categories>
        <category>spring4</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-ConcurrentHashMap(6)]]></title>
    <url>%2F2017%2F12%2F17%2Fjava%E5%B9%B6%E5%8F%91%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%B4%A9%E6%BA%83-ConcurrentHashMap-6%2F</url>
    <content type="text"><![CDATA[无论是HashMap还是ConcurrentHashMap都是日常使用和面试中的热点问题，所以必须整理一波。而且java8中对于HashMap的改动还是相当大的。 HashMapHashMap的结构是由数组+链表+红黑树组成的 HashMap的主体是一个Node[]，也就是一个Node数组，图中每个蓝色的球就是一个Node，Node的结构就是一个键值对:Node。顾名思义，HashMap通过hash算法将键值对映射到一个位置，那么具体怎么做呢。 定位1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; hashMap的hash方法并没有我们想象的那么简单。并不是只经过一次hashcode计算，而是把hashcode再与hashcode的高16位进行一次抑或运算。这个如果大家把这个过程自己写一下就发现，这样做这个HashMap里面的元素的位置会尽量分布均匀。 put方法123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; put和get是Hashmap最常用的操作了，JAVA8对hashmap进行了优化，最主要的一点就是当链表的长度大于等于8时，链表就会变成一个红黑树来提高效率。我们看一下代码思路:①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； ③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 摘自https://tech.meituan.com/java-hashmap.html resize我们知道当hashmap的键值对个数增加的时候，hashmap会自动进行扩容。什么时候扩容当然我们是可以控制的，就是通过hashmap的构造函数:initSize和loadFactor,默认构造参数初始大小为16，负载因子为0.75。也就是当Node个数超过16*0.75=12个的时候就会自动扩容，扩容的大小是当前大小的一倍。这里要主要，resize的时候是键值对的数量超过12，而不是数组中的node个数超过12。这里扩容后会对原HashMap中的元素重新hash，但是效率很高，因为直接扩大二倍，所以原有node的位置要么不变，要么当前位置+扩容大小，复杂度为O(1)。 通过get方法我们知道，当链表长度&gt;=8会变成一个红黑树。java8之前,在最极端的情况下,对链表的查询复杂度是O(n),而红黑树则降低到了O(logn)，大大提高了put和get的效率。 那么当链表长度减少时，红黑树会怎么变化呢。Hashmap也有默认参数，当红黑树中元素的个数&lt;=6，红黑树恢复为链表状态。 非线程安全说道hashmap总会说道线程安全这个问题，因为在hashmap的get、put方法中并没有对操作进行加锁处理。另一方面，当并发对hashmap进行修改，触发hashMap的resize方法，如果多个线程同时检测到元素个数超过数组大小*loadFactor，这样就会发生多个线程同时对Node数组进行扩容，都在重新计算元素位置以及复制数据，但是最终只有一个线程扩容后的数组会赋给table，也就是说其他线程的都会丢失，并且各自线程put的数据也丢失。 trick应尽量减少resize操作，所以在可以预计hashMap大小的情况小，应该给hashmap一个初始值，防止频繁的resize，对于负载因子，应当尽量少的改动。 ConcurrentHashMapjava8对concurrentHashMap也做了较大的修改，放弃了之前的段锁概念(segment lock)而改用更加高效的CAS操作实现并发hashmap。与HashMap相同的是ConcurrentHashMap的结构也是数组+链表+红黑树,有一个最重要的不同点就是ConcurrentHashMap不允许key或value为null值。CAS需要一个状态标识符，源码中使用了sizeCtrl 123456private transient volatile int sizeCtl;1. 负数代表正在进行初始化或扩容操作2. -1代表正在初始化3. -N 表示有N-1个线程正在进行扩容操作4. 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小 我们还是从get/put/resize的方法中关注ConcurrentHashMap如何保证线程安全 put方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public V put(K key, V value) &#123; return putVal(key, value, false);&#125;/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) ①tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (②casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; ③else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 首先可以看到在put方法中，如果table为null,首先会初始化这个map，代码如下 12345678910111213141516171819202122private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab; &#125; 代码比较短，首先会判断sizeCtl&gt;&gt;2)，表示n减去n右移2位，也就是n-n1/21/2 = 0.75n,所以这里和HashMap中的负载因子和容量大小是对应的。继续回到put方法的②: 1234static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125; 在这里，如果没有发生碰撞，使用CAS的方式对该位置赋值，会比较内存中的值与你指定的这个值是否相等，如果相等才接受你的修改，否则拒绝你的修改。 如果该节点发生碰撞，则继续③:检查是否处于扩容状态，如果是则调用helptransfer方法帮助扩容,首先拿到这个nextTable对象，调用transfer方法。 12345678910111213141516171819final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table; &#125; ConcurrentHashMap的扩容是允许多线程进行的，当一个线程发现当前的Table正在被扩容，它也会参与进来，帮助进行扩容操作。如果没有在进行扩容操作，会继续进入一个sychronized代码块，在这一部分，会判断是链表节点还是红黑树节点，并对其进行赋值，这点与Hashmap一致。跳出循环后会检验链表长度是不是超过了阈值，需要进行结构转换。 最后一句代码调用了addCount函数:以CAS的方式把当前ConcurrentHashMap的元素个数+1,更新baseCount的值，检测是否进行扩容。 transfor扩容方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; ①int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); ②boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; ③while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; ④if (finishing) &#123; nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; ⑤if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; ⑥else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); ⑦else if ((fh = f.hash) == MOVED) advance = true; // already processed ⑧else &#123; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123; int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 我们在上面put操作的时候就可以看出来，transfer扩容方法是支持并发的，虽然思想和Hashmap中的差不多，但是具体操作起来就复杂了很多。 参考http://blog.csdn.net/u010723709/article/details/48007881 首先在①处，初始化了一个新的table长度为原有table长度的两倍。接着又new 了一个ForwardingNode。这个类用于连接两个table的节点类，它包含一个nextTable指针，用于指向下一张表。而且这个节点的key value next指针全部为null，它的hash值为-1. 这里面定义的find的方法是从nextTable里进行查询节点，而不是以自身为头节点进行查找。②处初始化了一个advance变量，此变量是并发扩容的关键属性，如果等于true，说明这个节点已经处理过。从③开始进入了这个方法的主体，通过i–依次遍历原hash表中的节点。④处在于如果所有的节点都已经完成复制工作，就把nextTable赋值给table，清空临时对象nextTable，若没有完成复制工作，将会继续下面的代码继续复制 ⑤处将sizeCtl-1表示一个新的线程通过helftransfer方法进入transfer方法帮助扩容。 ⑥表示当前节点为空，设置为一个forwad节点，继续向后遍历 ⑦遍历到ForwardingNode节点，说明此节点被处理过了，直接跳过 ⑧该节点可能是链表节点也可能是树节点，进入sychronized代码块中进行复制 如果是链表节点,把链表分表拆分为，hash&amp;n等于0和不等于0的，然后分别放在新表的i和i+n位置,个人认为原博主的配图有误，所以自己分析了一下这里 如果是树节点，与链表的处理方式相同 多线程又是如何实现的呢？ 遍历到ForwardingNode节点((fh = f.hash) == MOVED)，说明此节点被处理过了，直接跳过。这是控制并发扩容的核心。由于给节点上了锁，只允许当前线程完成此节点的操作，处理完毕后，将对应值设为ForwardingNode（fwd），其他线程看到forward，直接向后遍历。如此便完成了多线程的复制工作，也解决了线程安全问题。 concurrentHashMap确实有些复杂的让人窒息，关键性操作的代码真的很长，看下来需要一些耐心，但是我终于大概明白了ConcurrentHashMap的原理，以后还要经常拿来看一看。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-JMM(5)]]></title>
    <url>%2F2017%2F12%2F17%2Fjava%E5%B9%B6%E5%8F%91%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%B4%A9%E6%BA%83-JMM%2F</url>
    <content type="text"><![CDATA[JMM在写这篇博客之前参考了大量的博客和书籍，但是个人总感觉理解不来，在这里记录下自己的看法，可能不对。 在并发编程中，我们要解决的关键性问题就是线程通信和同步的问题——那么就有两种结局方案，共享内存和消息传递。共享内存的方式就是各个线程在一个公共的内存区域中共同读写变量，消息传递则是通过显示的方法交换信息。 所以JAVA对内存进行了一种抽象，形成了java内存模型JMM。这种模型可以说就是为了方便多线程编程而设计。JMM的设计说起来其实很简单，各个线程拥有自己的本地内存，线程之间的共享变量存储在主存中，为了提高效率，各自的本地内存中还保留了一份共享变量的拷贝。本地内存是一个抽象的概念，并不存在，它在物理上覆盖了缓存区，寄存器以及各种优化技术。 因此JAVA中线程之间的通信可以使用以下方式： 一个线程将数据写入到主存中 另一个线程去主存获取这个数据 也就是说线程之间依靠在主存之中共享变量实现了线程之间的通信，虽然说起来这个过程很简单，但我们看的还是太过于宏观，屏蔽了太多底层的东西。因为我们对于多线程的编程都停留在java语言这种高级语言的层面，但是java语言底层会和操作系统、内存、寄存器这些硬件打交道。而这些硬件由于读写速率有很大差别，因此会有一些对编程语言的优化策略，并不是每条指令都是顺序执行的。由于存在这种硬件优化策略，所以java语言就要保证它的多线程编程所得出的结果是程序员所希望的结果，也就是对编程人员的可见性。所以为了保证这种对编程人员的可见性，java并发编程就需要抽象一种既能保证执行结果又能让程序设计人员无需关心底层的内存模型，这就是JMM。 从PIPELINE看JMM学过计算机组成原理或计算机体系结构的同学可能见过这幅图 这就是把一条机器指令分为了五个原子的步骤去执行IF表示取指令，WB表示写回内存。下一条指令会在前一条写回内存后才会执行，这么这个看来就是一个线程安全的模型了。只可惜，现实中的计算机指令流水线并不会这样设计，因为这样的效率实在是太低了。 实际上的流水线是这样的一种模型，在第一个位置空出来后就可以执行第二条了。这样才能最大限度的利用资源。那么为了提高效率，问题也就随之而来了，这样的一种模型就会造成一种数据依赖的情况，有可能第二条指令需要第一条指令的运算结果,出现这种情况最快的优化就是让IF在EX之后执行，通过通道直接获取到EX之后的值，而不必等到写回内存再去内存中调用。其实这种情况分细了来说就是流水线中遇到的WAR,WAW等读写冲突现象。 说完了计组中pipeline的思想，那么我们把JMM作一下类比，我们可以把JMM当做处理pipeline的容器，java代码在编译成字节码之后，为了解决读写冲突也需要设定一系列的机制。这些机制就包括设定内存屏障，happens-before原则，顺序一致性模型等等。如果你知道pipeline对机器指令读写冲突的解决方案，从字面上你就能理解jmm这些机制的作用。 所以知道了以上几种jmm的设计原则之后，就有了volatile的内存语义，lock的内存语义等等。它们讲述这些不同的线程之间通信和同步的方式在jmm中是怎样实现的。其实归根结底就是想解决在经历过种种编译优化之后怎样保持各个线程之间的数据依赖问题。 其实出现这些问题最根本的原因是人们对提升计算机效率的永恒追求，因为追求性能，出现了经典的五层流水线模型。因为追求性能出现了java并发编程。于是在硬件和软件层面都对追求性能而带来的数据冲突问题作出了解决，虽然具体做法不同但思想都是想通的。 这时我又想起了大学老师对我们说过的话：计算机这个东西在硬件和软件方面是相通的，双方的思想都可以拿来互相借鉴，想通了就很简单。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-Lock(4)]]></title>
    <url>%2F2017%2F12%2F13%2Fjava%E5%B9%B6%E5%8F%91%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%B4%A9%E6%BA%83-Lock%2F</url>
    <content type="text"><![CDATA[我们可以先来看看有哪些类实现了Lock接口，有我们很熟悉的ReentrantLock、ReadLock、WriteLock、ConcurrentHashMap中的Segment内部类以及在JAVA8中新加入的StampedLock，接下来一一分析一下这些锁的实现。 ReentrantLock可重入锁也是JUC中的一位元老级的人物了。可重入锁，顾名思义就是就是支持一个线程对资源的重复加锁，此外可重入锁还支持公平或非公平加锁。 ReentrantLock的类结构如图所示，一个内部抽象类Sync继承自AQS，作为一个同步器。NonfairSync和FairSync都继承Sync用于实现不同的加锁方法。ReentrantLock类中的方法都是通过调用内部类的方法实现的加锁与释放。因为AQS是用来构建锁或其他同步器的基本框架。分析ReentrantLock的核心就是加锁的方法，根据代码，公平锁和非公锁都实现各自的Lock和tryAcquire方法 1234567891011121314151617181920212223242526272829303132333435363738394041//非公平锁 static final class NonfairSync extends Sync &#123; final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125;//公平锁 static final class FairSync extends Sync &#123; final void lock() &#123; acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; &#125; 不同的加锁方式假设有一个state变量，初始值为0，假设当前线程为A,每当A获取一次锁，status++. 释放一次，status–.锁会记录当前持有的线程。当A线程拥有锁的时候，status&gt;0. B线程尝试获取锁的时候会对这个status有一个CAS(0,1)的操作，尝试几次失败后就挂起线程，进入一个等待队列。如果A线程恰好释放，–status==0, A线程会去唤醒等待队列中第一个线程，即刚刚进入等待队列的B线程，B线程被唤醒之后回去检查这个status的值，尝试CAS(0,1),而如果这时恰好C线程也尝试去争抢这把锁，C直接尝试对这个status CAS(0,1)操作，并成功改变了status的值，B线程获取锁失败，再次挂起，这就是非公平锁。B在C之前尝试获取锁，而最终是C抢到了锁。 公平锁：C发现有线程在等待队列，直接将自己进入等待队列并挂起,B获取锁。 可重入的实现原理:两个类实现的tryAquire()方法也是不同的。非公平锁由于是可重入锁的默认状态，所以它的tryAquire方法就是父类Sync的方法: 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 通过判断当前线程是否获是取得锁的线程，来决定操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true。公平锁与非公平锁实现此方法的差别就在于hasQueuedPredecessors()方法，该方法表示加入了同步队列的当前节点，是否还有前驱节点，如果返回true，表示它不是头结点，不能取到锁，继续等待，只有等到前驱节点释放的时候它才可以获取锁。 既然重入锁时会增加同步状态值，那么释放锁时就必须将同步状态值减为0才可以算作释放锁。 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 如果锁被获取了n次，那么前n-1次release都会返回false。同步状态值为0时，设置占有线程为null，并返回true，释放锁。 ReentrantReadWriteLock一般我们都会称这个锁为读写锁，从名字也可以看出，读写锁也是支持重入的，默认支持非公平。读写锁的特性为通过分离读锁和写锁，使得并发性有很大的提高。读锁在同一时刻允许多个线程访问，但有写锁线程访问时，所有的读线程和其他写线程都被阻塞。读写锁的结果如图所示: 它的实现同样依赖于Sync自定义同步器，由于读锁和写锁要分开计数，那么在只有一个状态值的情况下怎么计算读写锁的数量呢。由于java跨平台的特性，int类型的状态值始终是32位，于是设计者将状态值的低16位标识写状态，高16位标识读状态，如00..0011 00..0011表示读状态3，写状态3表示重入了三次读锁，重入了三次写锁。我们还是重点关注它的获取锁的代码。 获取写锁12345678910111213141516171819202122232425262728293031321️⃣ public void lock() &#123; sync.acquire(1); &#125;2️⃣ public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125;3️⃣protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; &#125; 首先是WriteLock内部类调用了Sync的acquire方法，acquire方法其实是一个自旋等待的过程。关键在于tryAcquire方法，该方法有一个if判断当前是否有读线程存在，如果存在则不能加写锁，因为读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下加写锁，那读锁程序无法感知到写锁的存在，读出的数据就可能是错的。因此加写锁时读锁必须全部释放，已经获取到写锁是阻塞其他全部线程。 获取读锁123456789101112131415161718192021222324252627protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 这段代码的主要逻辑首先获取了当前读锁的重入次数，当没有写锁在执行并且状态值&lt;MAX_COUNT时以CAS的方式设置状态值，如果没有获取到读锁，就加入到一个链中循环获取。 锁降级读写锁支持对写锁的降级操作，意思是当前线程持有写锁，先获取到读锁，随后释放写锁的过程。分段进行锁的释放则不属于锁降级,记录一段锁降级操作。 12345678910111213141516171819202122232425262728293031323334public void processData()&#123; //读锁获取 readLock.lock(); if(!update)&#123; //必须先释放读锁 readLock.unlock(); //锁降级从获取写锁开始 writeLock.lock(); try &#123; if(!update)&#123; //准备数据流程（略） update=true; &#125; //获取读锁。在写锁持有期间获取读锁 //此处获取读锁，是为了防止，当释放写锁后，又有一个线程T获取锁，对数据进行改变，而当前线程下面对改变的数据无法感知。 //如果获取了读锁，则线程T则被阻塞，直到当前线程释放了读锁，那个T线程才有可能获取写锁。 readLock.lock(); &#125;finally&#123; //释放写锁 writeLock.unlock(); &#125; //锁降级完成 &#125; try &#123; //使用数据的流程 &#125; finally&#123; //释放读锁 readLock.unlock(); &#125; &#125; StampedLock StampedLock是JAVA8中新加入的一种锁,旨在优化ReentrantReadWriteLock在读线程正在进行时会阻塞写线程的持锁。其中心思想是:在读锁存在是不应该一直阻塞写锁，而是应该让写线程写入数据，同时读线程重新读。因为在使用读写锁的场合，大部分的时间都是读线程在读取数据，有可能造成写线程的饥饿(Starvation)。由于现在参考资料较少:还是先翻译一下Doug Lea的注释吧。 StampedLock(标记锁，以下简称SL)具有三种读写模式。SL的状态由一个version和一个mode组成。获取锁的方法会返回一个stamp 获取锁的方法会返回一个stamp， 这个stamp表示和控制锁状态的获取。若返回值为0则表示加锁失败，锁的释放和降级操作需要stamp作为参数，若参数不匹配则返回失败。下面介绍三种读写模式: 写模式writeLock方法会因为独占式访问而阻塞后续进程,该方法返回一个stamp用于在UnlockWrite方法中释放锁。定时和非定时的tryWriteLock方法同样提供这种机制。当写线程持锁，不可以获取读锁，并且所有的乐观读的验证也会失败。 读模式readLock方法会可能会阻塞非独占式的访问，返回一个stamp用于unlockRead方法。计时和非计时的tryReadLock方法同样支持这种机制 乐观读模式tryOptimisticRead方法只有在当前线程没有在写模式下，才会返回一个非零的stamp值。validate方法会返回true，当获取到stamp之后锁没有在写模式下被获取。这种模式可以说是一种非常脆弱的读锁，可以随时被写锁打破。 乐观读锁用在只读代码的片段中可以减少争用并提高吞吐量。但由于这种模式天生脆弱，所以使用的前提是你足够了解它，因为乐观读可能是非连续的。 一个官方的Demo关于乐观锁的部分 :1234567891011121314151617181920212223242526// 乐观读锁（tryOptimisticRead） double distanceFromOrigin() &#123; // 尝试获取乐观读锁（1） long stamp = sl.tryOptimisticRead(); // 将全部变量拷贝到方法体栈内（2） double currentX = x, currentY = y; // 检查在（1）获取到读锁票据后，锁有没被其他写线程排它性抢占（3） if (!sl.validate(stamp)) &#123; // 如果被抢占则获取一个共享读锁（悲观获取）（4） stamp = sl.readLock(); try &#123; // 将全部变量拷贝到方法体栈内（5） currentX = x; currentY = y; &#125; finally &#123; // 释放共享读锁（6） sl.unlockRead(stamp); &#125; &#125; // 返回计算结果（7） return Math.sqrt(currentX * currentX + currentY * currentY); &#125;作者：今天你不奋斗明天你就落后链接：http://www.jianshu.com/p/b3e9539ab7ae 代码（1）首先尝试获取乐观读锁，如果当前没有其它线程获取到了写锁，那么（1）会返回一个非0的stamp用来表示版本信息，代码（2）拷贝变量到本地方法栈里面，代码（3）检查在（1）获取到的票据是否还有效，之所以还要在此校验是因为代码（1）获取读锁时候并没有通过CAS操作修改锁的状态而是简单的通过与或操作返回了一个版本信息，这里校验是看在在获取版本信息到现在的时间段里面是否有其他线程持有了写锁，如果有则之前获取的版本信息就无效了。这里如果校验成功则执行（7）使用本地方法栈里面的值进行计算然后返回。需要注意的是在代码（3)校验成功后，代码（7）计算中其他线程可能获取到了写锁并且修改了x,y的值，而当前线程执行代码（7）进行计算时候采用的才是对修改前值的拷贝，也就是操作的值是对之前值的一个拷贝，并不是新的值。另外还有个问题，代码（2)和（3）能否互换，答案是不能，假设位置换了，那么首先执行validate，假如验证通过了，要拷贝x,y值到本地方法栈，而在拷贝的过程中很有可能其他线程已经修改了x,y中的一个，这就造成了数据的不一致性了。那么你可能会问，那不交换(2)和（3）时候在拷贝x,y值到本地方法栈里面时候也会存在其他线程修改了x,y中的一个值那，这个确实会存在，但是，别忘了拷贝后还有一道validate,如果这时候有线程修改了x,y中的值，那么肯定是有线程在调用validate前sl.tryOptimisticRead后获取了写锁，那么validate时候就会失败。现在应该明白了吧，这也是乐观读设计的精妙之处也是使用时候容易出问题的地方。下面继续分析validate失败后会执行代码（4）获取悲观读锁，如果这时候其他线程持有写锁则代码（4）会导致的当前线程阻塞直到其它线程释放了写锁。获取到读锁后，代码（5）拷贝变量到本地方法栈，然后就是代码（6）释放了锁，拷贝的时候由于加了读锁在拷贝期间其它线程获取写锁时候会被阻塞，这保证了数据的一致性。最后代码（7）使用方法栈里面数据计算返回，同理这里在计算时候使用的数据也可能不是最新的，其它写线程可能已经修改过原来的x,y值了。 总体来说，相对于ReentrantReadWriteLock，由于乐观读锁并不需要CAS设置状态，而只是简单的测试，因此在高并发条件下会有更好的性能。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-AQS(3)]]></title>
    <url>%2F2017%2F12%2F09%2FJAVA%E5%B9%B6%E5%8F%91%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%B4%A9%E6%BA%83-AQS%2F</url>
    <content type="text"><![CDATA[什么是AQSAQS是AbstractQueuedSynchronizer的缩写，是用来实现一个锁的底层框架。 为什么要了解AQS(队列同步器)呢？因为我们在并发编程的时候很可能用到锁，而AQS与锁的实现密切相关。可是在图中我们并没有看到AQS与Lock产生直接关联，这是因为在每个锁内部都封装了一个抽象类Sync，而sync继承自AQS，如ReentranLock： AQS是JUC中Lock的实现关键，是实现锁或者自定义一个同步组件的基本框架，它使用了一个volatile int state作为同步状态，通过内置的FIFO队列(CLH)完成线程排队工作。AQS同事支持独占式获取同步状态，也支持共享式获取同步状态，以实现不同组件。Lock通过AQS框架，隐藏了具体的实现细节而与用户的交互使用接口，大大简化了锁的实现方式。它封装了线程、挂起唤醒的内部运作，我们只需要通过设置AQS的state值来控制他的线程挂起和唤醒的运作路径，就可以实现我们的同步器类了。 AQS提供的方法可分为三类: 独占式获取/释放状态 共享式获取/释放状态 查询同步队列情况 通过以下代码我们就可以简单实现一个互斥锁。 1234567891011121314151617181920212223242526272829303132333435public class mutex &#123; Sync sync = new Sync(); public void lock()&#123; sync.tryAcquire(1); &#125; public void unlock()&#123; sync.tryRelease(0); &#125; private static class Sync extends AbstractQueuedSynchronizer&#123; @Override protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; @Override protected boolean tryAcquire(int arg) &#123; if(compareAndSetState(0,1))&#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; @Override protected boolean tryRelease(int arg) &#123; if(getState()==0)&#123; throw new IllegalMonitorStateException(&quot;状态不符合预期&quot;); &#125; setExclusiveOwnerThread(null); setState(0); return true; &#125; &#125;&#125; AQS实现分析AQS内部维护了一个双向队列，队列的没个节点是一个Node内部类，当线程获取同步状态失败时，就会被封装为一个Node。 可以看到Node类有三个构造函数，参数包括Thread、node模式、等待状态。结合这个图我们就可以知道这个队列的基本形式了。等待进程被封装为Node并标记Node是共享模式还是独占模式，也可以设置它的等待状态。当前节点有前驱节点和后继节点，并有一个专门的变量保存他的下一个等待节点。 构成的AQS队列就是这样一种形式 同步器包含一个头结点和一个尾节点，加入队列的过程必须保证线程安全，因为同时可能有多个线程获取同步状态失败而进入队列尾部，因此AQS提供了compareAndSetTail方法,而每次出队时只可能有一个线程获取到同步状态，因此出队的方法不需要保证线程安全。 独占式独占式获取同步状态代码如下: 1234public final void acquire(int arg) &#123; if (!tryAcquire(arg)&amp;&amp;acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 该方法首先完成了获取同步状态，构造加点，加入队列并在同步队列中自旋的工作。首先调用tryAcquire方法保证线程安全的获取同步状态，如果失败则构造EXCLUSIVE独占式节点，加入同步队列尾部。acqireQueued则是自旋等待锁的释放。如果该过程失败了，则调用selfInterrupt方法将自己中断。 共享式共享式获取同步状态代码如下: 1234567891011121314151617181920212223242526272829303132public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 可以看到方法的主体doAcpuireShared方法会包含一个死循环，也就是一个自旋的过程。只有当前节点是头节点的时候，才会去尝试获取同步状态，如果返回值＞0，表示获取成功退出自旋状态。所以在上面的方法acquireShared，当返回值＜0的时候才会一直进入下面的方法尝试一直获取同步状态。 阻塞与唤醒当一个线程加入到CLH队列中时，如果不是头节点是需要判断该节点是否需要挂起；在释放锁后，需要唤醒该线程的继任节点。AQS使用了LockSupport类中的park方法实现了阻塞： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 123456public static void park(Object blocker) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null);&#125; LockSupport是用来创建锁和其他同步类的基本线程阻塞原语。每个使用LockSupport的线程都会与一个许可关联，如果该许可可用，并且可在进程中使用，则调用park()将会立即返回，否则可能阻塞。如果许可尚不可用，则可以调用 unpark 使其可用。但是注意许可不可重入，也就是说只能调用一次park()方法，否则会一直阻塞。可以看到park来自于UNSAFE类，UNSAFE中包含了大量的JNI方法，也就是说park和unpark方法是利用了C语言编写的方法，对操作系统底层进行的操作。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC-CAS(2)]]></title>
    <url>%2F2017%2F12%2F08%2Fjava%E5%B9%B6%E5%8F%91%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%B4%A9%E6%BA%83-CAS%2F</url>
    <content type="text"><![CDATA[Compare And SetCAS是java并发中最底层的一种技术支持，对内存中的共享数据的读写保证其原子操作。过程如下：首先CPU将内存中的将要被修改的数据与预期的值进行比较，如果这两个值相等，CPU则会将内存中数值替换为新值，否则不做操作。最后，CPU会将旧值返回。CAS的工作方式更多的是与硬件层面的CPU进行交互，而不在语言层面，所以很多资料都是点到为止：一种底层的原子性操作。 我们可以在AtomicBoolean.class中找到代码 可以看到这里有CAS操作，再进入到unsafe.class中，可以发现CAS操作都是native型的，即调用了JNI的方法。 所以当我们需要对一个数据进行原子操作的时候，java给我们提供了13个原子操作类: AtomicBoolean AtomicIngeger AtomicLong AtomicIntegerArray AtomicLongArray AtomicReferenceArray …. CAS存在的问题 ABA问题 循环开销大 无法保证对多个共享变量的原子操作 为什么是volatile和cas作底层由于java的CAS同时具有volatile读和volatile写的内存语义，因此java之间线程通信目前有以下几种形式。 A线程写volatile变量，B线程读这个volatile变量 A线程写volatile变量，B线程以cas更新volatile变量 A线程cas更新一个volatile变量，B线程cas更新这个volatile变量 A线程cas更新一个volatile变量，B线程读这个volatile变量 JAVA的CAS会使用现代处理器上提供的高效机器级别的原子指令，这些指令以原子的形式对内存执行读写操作。同时volatile和CAS一起使用可以实现线程之间的通信，因此构成了JUC的基石。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC--常用篇(1)]]></title>
    <url>%2F2017%2F12%2F03%2Fjava%E5%B9%B6%E5%8F%91%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%B4%A9%E6%BA%83-%E5%B8%B8%E7%94%A8%E7%AF%87%2F</url>
    <content type="text"><![CDATA[关于并发的一些思考最近看完了《java多线程编程核心技术》、《java并发编程艺术》两本书。第一本更偏向于线程基础技术，看完之后给人一种眼前明亮之感。啊，原来并发编程就是这些操作。当我看完第二本之后，就已经一脸茫然，忘记了第一本的内容 - -!。因为第二本的内容太丰富，涉及到并发的底层原理和框架。于是我又拿出来《java编程思想》找到了并发的一章来看，发现看完已经满脑浆糊了，所以还是要坚持写一下博文，理一下思路也好。 多线程，任何一个程序员都知道，但是实际工作中，大部分程序员面对的都是业务的CRUD和BUG定位，貌似没有太多机会接触并发。大家都知道程序运行的时候，最关键的是内存和CPU，而CPU运算的时候，是要从内存取值，当然现在很多时候是在L1/L2等Cache中取值，然后放入寄存器，参与运算，得到结果，先放入寄存器，再放入内存。程序执行的指令也放在寄存器，它记录当前程序执行的地址。 上面说到了，一个数值，进入CPU运算，经过了内存、cache、寄存器。看过jvm我们就知道，当多线程运算同一个值的时候，是每个线程拷贝了一份值的副本到自己的线程工作内存（这里还涉及到java的内存模型），当一个线程计算完毕（计算结果写入寄存器），还没有刷到主存，另一个线程从主存中取到的值还是旧值。所以一个很直观的问题就是如何保证每个线程拿到的数据是最新的，这就是同步机制。最常见的volatile和synchronized就是为了解决这个问题。 最简单的解决方案就是：共享变量同一时刻只允许有一个线程操作。这就保证了线程要么拿不到值，要么拿到最新的值。于是有了synchronized告诉jvm：这个地方是临界区，只有一把锁。那道锁的那个家伙才能开门进去，否则只能在门口等着。java中的锁，可以是this，方法，对象，类。锁的范围可以是代码块，方法甚至类。jvm会在锁和方法区之间建立联系。jvm生成一个对象会产生很多额外的信息，起码要有对象的内存地址或一个间接的指针，所以要标识一个对象被哪个线程占有并不困难。 上面的方法虽然可以解决问题，但是很简单粗暴，我们想要一种更灵活的方式。很多时候我们并不关心谁在操作对象，我们只关心这个值到底是多少。于是就有了volatile：保证可见性，不保证原子性。其实意思就是说被volatile修饰的这个对象是一个尊贵的java会员，你要找他必须到他的家（内存）去接它出来，你请它聊天吃饭之后还要把它送回家(内存)。所以这里略过了计算机的高速缓存，读写内存。所以可见性就是说这个值谁都可以看到。至于不保证原子性，就是说这个值谁都可以取来运算。至于说到volatile的效率嘛，肯定也是大打折扣的，因为操作内存很定要比缓存慢的多。就如同数据库，其实我们也是写入了缓存，后台线程刷到磁盘而已。其实从硬件到软件，设计的思想大都是相通的。 再说sychronized举个栗子，多人上厕所。多线程和锁，一个是线程，一个是对象。一个在私有的线程栈中，一个在共享堆中。如何标识某个对象被某个线程锁定？线程开启一片栈帧，在其中存储对象锁记录，堆中对象有对象头（元数据、Runtime State、gc分代等等），可以标识被哪个线程锁定，实际上锁线程就是利用了对象头和monitor来实现锁机制。 所以在上厕所的例子中，人就是线程，厕所就是共享对象，锁就是对象头，monitor就是钥匙。 sychronized锁的是一个对象，或者是一个类的实例，或者是类本身。sychronized内部原理是通过对象内部一个叫监视器的东西来实现的。本质又是依赖于操作系统的mutex::Lock(一种互斥锁)来实现的。而操作系统实现线程切换需要从用户态转向核心态，这个成本非常高。这也是我们为什么说sychronized效率低的原因。其实我们常用的HashMap内部就有很多的sychronized方法，这也就是我们说HashMap效率低的问题（关于HashMap可以衍生出很多问题，包括一些算法和红黑树，以后会慢慢写），如下给出了HashMap的put方法。 public synchronized V put(K key, V value) {} 在JDK5之后的版本一直在对sychronized进行优化，都是为了减少这种重量级锁的使用。如JDK6中引入的自旋锁，适应性自旋锁，锁消除，锁粗化，偏向锁等技术减少锁的消耗。以上内容等我想明白再细说吧。 既然对sychronized有这么多的怨言，当然就会出现可行的替代方案-Lock。简单来说就是把sychronized拆分成获得锁，释放锁的多个步骤。用更灵巧的方式进行同步，使用Lock会更灵活，粒度可以自由控制。当然也会带来更复杂的参数和学习成本。😢 介绍一种反汇编的指令： javap xxx.class 通过javap可以更清晰的看到底层实现的细节,上图就展示了sychronized的底层代码。 再说volatile如果对声明了volatile变量进行写操作时，JVM会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写会到系统内存。 这一步确保了如果有其他线程对声明了volatile变量进行修改，则立即更新主内存中数据。 但这时候其他处理器的缓存还是旧的，所以在多处理器环境下，为了保证各个处理器缓存一致，每个处理会通过嗅探在总线上传播的数据来检查 自己的缓存是否过期，当处理器发现自己缓存行对应的内存地址被修改了，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作时，会强制重新从系统内存把数据读到处理器缓存里。 这一步确保了其他线程获得的声明了volatile变量都是从主内存中获取最新的。 volatile关键字的另一种用途是保证long和double的原子性操作。其实是利用了某些cpu的高速缓存是64字节宽度，并且不支持填充缓存行的机制。这种应用场景应用相对较少且并不具有普适性，就不在过多介绍。 创建多线程的方式 继承Thread类 实现Runnable接口 匿名内部类 带返回值的线程(Callable/Future) 定时器 线程池 Lambda表达式 其中第七种是从java8才开始的，其它六种应该很常见，记录一下第七种。new Thread(() -&gt; { Sysout.out.println(&quot;I am a new Thread&quot;); }).start(); 最近也在学习lambda表达式的写法，真的是一种让人学会了就一直想秀的语法。 总结写了一些比较基础的东西，发现再深入一点可能就讲不清楚了。需要在花上半个月再好好看一遍，贴一张书中的图，看完整本书再看这个图就觉得清晰了很多。计划从下往上总结吧。 回头看了一下才发现，大多数内容是加锁。但其实有一点我们要清楚，使用多线程的目的是完成业务而不是为了和锁纠缠不清，加锁只是不得已而为之。]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[表面理解jvm-内存]]></title>
    <url>%2F2017%2F11%2F22%2F%E8%A1%A8%E9%9D%A2%E7%90%86%E8%A7%A3jvm-%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[最近看完了《深入理解java虚拟机》这本书，记录一下所学所思，留作以后复习。 宏观先来说说虚拟机，我们都知道Java程序运行在虚拟机上，虚拟机负责和操作系统打交道，最终通过二进制指令操作电子电路运行，完成数据的读取，运算，输出。虚拟机在加载.class文件的时候会在内存开辟一块区域”方法区”,专门用来存储累的基本信息，同时在”堆”区生成这个类的Class对象，作为类的一个镜像，为反射机制提供一种可能。Java是一门面向对象的语言，程序运行过程中伴随着对象的生成与死亡，有的是临时对象短暂存活，有的是壮年而亡，而有的长命百岁。所以虚拟机就不停地申请内存，回收内存。对象的生成方法很多，对象的回收方法也很多，例如GC、标记清除/整理等。 垃圾回收首先要确定的是什么是垃圾，什么时候回收，在哪里回收，怎么回收。不同的对象可能需要不同的回收策略。一个很容易想到的方法就是在后台启动一个线程，每隔一段时间扫描一次内存，清除垃圾，如此往复。 实际情况往往非常复杂，效率、安全性、对当前程序的影响都要考虑进去。于是人们发现，对象的生命周期不同，使用一种GC方法效率很差。于是就有了Hotspot的方案，堆区根据不同的生命周期，分为eden、to survivor、from survivor以及非堆的元数据区(java8之前的永久区)。 每个区采用了不同的清理算法。于是便出现了最初的串行收集器。 同时，为了最大程度的利用CPU的多核资源，出现了并行收集器，即多个线程一起收集垃圾。 为了降低垃圾收集对原有程序的影响,如STW,一种全局暂停的现象，并发收集器应运而生。 到此为止，便可以引出jvm优化中最重要的两部分，jvm内存怎么划分，选择哪一种垃圾收集器，就是我们常说的jvm调优。这就考验一个开发人员对业务系统的理解和眼光，确定优化方向并调整参数。 jvm内存模型首先要分清楚的一点是jvm内存模型 != java内存模型(JMM) 自己画了一张思路的整理图： 整理一些零碎的东西： 程序计数器是此内存区唯一一个没有OOM情况的区域。 方法区有个别名叫做非堆，用于存储加载的类的信息，在hotspot虚拟上更多的叫做“永久代”,在java8中已经改名为元数据区(MetaSpace)，该区域也可以选择不进行垃圾回收。 新生对象优先被分配到Eden区 大对象直接被分到老年代，常见的如长字符串以及数组 长期存活的对象直接进入老年代。一次Minor GC年龄增长一岁，默认15岁进入老年代。可以调节-XX：MaxTenuringThreshold参数来改变 在survivor空间中年龄相同的所有对象的大小总和大于survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代(这一条读了很多遍才明白) 对象创建当我们使用new创建一个对象时，大概发生了这样一些事情。首先类加载器检查这个类有没有被加载过，如果没有则需要加载-&gt;解析-&gt;初始化。之后虚拟机为它分配内存，就是将一块确定大小的内存划分出来。这时会遇到两个问题： 内存是否规整内存是否规整取决于所使用的gc器，如Serial，ParNew等带有整理功能的收集器，就是规整的，在分配内存时只要将标志占用或空闲的指针移动就可以了。如果使用CMS这种基于mark-sweep的算法gc器，则不是规整的，需要利用一张”空闲列表“查找空闲的区块来分配内存。 频繁创建对象对象的频繁创建可能造成前一个对象的指针没有来得及修改，后一个对象便占用了前一个对象的位置。解决方法有两种：一是CAS(compare and sweep一种乐观锁)+失败重试保证更新的原子性，也是虚拟机实际采用的一种方法。二是TLAB（本地线程分配缓冲）,哪个线程需要分配内存就在哪个线程的TLAB上进行分配，可以使用-XX：+UseTLAB开启，个人认为这个参数可以在高并发场景下开启，适合在eden区使用。 HotSpot的实现方式当判断一个对象是否应该被回收时，java采用了一种可达性分析的方法来判断。要做到这点就需要得到所有的GC Roots节点，从GC Root来遍历。如果我们对栈全部扫描一遍这是相当浪费时间和资源的事情，于是我们可以在某个位置把栈上的引用位置记录下来，这样在gc时便不用全盘扫描。在Hotspot中这种结构就叫OopMap,记录了在该类型的对象内什么偏移量上是什么类型的数据。但是我们并不能在任何时候都生成OopMap，只会在称之为安全点的地方生成： 循环的末尾 方法返回前 可能抛出异常的地方 另一个需要考虑的问题是如何在GC发生时如何保证所有线程走到最近的安全点再停下来，目前最广泛的做法就是主动式中断，设置一个标志，让各个线程主动轮询这个标志，如果标志位true就中断。这时又会有问题，如果程序不能继续执行呢，例如碰到了sleep情况，jvm不会等到线程被重新分配CPU时间，这时就需要安全区来解决。在安全区的任意地点GC都是安全的，当线程进入安全区，首先会标识自己，如果这段时间jvm发起了GC，则不管标记安全区的线程。当线程离开安全区，它要自己检查是否完成了根节点枚举，如果完成了就可以继续执行，否则就要等待。 垃圾收集器 串行收集器 serial收集器 -XX:+UseSerialGC 并行收集器 ParNew收集器 -XX:+UseParNewGC-XX:ParallelGCThreads 限制线程数量 Parallel收集器 -XX:+UseParallelGC 并发收集器 CMS收集器 -XX:+UseConcMarkSweepGC-XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长。 -XX:+CMSFullGCsBeforeCompaction 设置进行几次Full GC后，进行一次碎片整理-XX:ParallelCMSThreads 设定CMS的线程数量 G1收集器：据说会在java9上设置为默认的垃圾收集器，但是最近java9已经更新了，并没有相关的消息。G1的优点就是调优简单，只需要调节最大堆内存和最大暂停时间，另外就是取消了年轻代和老年代的物理划分。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMvc浅谈]]></title>
    <url>%2F2017%2F11%2F11%2FSpringMvc%E6%B5%85%E8%B0%88%2F</url>
    <content type="text"><![CDATA[springmvc在哪里springmvc是spring体系的一部分，位于web部分。 springmvc的设计模式先来看一个简化版:用户请求到达控制器，控制器并没有处理业务逻辑的能力，于是把请求交给后台的一个model做处理，并将处理的结果返回给控制器。当控制器拿到数据后，就要找到视图并做渲染，并将渲染好的结果返回给用户，这就是一个通用的mvc设计模式。 spirngmvc架构： 可以看到这个架构的入口就是DispatcherServlet，其本质也是一个servlet，同时这也显示出了它与struts2的区别之一，Struts2的入口是一个过滤器。DispatcherServlet也没有处理事务的能力，仅作为一个数据的分发中心，将数据交给后面的过程来处理。DispatcherServlet通过HandlerMapping来查找Handler，HandlerMapping会返回两部分内容，其一是handler对象，也就是后台模型对象，还有一部分是拦截器数组。前端控制器拿到这些返回数据时，其实就应该来执行handler对象，因为执行handler对象就可以处理具体的业务逻辑。但是springmvc并没有这样做，它将数据利用HandlerAdapter适配器进行包装，也就到了图中的Handler部分。Handler处理过后返回一个ModelAndView对象，包括两部分：Model和view，Model就是数据，view就是视图名称，而不是视图对象。这时前端控制器既有数据，又有视图名称，这时通过视图解析器返回真正的视图对象，最后将视图对象进行渲染并返回给用户。 springmvc为什么要设计适配器？没有行不行？ 首先要明确的是在springmvc框架中controller的类型有很多种，比较常见的是@controller类型和实现Handler接口的类型，如果没有适配器，前端控制器就需要做一个类型判断，每种类型需要做哪些不同的处理。这时判断逻辑就会写死在代码中，并不符合springmvc的可扩展行的设计，一旦用户需要自己创建一个类型，那么就需要修改spring源码，这显然是不可取的。但有了适配器问题就方便了很多，每种类型只需要定义一种适配器即可。 springmvc为什么要设计视图解析器？没有行不行？ 其实答案和上一个问题一样，当然都是可以的，只是这样需要在前端控制器加入逻辑判断，并不优雅也不易扩展。]]></content>
      <categories>
        <category>springmvc</category>
      </categories>
      <tags>
        <tag>springmvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis持久化]]></title>
    <url>%2F2017%2F11%2F10%2Fredis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis的强大功能很大程度上是由于其将所有数据存储在内存中，为了使redis重启后数据不丢失，需要将数据以某种形式保存在硬盘中。 Redis支持两种持久化方式，RDB和AOF。可以单独使用一种或两种结合。redis默认的持久化方式是RDB。 RDB通过快照完成，当符合一定条件时redis会自动将内存中的数据进行快照并保存在硬盘上。参数有两个：时间和改动键的个数。当指定时间内更改键的个数大于指定值就会快照,默认配置如下，单位为秒。 可以通过SAVE和BGSAVE指令来手动进行快照。 SAVE由主进程进行快照，会阻塞其他请求。 BGSAVE通过fork一个子进程进行快照。 RDB快照过程 redis使用fork函数复制一份当前进程的副本。 父进程继续接受后续指令，子进程还是将内存中的数据写入硬盘中的临时文件。 子进程写入完成数据后用临时文件替换就得RDB文件。 可以配置rdbcompression yes来选择是否对rdb进行压缩。压缩的好处显而易见就是减少资源的消耗。缺点就是消耗更多的cpu资源。而选择不压缩就相反。 s AOF持久化方式策略是将发送到redis服务端的每条命令都记录下来，保存到aof文件，其实aof就是一种日志策略，只要重新执行每一条记录下的指令，就可以恢复这个过程中的数据。通过修改配置为yes就可以启动aof的持久化方式。 但是使用AOF方式可能会记录很多中间的过程，这或许对于我们所需的最终结果是没有什么帮助的。例如12set abc 1set abc 2 reids会记录这两条命令，但我们只需要abc 2就可以了。 redis提供了BGREWRITEAOF指令来优化AOF文件，目的就是去除中间的执行过程。重写策略提供了一些参数： 第一参数指定了重写百分比。例如现在的aof文件大小为64MB，那么下一次重写就是128mb的时候也就是再增加100%的64MB 第二个参数指定了aof文件最小为64MB的时候才进行重写。 写入硬盘文件写入默认情况下先写入系统缓存，系统每根据策略同步，才是真正写入硬盘中，如果这期间服务器宕机，数据也是会丢失的，redis提供了一些配置来修改同步策略。 每次同步 安全但是最慢 每秒同步 默认策略 不主动同步，由操作系统决定，同步周期可能达到30s 最快但是不安全]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java对象:引用||传递]]></title>
    <url>%2F2017%2F11%2F08%2Fjava%E5%AF%B9%E8%B1%A1-%E5%BC%95%E7%94%A8-%E4%BC%A0%E9%80%92%2F</url>
    <content type="text"><![CDATA[在java中，任何对象变量的值都是对存储在另外一个地方的一个对象的引用。 赋值在java中有八种基本数据类型，分别是byte、short、int、long、float、double、boolean、char。这八种基本类型的数据，值就保存咋变量中。除去以上八种基本数据类型，其余类型包括自定义的类，都属于引用类型，变量中保存的是引用对象的地址，我们也称为引用。1234int x=1;int y=x;String a = &quot;nihao&quot;;String b = a; 传参1234567891011public class main &#123; private static void add(int a)&#123; a++; System.out.println(a+&quot;--add&quot;); &#125; public static void main(String[] args) &#123; int a = 1; add(a); System.out.println(a+&quot;--origin&quot;); &#125;&#125; 结果为122--add1--origin 果然对于int这种基本类型，传递的是值而不是引用。 1234567891011121314public class main &#123; private static void add(String a)&#123; a = a+&quot;++++&quot;; System.out.println(a); &#125; public static void main(String[] args) &#123; String a = &quot;hello&quot;; add(a); System.out.println(a); &#125;&#125;out:hello++++hello 再测试一下String类型，String 不属于基本类型，出乎我意料的是以为String会是引用传递，但发现string竟然是值传递。再测试一下自定义的类。 12345678910111213141516public class main &#123; private static void add(student a)&#123; a.setName(&quot;gyj&quot;); System.out.println(a.toString()); &#125; public static void main(String[] args) &#123; student s = new student(); s.setGender(&quot;男&quot;); s.setName(&quot;sc&quot;); add(s); System.out.println(s.toString()); &#125;&#125;out:student&#123;name=&apos;gyj&apos;, gender=&apos;男&apos;&#125;student&#123;name=&apos;gyj&apos;, gender=&apos;男&apos;&#125; 果然自定义的类型是使用引用传递，通过查找资料得出以下结论。 对象就是传引用 原始类型就是传值 String，Integer, Double等immutable类型因为没有提供自身修改的函数，每次操作都是新生成一个对象，所以要特殊对待。可以认为是传值。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis解决分布式锁]]></title>
    <url>%2F2017%2F11%2F01%2Fredis%E8%A7%A3%E5%86%B3%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[废话不多说，首先分享一个业务场景-抢购。一个典型的高并发问题，所需的最关键字段就是库存，在高并发的情况下每次都去数据库查询显然是不合适的，因此把库存信息存入Redis中，利用redis的锁机制来控制并发访问，是一个不错的解决方案。 首先是一段业务代码： 12345678910111213141516171819@Transactionalpublic void orderProductMockDiffUser(String productId)&#123; //1.查库存 int stockNum = stock.get(productId); if(stocknum == 0)&#123; throw new SellException(ProductStatusEnum.STOCK_EMPTY); //这里抛出的异常要是运行时异常，否则无法进行数据回滚，这也是spring中比较基础的 &#125;else&#123; //2.下单 orders.put(KeyUtil.genUniqueKey(),productId);//生成随机用户id模拟高并发 sotckNum = stockNum-1; try&#123; Thread.sleep(100); &#125; catch (InterruptedExcption e)&#123; e.printStackTrace(); &#125; stock.put(productId,stockNum); &#125;&#125; 这里有一种比较简单的解决方案，就是synchronized关键字。1public synchronized void orderProductMockDiffUser(String productId) 这就是java自带的一种锁机制，简单的对函数加锁和释放锁。但问题是这个实在是太慢了，感兴趣的可以可以写个接口用apache ab压测一下。 1ab -n 500 -c 100 http://localhost:8080/xxxxxxx 下面就是redis分布式锁的解决方法。首先要了解两个redis指令SETNX 和 GETSET，可以在redis中文网上找到详细的介绍。SETNX就是set if not exist的缩写，如果不存在就返回保存value并返回1，如果存在就返回0。GETSET其实就是两个指令GET和SET，首先会GET到当前key的值并返回，然后在设置当前Key为要设置Value。 首先我们先新建一个RedisLock类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Slf4j@Componentpublic class RedisService &#123; @Autowired private StringRedisTemplate stringRedisTemplate; /*** * 加锁 * @param key * @param value 当前时间+超时时间 * @return 锁住返回true */ public boolean lock(String key,String value)&#123; if(stringRedisTemplate.opsForValue().setIfAbsent(key,value))&#123;//setNX 返回boolean return true; &#125; //如果锁超时 *** String currentValue = stringRedisTemplate.opsForValue().get(key); if(!StringUtils.isEmpty(currentValue) &amp;&amp; Long.parseLong(currentValue)&lt;System.currentTimeMillis())&#123; //获取上一个锁的时间 String oldvalue = stringRedisTemplate.opsForValue().getAndSet(key,value); if(!StringUtils.isEmpty(oldvalue)&amp;&amp;oldvalue.equals(currentValue))&#123; return true; &#125; &#125; return false; &#125; /*** * 解锁 * @param key * @param value * @return */ public void unlock(String key,String value)&#123; try &#123; String currentValue = stringRedisTemplate.opsForValue().get(key); if(!StringUtils.isEmpty(currentValue)&amp;&amp;currentValue.equals(value))&#123; stringRedisTemplate.opsForValue().getOperations().delete(key); &#125; &#125; catch (Exception e) &#123; log.error(&quot;解锁异常&quot;); &#125; &#125;&#125; 这个项目是springboot的项目。首先要加入redis的pom依赖，该类只有两个功能，加锁和解锁，解锁比较简单，就是删除当前key的键值对。我们主要来说一说加锁这个功能。首先，锁的value值是当前时间加上过期时间的时间戳，Long类型。首先看到用setiFAbsent方法也就是对应的SETNX，在没有线程获得锁的情况下可以直接拿到锁，并返回true也就是加锁，最后没有获得锁的线程会返回false。 最重要的是中间对于锁超时的处理，如果没有这段代码，当秒杀方法发生异常的时候，后续的线程都无法得到锁，也就陷入了一个死锁的情况。我们可以假设CurrentValue为A，并且在执行过程中抛出了异常，这时进入了两个value为B的线程来争夺这个锁，也就是走到了注释*的地方。currentValue==A，这时某一个线程执行到了getAndSet(key,value)函数(某一时刻一定只有一个线程执行这个方法，其他要等待)。这时oldvalue也就是之前的value等于A，在方法执行过后，oldvalue会被设置为当前的value也就是B。这时继续执行，由于oldValue==currentValue所以该线程获取到锁。而另一个线程获取的oldvalue是B，而currentValue是A，所以他就获取不到锁啦。多线程还是有些乱的，需要好好想一想。接下来就是在业务代码中加锁啦：首要要@Autowired注入刚刚RedisLock类，不要忘记对这个类加一个@Component注解否则无法注入 12345678910111213141516171819202122232425private static final int TIMEOUT= 10*1000;@Transactionalpublic void orderProductMockDiffUser(String productId)&#123; long time = System.currentTimeMillions()+TIMEOUT; if(!redislock.lock(productId,String.valueOf(time))&#123; throw new SellException(101,&quot;换个姿势再试试&quot;) &#125; //1.查库存 int stockNum = stock.get(productId); if(stocknum == 0)&#123; throw new SellException(ProductStatusEnum.STOCK_EMPTY); //这里抛出的异常要是运行时异常，否则无法进行数据回滚，这也是spring中比较基础的 &#125;else&#123; //2.下单 orders.put(KeyUtil.genUniqueKey(),productId);//生成随机用户id模拟高并发 sotckNum = stockNum-1; try&#123; Thread.sleep(100); &#125; catch (InterruptedExcption e)&#123; e.printStackTrace(); &#125; stock.put(productId,stockNum); &#125; redisLock.unlock(productId,String.valueOf(time));&#125; 大功告成了！比synchronized快了不知道多少倍，再也不会被老板骂了!]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
</search>
